[{"uri":"https://beforelights.github.io/AWS-Worklog/vi/4-eventparticipated/4.1-event1/","title":"Sự kiện 1","tags":[],"description":"","content":"Báo cáo Tóm tắt: “Vòng đời Phát triển Định hướng AI: Tái định hình Kỹ thuật Phần mềm” Mục tiêu Sự kiện Sự kiện nhằm cung cấp sự hiểu biết sâu sắc về tác động chuyển đổi của AI tạo sinh đối với phát triển phần mềm. Các mục tiêu chính bao gồm:\nGiới thiệu khung Vòng đời Phát triển Định hướng AI (AI-DLC) và các nguyên tắc nền tảng của nó. Trình diễn khả năng của Kiro và Amazon Q Developer như các công cụ hỗ trợ phát triển định hướng AI. Khám phá cách AI tạo sinh có thể nâng cao năng suất và hợp lý hóa quy trình kỹ thuật phần mềm. Diễn giả Phiên họp có sự chia sẻ từ hai diễn giả nổi bật:\nToan Huynh – Specialist SA, PACE My Nguyen – Senior Prototyping Architect, Amazon Web Services - ASEAN Điểm nổi bật Chính Sự kiện tập trung vào khung AI-DLC, tái định hình phát triển phần mềm bằng cách định vị AI là đối tác cộng tác. Các khái niệm chính bao gồm:\nKhái niệm Cốt lõi AI-DLC: Khung nhấn mạnh cách tiếp cận lấy con người làm trung tâm, trong đó AI đóng vai trò là cộng tác viên để tăng cường khả năng của lập trình viên. Điều này dẫn đến chu kỳ phát triển được tăng tốc, giảm thời gian từ vài tuần hoặc vài tháng xuống chỉ còn vài giờ hoặc vài ngày.\nQuy trình làm việc AI-DLC: Quy trình lặp lại luân phiên giữa các nhiệm vụ do AI điều khiển (ví dụ: tạo kế hoạch, triển khai giải pháp, tìm kiếm sự làm rõ) và các nhiệm vụ do con người điều khiển (ví dụ: cung cấp sự làm rõ, xác thực giải pháp). AI chỉ thực thi các giải pháp sau khi con người xác thực, đảm bảo chất lượng và sự liên kết.\nCác giai đoạn AI-DLC: Vòng đời được chia thành ba giai đoạn riêng biệt:\nKhởi tạo (Inception): Thiết lập bối cảnh, làm rõ ý định của người dùng thông qua user stories, và lập kế hoạch nhiệm vụ sử dụng Units of Work. Xây dựng (Construction): Mô hình hóa miền, tạo mã, kiểm thử và triển khai cơ sở hạ tầng dưới dạng mã (IaC) với các bài kiểm thử tự động. Vận hành (Operation): Quản lý triển khai sản xuất và giải quyết sự cố. Các thách thức được giải quyết bởi AI-DLC:\nMở rộng phát triển AI cho các dự án phức tạp. Tăng cường kiểm soát và cộng tác với các tác nhân AI (AI agents). Duy trì chất lượng mã từ giai đoạn proof-of-concept đến sản xuất. Đi sâu: Kiro - IDE AI cho Prototype đến Production Phiên họp bao gồm một bản demo chi tiết về Kiro, một Môi trường Phát triển Tích hợp (IDE) ưu tiên AI được thiết kế để hỗ trợ khung AI-DLC. Các tính năng chính của Kiro bao gồm:\nPhát triển dựa trên Đặc tả (Spec-Driven Development): Kiro chuyển đổi các lời nhắc cấp cao (ví dụ: \u0026ldquo;Xây dựng ứng dụng trò chuyện giống Slack\u0026rdquo;) thành các tạo tác có cấu trúc như:\nrequirements.md cho các yêu cầu rõ ràng. design.md cho thiết kế hệ thống. tasks.md cho các nhiệm vụ rời rạc, có thể hành động. Cách tiếp cận có cấu trúc này đảm bảo khả năng truy xuất nguồn gốc và chuyển việc phát triển từ viết mã dựa trên trực giác sang một quy trình có hệ thống. Quy trình làm việc Agentic: Các tác nhân AI của Kiro tự chủ thực hiện các nhiệm vụ trong khi vẫn giữ quyền kiểm soát cho lập trình viên. Các tính năng chính bao gồm:\nKế hoạch Triển khai: Kiro tạo ra các kế hoạch chi tiết với các nhiệm vụ và nhiệm vụ phụ liên kết với các yêu cầu cụ thể để xác thực. Agent Hooks: Các hook này kích hoạt các tác nhân AI thực hiện các nhiệm vụ như tạo tài liệu, viết kiểm thử đơn vị, hoặc tối ưu hóa hiệu suất mã trong nền. Bài học Chính Sẵn sàng cho Sản xuất Định hướng AI: Kiro đảm bảo mã sẵn sàng cho sản xuất bằng cách tạo các tài liệu thiết kế chi tiết (ví dụ: sơ đồ luồng dữ liệu, hợp đồng API) và kiểm thử đơn vị trước khi bắt đầu triển khai. Kiểm soát của Con người thông qua Tạo tác: Lập trình viên duy trì sự giám sát bằng cách xác thực và tinh chỉnh các tạo tác (yêu cầu, thiết kế, kế hoạch nhiệm vụ) trước khi các tác nhân AI thực thi việc triển khai. Áp dụng Kiến thức vào Công việc Sự kiện đã cung cấp những hiểu biết có thể hành động để tích hợp các công cụ định hướng AI vào quy trình làm việc của tôi:\nÁp dụng Trợ lý Viết mã AI: Các công cụ như Amazon Q Developer có thể tự động hóa các nhiệm vụ lặp đi lặp lại, cho phép tôi tập trung vào các hoạt động có giá trị cao. Ưu tiên Nhiệm vụ Lấy con người làm trung tâm: Bằng cách giao các nhiệm vụ thường ngày cho AI, tôi có thể dành nhiều thời gian hơn cho các hoạt động sáng tạo và chiến lược như mô hình hóa miền và thiết kế kiến trúc. Trải nghiệm Sự kiện Tham dự sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering là một trải nghiệm mở mang tầm mắt. Phiên họp đã làm nổi bật cách AI tạo sinh đang phát triển từ một trợ lý viết mã thành một người điều phối trung tâm của quy trình phát triển. Cách tiếp cận có cấu trúc của AI-DLC, kết hợp với các công cụ như Kiro, đã chứng minh tiềm năng cách mạng hóa kỹ thuật phần mềm.\nBản demo trực tiếp của Kiro đặc biệt ấn tượng, cho thấy một lời nhắc văn bản đơn giản có thể được chuyển đổi thành một kế hoạch phát triển toàn diện, có thể thực thi như thế nào. Cách tiếp cận này không chỉ tăng tốc độ phát triển mà còn đảm bảo khả năng truy xuất và bảo trì.\nBài học Rút ra Cách tiếp cận có cấu trúc, được con người xác thực của AI-DLC giải quyết các thách thức quan trọng trong phát triển định hướng AI, bao gồm khả năng mở rộng, kiểm soát và chất lượng mã. AI tạo sinh, khi được tích hợp một cách thấu đáo, có thể nâng cao đáng kể năng suất trong khi vẫn duy trì các tiêu chuẩn chất lượng cao. Hình ảnh Sự kiện "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/","title":"Báo cáo thực tập","tags":[],"description":"","content":"Báo cáo thực tập Thông tin sinh viên: Họ và tên: Mai Quốc Anh\nSố điện thoại: 0931823911\nEmail: maiquocanh2608@gmail.com\nTrường: Đại học FPT TP.HCM\nNgành: Kỹ thuật Phần mềm\nCông ty thực tập: Công ty TNHH Amazon Web Services Vietnam\nVị trí thực tập: FCJ Cloud Intern\nThời gian thực tập: Từ ngày 08/09/2025 đến ngày 12/12/2025\nNội dung báo cáo Worklog Proposal Các bài blogs đã dịch Các events đã tham gia Workshop Tự đánh giá Chia sẻ, đóng góp ý kiến "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/","title":"Nhật ký công việc","tags":[],"description":"","content":"Tuần 1: Làm quen với AWS, Thiết lập Tài khoản và Các dịch vụ Cốt lõi (EC2, VPC, IAM)\nTuần 2: EC2 Nâng cao, Chính sách IAM và Host Website Tĩnh với S3 \u0026amp; CloudFront\nTuần 3: VM Import/Export và Ứng dụng Web Sẵn sàng Cao với Auto Scaling \u0026amp; ALB\nTuần 4: CloudWatch Dashboards, Tối ưu hóa Chi phí với Lambda và Di chuyển Cơ sở dữ liệu\nTuần 5: DNS Lai với Route 53 Resolver, AWS Managed AD và Thực hành CLI\nTuần 6: Phạm vi Dự án, Ước tính Chi phí và Nghiên cứu DevSecOps\nTuần 7: Amazon FSx for Windows File Server: Triển khai, Hiệu suất và Hạn ngạch\nTuần 8: Cơ bản về Three.js và Ôn thi Giữa kỳ\nTuần 9: Phân tích Chi phí với Athena/CUR và Điều phối Serverless với Step Functions\nTuần 10: Các mô hình Step Functions Nâng cao và Cảnh báo Bảo mật Đa kênh\nTuần 11: Lambda Cảnh báo Thống nhất (Slack/Telegram/SES) và Quản lý Dự án Ứng phó Sự cố\nTuần 12: Tối ưu hóa Bảng điều khiển Bảo mật S3, Xác thực React và WireGuard VPN\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.1-week1/","title":"Nhật ký Tuần 1","tags":[],"description":"","content":"Mục tiêu Tuần 1: Kết nối với các thành viên và người hướng dẫn FCJ. Tìm hiểu môi trường làm việc văn phòng là như thế nào. Cài đặt Linux, học cách sử dụng Linux đúng cách. Học các kiến thức cơ bản về AWS, console và CLI. Hoàn thành mô-đun thứ nhất và thứ hai. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Xem xét và xác nhận các quy định và hướng dẫn thực tập chính thức. - Tạo tài khoản AWS dựa trên tài liệu. (Xem ID tài khoản, Cập nhật thông tin xác thực tài khoản, Tạo bí danh) - Xác nhận các bước cần thiết để đóng tài khoản của tôi - Hiểu về MFA cho tài khoản (Chọn Virtual MFA để dễ sử dụng) - Hiểu và tạo Nhóm và Người dùng - Đọc phần Hỗ trợ xác thực tài khoản (Tôi không cần làm phần này vì mọi thứ diễn ra suôn sẻ) - Học về những điều cơ bản của AWS Management Console - Biết về các trường hợp hỗ trợ (các loại trường hợp hỗ trợ, cách tạo một trường hợp tốt) - Biết về các loại Ngân sách, các bước để tạo chúng và lợi ích cho từng loại. 08/09/2025 08/09/2025 Setting up an AWS account What is the AWS Management Console? Managing Costs with AWS Budgets Getting Help with AWS Support AWS Service Quotas Compare AWS Support Plans 3 - Cài đặt Hugo và bắt đầu thiết lập\n- Học các nguyên tắc cơ bản về IAM\n+ Tạo và quản lý IAM Groups để tổ chức người dùng\n+ Áp dụng IAM Policies cho các quyền hiệu quả\n+ Quản lý IAM Users thông qua các nhóm để kiểm soát hợp lý\n+ IAM Role để chuyển đổi quyền dễ dàng\n- Bắt đầu với Amazon VPC (Virtual Private Cloud)\n+ Ôn tập Subnets, làm quen với mối quan hệ của nó với AZs (Availability Zone) và các thực tiễn tốt nhất + Học về Route table + Học về IGW (Internet Gateway) và NAT Gateway Học về các nguyên tắc cơ bản của Tường lửa (Security Group, Network ACLs, VPC Resource Map) - Thực hành sau khi học các nguyên tắc cơ bản + Tạo một EC2 instance, NAT Gateway, sử dụng Reachability Analyzer, SSM, CloudWatch 09/09/2025 09/09/2025 AWS Identity and Access Management (IAM) Access Control Amazon VPC and AWS Site-to-Site VPN Workshop 4 - Hoàn thành việc sửa lỗi cho Hugo Bắt đầu với Site to Site VPN + Tạo một VPC cho VPN, tạo một EC2 instance Tạo một Virtual Private Gateway để kết nối với các endpoints, tạo một Customer Gateway, Thiết lập route tables và propagation cho kết nối VPN (EC2 trong trường hợp này) + Cấu hình Customer Gateway (Tôi chọn Libreswan mà không biết Strongswan được khuyến nghị và OpenSwan không còn sử dụng được nữa.) + Dành phần lớn thời gian để gỡ lỗi. 10/09/2025 10/09/2025 Amazon VPC and AWS Site-to-Site VPN Workshop 5 - Hoàn thành gỡ lỗi cấu hình của Customer Gateway (một số lệnh không hoạt động và những lệnh hoạt động nằm trong 5.2.7, sử dụng systemd thay vì service) - Hoàn thành Amazon VPC and AWS Site-to-Site VPN Workshop một cách trọn vẹn - Bắt đầu Lab mới (Introduction to Amazon EC2) + Tạo một Linux VPC, Windows VPC, Security group Linux, Security group Windows + Tạo Windows Instance và kết nối với nó. + Tạo Linux Instance và kết nối với nó. + Học về các nguyên tắc cơ bản của EC2, thay đổi instance type, tạo snapshots, v.v\u0026hellip; + Tạo custom AMIs có và không có sysprep, tạo instances từ các AMIs. + Đối với phần Cách kết nối khi bạn mất keypair, tôi đã tạo một IAM Role với AmazonSSMFullAccess và cập nhật EC2 để có chính sách đó, kiểm tra SSM nhưng tôi không thấy instance, dành một chút thời gian tìm kiếm và vẫn thấy Managed: false, kiểm tra kết nối, kiểm tra SSM Agent logs xem có lỗi không (không có lỗi), khởi động lại dịch vụ SSM bên trong AMI và nó hoạt động sau đó, nó vẫn là Managed: false vì một số lý do + Thay thế keypair qua chỉnh sửa user data thành công cho máy Linux + Cài đặt môi trường desktop cho Ubuntu AMI và nó khởi động thành công 11/09/2025 11/09/2025 Amazon VPC and AWS Site-to-Site VPN Workshop Introduction to Amazon EC2 Create an Amazon EC2 AMI using Windows Sysprep Working with SSM Agent on EC2 instances for Windows Server AWS Systems Manager Parameter Store 6 - Thiết lập một máy chủ web LAMP + Tải xuống Apache, PHP và MariaDB và chạy máy chủ web + Máy chủ chạy đúng dự kiến với tệp PHP + Hoàn thành cấu hình cơ sở dữ liệu + Cài đặt phpMyAdmin, đăng nhập thành công vào trang phpMyAdmin và tạo cơ sở dữ liệu mới sau đó - Cài đặt Node.js trên Linux sử dụng Node Version Manager (nvm) để dễ sử dụng, nó cho phép chúng ta chuyển đổi giữa các phiên bản khác nhau - Triển khai AWS FCJ Management trên EC2 Linux instance thành công - Cài đặt XAMPP và Node.js trên Windows Instance, cấu hình đầy đủ và triển khai chúng 12/09/2025 12/09/2025 Introduction to Amazon EC2 Kết quả đạt được Tuần 1: Đã tạo thành công và bảo mật tài khoản AWS Free Tier với MFA và ngân sách. Nắm vững các nguyên tắc cơ bản của IAM: Nhóm, Người dùng, Chính sách và Vai trò. Xây dựng và bảo mật cơ sở hạ tầng VPC với Subnets, Route Tables, NAT Gateways, Security Groups và NACLs. Thiết lập kết nối Site-to-Site VPN (Libreswan) hoạt động để mô phỏng mạng đám mây lai. Thực hiện các hoạt động EC2 nâng cao: AMIs tùy chỉnh (Sysprep), khôi phục Keypair qua User Data và gỡ lỗi SSM Agent. Triển khai ngăn xếp LAMP và môi trường Node.js trên cả phiên bản EC2 Linux và Windows. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"Xây dựng nền tảng phát sóng dữ liệu thị trường sàn giao dịch hiệu suất cao trên AWS bởi Abhishek Sarolia và Avanish Yadav vào ngày 24/09/2025 trong Amazon ElastiCache, Amazon RDS, AWS Direct Connect, AWS Transit Gateway, Best Practices, Customer Solutions, Database, Networking \u0026amp; Content Delivery, RDS for PostgreSQL | Permalink\nĐây là bài đăng hợp tác cùng Abhishek Chawla, Giám đốc Sản phẩm \u0026amp; Công nghệ; Kartik Manimuthu, Giám đốc Kỹ thuật Đám mây; và Digvijay, Giám đốc Kỹ thuật Ứng dụng tại SMC Global Securities Ltd.\nSMC Global Securities Ltd. (SMC), thành lập năm 1990, là công ty dịch vụ tài chính hàng đầu Ấn Độ cung cấp các dịch vụ giao dịch, tư vấn tài sản và phân phối sản phẩm tài chính cho các nhà đầu tư cá nhân, công ty và khách hàng giàu có.\nSMC Global Securities (SMC) đã hợp tác với Amazon Web Services (AWS) để hiện đại hóa hạ tầng giao dịch bán lẻ của họ. Là một phần của sáng kiến này, SMC đã xây dựng hệ thống phân phối dữ liệu tài chính vững chắc trên AWS xử lý hiệu quả luồng dữ liệu thị trường thời gian thực từ các sàn giao dịch lớn của Ấn Độ (NSE, BSE, MCX và NCDEX). Nền tảng này sử dụng công nghệ mạng Multicast để thu thập và phát sóng dữ liệu giá sàn với hiệu suất và khả năng mở rộng cao.\nNhiều khách hàng AWS vận hành hệ thống tài chính lõi trên đám mây thường xử lý dữ liệu unicast từ hạ tầng on-premises. Điều này thường liên quan đến chuyển đổi nguồn dữ liệu multicast thành unicast trước khi truyền tới AWS qua AWS Direct Connect. Tuy nhiên, việc thu nhận trực tiếp dữ liệu multicast ngoại vi trên AWS đã đưa ra thách thức đối với nhiều tổ chức. Bài viết này trình bày cách SMC tiếp cận đổi mới để vượt qua các trở ngại đó. Chúng tôi trình bày cách SMC dùng hỗ trợ multicast tích hợp của AWS Transit Gateway để liên lạc trong môi trường Amazon Virtual Private Cloud (Amazon VPC), kết hợp với Fortinet SD-WAN cho giải pháp overlay. Thiết lập này cho phép SMC thiết lập các đường hầm Generic Routing Encapsulation (GRE) qua Direct Connect, mang nguồn dữ liệu giá multicast từ hệ thống on-premises của họ trực tiếp vào AWS Cloud.\nAWS Transit Gateway là gì AWS Transit Gateway là một bộ trung chuyển mạng giúp kết nối các VPC và mạng on-premises theo kiểu hub-and-spoke. Nó hỗ trợ nhiều loại kết nối như VPC, thiết bị SD-WAN, cổng Direct Connect, kết nối VPN và các Transit Gateway khác. Điều này loại bỏ nhu cầu kết nối điểm-điểm phức tạp. Một chức năng quan trọng là hỗ trợ multicast native, tự động xử lý định tuyến multicast cho các instance gửi dữ liệu đến nhiều instance nhận thuộc cùng một nhóm multicast.\nThách thức SMC bắt đầu hành trình trên AWS với triết lý cốt lõi là mang lại “trải nghiệm giao dịch nhanh và liền mạch” cho người dùng cuối. Việc có một nền tảng phát sóng có hiệu suất cao là chìa khóa cho trải nghiệm đó. Vì nền tảng phát sóng nhận sự kiện từ sàn giao dịch chứng khoán và gửi đến các trader, nó là thành phần quan trọng của ứng dụng giao dịch bán lẻ hiện đại.\nSMC cần một hệ thống có khả năng cung cấp dữ liệu thị trường tài chính gần như thời gian thực cho trader với mức độ chịu mất gói bằng 0, bởi vì ngay cả một gói lỗi cũng có thể hiển thị thông tin thị trường then chốt sai (như đỉnh giá trong 52 tuần). Điều này có thể gây ra thua lỗ tài chính đáng kể cho trader và ảnh hưởng tới niềm tin của khách hàng. Hạ tầng phát sóng on-premises hiện tại của SMC gặp thách thức về khả năng mở rộng và không đáp ứng được yêu cầu hiệu suất của các ứng dụng giao dịch tài chính hiện đại, khiến downtime thường xuyên và giảm hiệu suất.\nTổng quan giải pháp Các tổ chức cần kết nối mạng hybrid để liên kết liền mạch các trung tâm dữ liệu on-premises, địa điểm từ xa và hạ tầng cloud. AWS cung cấp các tùy chọn kết nối cho các kiến trúc hybrid như Direct Connect và Site-to-Site VPN, để kết nối tài nguyên on-premises lên AWS an toàn.\nSMC hoạt động trong lĩnh vực tài chính có quy định khắt khe, nên khi bắt đầu thiết kế nền tảng broadcast tài chính lai trên AWS Cloud, họ xác định bốn mục tiêu chính:\nKhả năng mở rộng Độ tin cậy Hiệu suất Bảo mật Để đạt các mục tiêu này ở quy mô lớn, SMC sử dụng AWS Control Tower để thiết lập workloads trên AWS. AWS Control Tower cung cấp cách rõ ràng và hiệu quả để này và quản trị môi trường AWS đa tài khoản an toàn. Nó tạo ra landing zone dựa trên best-practices và quản trị thông qua các controls từ danh mục có sẵn. Landing zone là nền tảng đa tài khoản theo chuẩn well-architected, tuân theo best-practices của AWS.\nCác cân nhắc thiết kế Đáp ứng yêu cầu từ các sàn truyền thống phải kết thúc kết nối mạng dữ liệu giá tại địa điểm on-premises, SMC đánh giá hai phương án kiến trúc:\nKết thúc nguồn dữ liệu multicast tại trung tâm dữ liệu, chuyển đổi thành unicast và chuyển giải pháp phát sóng hiện tại lên AWS. Cách này nhanh hơn nhưng mang theo các hạn chế giải pháp cũ lên cloud. Kết thúc nguồn dữ liệu multicast tại trung tâm dữ liệu và gửi trực tiếp nguồn multicast lên AWS. Cách này cho phép thiết kế lại hệ broadcast bằng các dịch vụ AWS native. Sau khi cân nhắc, SMC quyết định kiến trúc lại hoàn toàn hệ thống trên AWS. Quyết định chiến lược này dựa vào hai mục tiêu:\nXây dựng kiến trúc sẵn sàng cho tương lai Tối đa hóa hiệu quả với các dịch vụ AWS native Để đạt các mục tiêu, nền tảng tuân thủ một số nguyên tắc cốt lõi:\nƯu tiên tính mới của sự kiện hơn sự đầy đủ\nVì hiệu suất và tính thực tiễn, hệ thống sẽ loại bỏ các sự kiện cũ. Ví dụ, giá giao dịch cuối cùng (LTP) của mã chứng khoán XYZ là 100, 101, 102 lần lượt tại T1, T2, T3, thì hệ thống có thể loại bỏ giá 100 và 101 để hiển thị trực tiếp giá 102. Người dùng chủ yếu quan tâm đến giá hiện tại hơn các giá cũ khi kiểm tra LTP.\nHình 1 – Giá giao dịch cuối cùng\nTuy nhiên, giá trị lịch sử rất là quan trọng cho việc phân tích như đỉnh/thấp trong 12 tuần, 52 tuần, hoặc xem danh sách tổng hợp lệnh.\nHình 2 – Danh sách giá từ cao xuống thấp\nVì vậy, giải pháp cần một chế độ thời gian thực cho dữ liệu giá mới nhất và cơ chế đối chiếu dữ liệu đã loại bỏ/lỗi qua path khác. Để đáp ứng, hệ thống ghi nhận và đối chiếu thời gian thực bằng microservices độc lập và có khả năng mở rộng trên cụm Amazon Elastic Container Service (Amazon ECS), sử dụng dịch vụ AWS native để xử lý:\nAmazon ElastiCache để cache và phản chiếu packet dữ liệu ghi nhận mới nhất, truy xuất nhanh Amazon RDS PostgreSQL cho lưu trữ dài hạn và đối chiếu batch Hình 3 – Ghi lại và đối chiếu giá\nXử lý đa luồng cho throughput cao\nDo khối lượng dữ liệu thị trường lớn, hệ thống xử lý đa luồng trên tất cả các phần. Để hạn chế mất packet do giới hạn băng thông mạng, thiết lập nhiều kết nối TCP ở các port khác nhau trên mỗi instance để truyền dữ liệu song song.\nMột thách thức là đảm bảo thứ tự xử lý đúng. Nếu XYZ được update hai lần một giây—M1 (giá lên 100) và M2 (giá lên 101) —mà M2 xử lý trước M1 sẽ gây lỗi lớn. Để xử lý, hệ thống thêm thành phần thời gian tùy biến (custom chronological component) trước khi dữ liệu trả về giao diện người dùng.\nHình 4 – Sắp xếp dữ liệu theo thứ tự thời gian\nQuản lý kết nối WebSocket ở quy mô lớn\nCông nghệ WebSocket cho phép giao tiếp hai chiều, thời gian thực giữa máy khách và máy chủ, làm cho nó trở nên lý tưởng để phát sóng dữ liệu thị trường đến giao diện web và di động. Không giống như các yêu cầu HTTP truyền thống, các kết nối WebSocket:\nDuy trì kết nối liên tục, giảm latency Giảm tải mạng khi loại bỏ handshake lặp lại Cho phép cập nhật đẩy từ máy chủ (server-push), điều này rất quan trọng đối với việc phân phối dữ liệu thị trường theo thời gian thực Giảm tải máy chủ so với các phương pháp dựa trên thăm dò (polling-based) SMC đã triển khai các kết nối WebSocket chạy trên các cụm ECS để sử dụng những lợi ích này trên các giao diện ứng dụng web và di động của họ. Tuy nhiên, việc vận hành các hệ thống dựa trên WebSocket ở quy mô lớn đặt ra những thách thức:\n1. Thách thức về quản lý kết nối\nKhi thiết lập, các client WebSocket duy trì kết nối với các instance server cụ thể. Điều này làm phức tạp quá trình cân bằng tải truyền thống, đặc biệt khi scaling ECS container vì các kết nối hiện tại không dễ chia lại sang các instance mới do trạng thái của chúng.\n2. Thách thức về “bầy đàn” (thundering herd) của WebSocket\nTrong giờ thị trường, hàng nghìn nhà giao dịch đồng thời cố gắng thiết lập các kết nối WebSocket, đặc biệt là vào thời điểm mở cửa thị trường hoặc sau khi bảo trì hệ thống. Hiệu ứng \u0026ldquo;thundering herd\u0026rdquo; này có thể làm quá tải máy chủ và dẫn đến lỗi kết nối. Hơn nữa, khi các container được thay thế trong các sự kiện mở rộng quy mô, nhiều máy khách cố gắng kết nối lại đồng thời có thể tạo ra căng thẳng tương tự trên hệ thống.\nĐể giải quyết những thách thức này, một chiến lược quản lý kết nối toàn diện đã được triển khai. Điều này bao gồm mở rộng quy mô dựa trên kết nối thông qua các báo động Amazon CloudWatch tùy chỉnh và kết nối lại máy khách theo cấp số nhân (staggered client reconnections) bằng cách sử dụng exponential backoff and jitter. Để có khả năng mở rộng dài hạn, nhóm cũng đánh giá các cách tiếp cận thay thế như quản lý trạng thái bên ngoài bằng cách sử dụng ElastiCache để lưu trữ trạng thái kết nối cho các chuyển đổi máy khách liền mạch giữa các container và mở rộng quy mô dần với các khoảng thời gian được kiểm soát để ngăn chặn sự gia tăng đột biến của kết nối.\nĐộ ổn định sản xuất \u0026amp; quan sát\nĐể đảm bảo độ tin cậy của hệ thống phát sóng, SMC đã triển khai một công cụ tùy chỉnh sử dụng LGTM stack để giám sát và quan sát toàn diện, kết hợp bốn công cụ chính: Loki cho nhật ký, Grafana để trực quan hóa, Tempo để theo dõi và Mimir for metrics. cho các số liệu. Điều này được tích hợp với một hệ thống thông báo và quản lý sự cố tập trung bằng cách sử dụng AWS Systems Manager Incident Manager để nhanh chóng giảm thiểu và phục hồi từ các sự cố ảnh hưởng đến các ứng dụng được lưu trữ trên AWS.\nHình 5 – Trình quản lý sự cố tích hợp\nKiến trúc giải pháp Kiến trúc tham chiếu cấp cao sau đây cho thấy cách SMC triển khai nền tảng phát sóng của họ. AWS Transit Gateway đóng một vai trò quan trọng trong kiến trúc này bằng cách đóng vai trò là bộ định tuyến đám mây giúp hợp lý hóa cấu trúc liên kết mạng, đồng thời cho phép định tuyến multicast trên nhiều VPC. Nó tập trung hóa khả năng kết nối giữa các VPC và mạng on-premises, đồng thời hỗ trợ các kết nối băng thông cao, độ trễ thấp.\nViệc sử dụng AWS Transit Gateway đã cho phép SMC mở rộng mạng của họ khi họ thêm các VPC hoặc địa điểm on-premises mới, thực hiện các chính sách mạng nhất quán trên tất cả các mạng được đính kèm và giảm số lượng điểm kết nối cần thiết để kết nối nhiều VPC và mạng on-premises.\nSMC đã sử dụng Fortinet Firewall để thu nạp dữ liệu multicast qua các đường hầm GRE trong Amazon VPC. Họ đã tích hợp FortiGate SD-WAN Hub của họ với AWS Transit Gateway để thiết lập kết nối an toàn, hiệu suất cao giữa môi trường on-premises và AWS, cho phép phân phối hiệu quả các nguồn cấp dữ liệu thị trường multicast trên nhiều VPC, hợp lý hóa việc quản lý các kiến trúc mạng phức tạp và giảm chi phí vận hành trong việc quản lý mạng đa VPC.\nCách định cấu hình FortiGate SD-WAN nằm ngoài phạm vi thảo luận của bài đăng này, nhưng có thể kiểm tra chi tiết đầy đủ tại đây.\nHình 6 – Kiến trúc hệ thống phát sóng\nSolution Outcome Hệ thống mới được thiết kế của SMC trong AWS hiện có thể xử lý hàng chục nghìn người dùng đồng thời. Nó có thể xử lý hơn 100K tin nhắn mỗi giây từ nhiều sàn giao dịch chứng khoán với thời gian ngừng hoạt động bằng không. AWS cho phép SMC mở rộng quy mô nền tảng của họ để đáp ứng nhu cầu kinh doanh gia tăng trong giờ cao điểm, dẫn đến hiệu suất tốt hơn và độ trễ thấp hơn (cải thiện khoảng 60%) và thu nhỏ quy mô liền mạch sau giờ làm việc để tiết kiệm chi phí.\nHình 7 – Các chỉ số độ trễ hệ thống\nKết luận Hành trình của SMC từ nền tảng phát sóng on-premises sang nền tảng cloud-native là một ví dụ điển hình về cách các tổ chức tài chính có thể vượt qua các giới hạn cơ sở hạ tầng truyền thống thông qua việc áp dụng AWS một cách chiến lược. Sự chuyển đổi đòi hỏi những quyết định kiến trúc táo bạo—chọn tái kiến trúc thay vì di chuyển—và chứng minh rằng với việc lập kế hoạch cẩn thận, các dịch vụ AWS phù hợp và cam kết hiện đại hóa, các công ty dịch vụ tài chính có thể xây dựng cơ sở hạ tầng đáp ứng các yêu cầu khắt khe ngày nay đồng thời mở rộng quy mô cho các cơ hội ngày mai.\nTại SMC Global Securities (và Stoxkart), hành trình chuyển đổi kỹ thuật số của chúng tôi với AWS đã tăng cường đáng kể tính ổn định, hiệu suất và sự linh hoạt trong hoạt động của nền tảng. Việc di chuyển từ on-premises lên đám mây đã loại bỏ nhu cầu mở rộng quy mô, vá lỗi và nâng cấp cơ sở hạ tầng thủ công—giải phóng các nhóm của chúng tôi để tập trung vào đổi mới. Với khả năng kiểm soát, khả năng hiển thị được cải thiện và khả năng tự động mở rộng quy mô trong giờ giao dịch cao điểm, chúng tôi đã xây dựng một hệ sinh thái môi giới kiên cường, sẵn sàng cho tương lai, mang lại trải nghiệm liền mạch cho khách hàng của chúng tôi.\n– Abhishek Chawla (SMC , CTO)\nVề các tác giả﻿ Abhishek Sarolia Abhishek Sarolia là Kiến trúc sư Giải pháp cấp cao tại AWS. Anh làm việc với người dùng AWS để giải quyết các thách thức kinh doanh của họ bằng cách thiết kế các giải pháp an toàn, hiệu suất cao và khả năng mở rộng sử dụng các công nghệ điện toán đám mây mới nhất. Anh có niềm đam mê với công nghệ và thích xây dựng, thử nghiệm các dự án về AI/ML và IoT. Ngoài công việc, anh yêu thích du lịch, đọc sách phi hư cấu và dành thời gian cho gia đình.\nAbhishek Chawla (Khách mời) Abhishek Chawla là Giám đốc Sản phẩm và Công nghệ Tập đoàn (CPTO) tại SMC Global Securities, nơi anh lãnh đạo chiến lược công nghệ và sản phẩm cho nhiều đơn vị kinh doanh như môi giới dịch vụ đầy đủ (SMC), môi giới môi giới chiết khấu (Stoxkart), quản lý tài sản và phân phối. Với gần hai thập kỷ kinh nghiệm trong các lĩnh vực fintech, edtech, chăm sóc sức khỏe, và du lịch, Abhishek đã thúc đẩy những chuyển đổi kỹ thuật số quy mô lớn bằng cách hiện đại hóa hạ tầng, xây dựng nền tảng cloud-native và mở rộng các nhóm kỹ thuật hiệu suất cao. Anh làm việc chặt chẽ với các CEO để đảm bảo các sáng kiến công nghệ phù hợp với mục tiêu kinh doanh, tạo ra tác động đo lường được thông qua đổi mới, hiệu quả và lấy khách hàng làm trọng tâm.\nKartik Manimuthu (Khách mời) Kartik Manimuthu là Giám đốc Kỹ thuật Đám mây tại SMC Global Securities. Với niềm đam mê giải quyết các bài toán kinh doanh phức tạp bằng công nghệ, anh dẫn dắt nhóm kỹ thuật thiết kế các giải pháp sáng tạo, vững chắc giúp thúc đẩy chuyển đổi số của công ty. Kartik chuyên về chuyển đổi lên cloud, hiện đại hóa hạ tầng doanh nghiệp và xây dựng nền tảng có thể mở rộng phù hợp với mục tiêu kinh doanh. Ngoài văn phòng, anh thích khám phá công nghệ mới và đọc sách.\nDigvijay (Khách mời) Digvijay là Giám đốc Kỹ thuật tại SMC, một công ty môi giới hàng đầu, nơi anh đã dẫn dắt chiến lược công nghệ và đổi mới sản phẩm trong hai năm qua. Với hơn 10 năm kinh nghiệm trong ngành phần mềm, Digvijay có chuyên môn sâu về xây dựng hệ thống có khả năng mở rộng và lãnh đạo các nhóm kỹ thuật hiệu suất cao. Trước khi gia nhập SMC, Digvijay từng giữ các vị trí kỹ thuật chủ chốt tại Microsoft và Expedia, đóng góp vào các nền tảng lớn phục vụ khách hàng. Quản lý của anh kết hợp nền tảng kỹ thuật vững chắc với hiểu biết sâu về ngành dịch vụ tài chính.\nAvanish Yadav Avanish Yadav là Kiến trúc sư Giải pháp Mạng cấp cao tại AWS. Với niềm đam mê về công nghệ mạng, anh thích sáng tạo và hỗ trợ người dùng giải quyết các vấn đề kỹ thuật phức tạp bằng cách xây dựng các kiến trúc điện toán đám mây an toàn, khả năng mở rộng. Khi không cộng tác với người dùng để cung cấp giải pháp chuyên sâu, anh thường chơi cricket bên ngoài công việc. LinkedIn: /avanish-yadav-93b8a947/.\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Optimize security operations with AWS Security Incident Response bởi Kyle Shields và Matt Meck vào ngày 23/09/2005 trong Best Practices, Customer Solutions, Security, Identity, \u0026amp; Compliance, Technical How-to | Permalink | Comments\nCác mối đe dọa bảo mật yêu cầu hành động nhanh chóng, đó là lý do AWS Security Incident Response cung cấp bảo vệ gốc AWS có thể ngay lập tức củng cố tư thế bảo mật của bạn. Giải pháp toàn diện này kết hợp logic tự động phân loại và đánh giá với metadata chu vi bảo mật của bạn để xác định các vấn đề quan trọng, liền mạch bổ sung chuyên môn con người khi cần. Khi Security Incident Response được tích hợp với Amazon GuardDuty và AWS Security Hub trong một môi trường bảo mật hợp nhất, tổ chức có quyền truy cập 24/7 vào AWS Customer Incident Response Team (CIRT) để phát hiện nhanh chóng, phân tích chuyên môn, và ngăn chặn đe dọa hiệu quả—quản lý qua một bảng điều khiển trực quan. Security Incident Response bao gồm trong Amazon Managed Services (AMS), giúp tổ chức áp dụng và vận hành AWS ở quy mô lớn một cách hiệu quả và an toàn.\nTrong bài này, chúng tôi hướng dẫn bạn kích hoạt Security Incident Response và thực hiện bằng chứng khái niệm (POC) để nhanh chóng nâng cao khả năng bảo mật khi nhận lợi ích ngay lập tức. Chúng tôi khám phá chức năng dịch vụ, thiết lập tiêu chí thành công POC, xác định cấu hình, chuẩn bị triển khai, kích hoạt dịch vụ và tối ưu hiệu quả từ ngày đầu tiên, giúp tổ chức bạn xây dựng niềm tin trong suốt vòng đời phản ứng sự cố đồng thời cải thiện thời gian phục hồi.\nHiểu chức năng của Security Incident Response Dịch vụ AWS Security Incident Response cung cấp khả năng phát hiện và phản ứng mối đe dọa toàn diện thông qua quy trình bốn bước hợp lý. Nó bắt đầu bằng việc lấy các phát hiện bảo mật từ GuardDuty và các tích hợp Security Hub được chọn với công cụ bên thứ ba. Dịch vụ tự động phân loại các phát hiện này bằng metadata khách hàng và tình báo đe dọa để xác định hành vi bất thường và hoạt động nghi ngờ. Khi phát hiện mối đe dọa tiềm ẩn, thành viên CIRT chủ động điều tra các trường hợp qua portal khách hàng để xác định đó là tích cực thật hay giả. Với các mối đe dọa được xác nhận, dịch vụ leo thang các phát hiện để hành động ngay lập tức, trong khi với tích cực giả sẽ cập nhật hệ thống phân loại tự động và quy tắc triệt tiêu cho GuardDuty và Security Hub, liên tục cải thiện độ chính xác phát hiện.\nBảo vệ toàn diện với ít điều kiện tiên quyết Security Incident Response mang lại năng lực bảo mật mạnh mẽ nhờ tích hợp liền mạch với cả hệ thống phát hiện và phản ứng sự cố AWS (TDIR) và dịch vụ bảo mật bên thứ ba như CrowdStrike, Lacework, TrendMicro. Giải pháp này cung cấp trung tâm chỉ huy thống nhất để quản lý sự cố đầu-cuối—từ lập kế hoạch, giao tiếp đến giải quyết—khi lấy các phát hiện GuardDuty và tích hợp với nhà cung cấp ngoài qua Security Hub. Với quản lý case an toàn cùng timeline hoạt động bất biến, nó nâng cao đáng kể hoạt động bảo mật khi tăng cường các đội SOC và phản ứng sự cố (IR) bằng khả năng hiển thị tốt hơn cũng như quyền truy cập vào các công cụ và nhân sự đã kiểm chứng từ AWS. CIRT AWS cộng tác với đội ứng phó của bạn trong truy vết và phục hồi, giải phóng nguồn lực có giá trị cho các ưu tiên khác.\nDịch vụ cung cấp giá trị liên tục qua khả năng giám sát và phản ứng chủ động. Nó liên tục giám sát môi trường của bạn bằng các phát hiện từ GuardDuty và Security Hub, với tự động hóa dịch vụ, phân loại và phân tích làm việc âm thầm để cảnh báo bạn chỉ trong trường hợp có mối bận tâm bảo mật thực sự. Bảo vệ này mang lại giá trị tức thì lúc xảy ra sự cố tiềm năng mà không đòi hỏi bạn phải chú ý liên tục.\nBắt đầu rất đơn giản—điều kiện duy nhất là bật AWS Organizations và bảo đảm rằng bạn đã thiết lập Organizations với cấu trúc đơn vị tổ chức (OU) cơ bản gồm các tài khoản thành viên. Nền tảng này vừa cho phép triển khai Security Incident Response, vừa là nền tảng vững chắc cho chiến lược TDIR mạnh ở toàn tổ chức.\nXác định tiêu chí thành công Thiết lập tiêu chí thành công giúp so sánh kết quả POC với mục tiêu kinh doanh. Một số ví dụ:\nChỉ định đội phản ứng sự cố: Xác định và ghi chép thành viên đội nội bộ cũng như nguồn lực ngoài chịu trách nhiệm phản ứng sự cố. Như nhấn mạnh trong AWS Well-Architected Security Pillar, có nhân sự chỉ định sẽ giảm thời gian phân loại và phản ứng khi sự cố xảy ra. Phát triển framework phản ứng sự cố chính thức: Xây dựng kế hoạch phản ứng sự cố toàn diện với playbook chi tiết cùng quy trình tập luyện tabletop thường xuyên. AWS cung cấp thư viện playbook tham khảo trên GitHub. Chạy bài tập tabletop: Xem xét thực hiện mô phỏng thường xuyên để kiểm tra kế hoạch phản ứng sự cố, phát hiện lỗ hổng, xây dựng “bản năng hành động” cho đội trước khi khủng hoảng thực sự xảy ra. AWS cung cấp ngữ cảnh về các loại bài tập tabletop. Xác định các nhà cung cấp bảo mật bên thứ ba hiện có: Xác định nhà cung cấp tích hợp Security Hub đẩy dữ liệu vào Security Incident Response. Đối tác AWS cung cấp phát hiện như tài liệu ở Detect and Analyze. Triển khai GuardDuty: Cấu hình GuardDuty theo thực hành tốt nhất để giám sát—phát hiện đe dọa trên dịch vụ trọng yếu. AWS duy trì thực hành tốt nhất GuardDuty tại AWS Security Services Best Practices for GuardDuty. Kiểm tra tiêu chí thành công của bạn để đảm bảo mục tiêu thực tế với thời gian cũng như ràng buộc đặc thù tổ chức. Ví dụ: Bạn có kiểm soát hoàn toàn cấu hình dịch vụ AWS không? Có nguồn lực có thể dành thời gian thực thi và kiểm tra không? Thời điểm này có thuận tiện để các bên liên quan đánh giá dịch vụ không?\nĐịnh nghĩa cấu hình Security Incident Response Sau khi xác định tiêu chí và thời gian, bạn nên định nghĩa cấu hình Security Incident Response. Một số quyết định quan trọng gồm:\nChọn tài khoản quản trị viên được ủy quyền: Xác định tài khoản làm quản trị viên được ủy quyền (DA). Tài khoản này và AWS Region đã chọn sẽ lưu trữ dịch vụ và portal Security Incident Response. AWS Security Reference Architecture (SRA) đề nghị dùng tài khoản công cụ bảo mật chuyên biệt. Xem các lưu ý nên cân nhắc trước khi chốt DA. Định nghĩa phạm vi tài khoản: Security Incident Response là dịch vụ cấp tổ chức. Mỗi tài khoản ở mọi Region trong tổ chức đều nằm trong bảo hiểm dưới một đăng ký duy nhất. Bảo hiểm tự động điều chỉnh khi thêm/xóa tài khoản, bảo vệ toàn diện AWS footprint. Cấu hình nguồn phát hiện: Xác định các phát hiện đáp ứng nhu cầu tổ chức. Dịch vụ mặc định lấy phát hiện GuardDuty toàn tổ chức và một số loại phát hiện Security Hub từ đối tác bên thứ ba. Đánh giá kế hoạch bảo vệ GuardDuty và phát hiện Security Hub hữu ích nhất cho tư thế bảo mật, khả năng phản ứng sự cố của bạn. Xây dựng framework leo thang: Thiết lập ngưỡng leo thang rõ ràng cho từng loại trường hợp: tự quản lý, có hỗ trợ AWS, chủ động. Ai có quyền xác định gửi loại case nào dựa trên mức độ nghiêm trọng, tác động, yêu cầu nguồn lực. Triển khai chiến lược phân tích: Xác định dùng công cụ phân tích AWS gốc như Amazon Athena, Amazon OpenSearch, và Amazon Detective), hoặc tích hợp SIEM (security information and event management) hiện có. Chức năng này làm giàu phản ứng sự cố với dữ liệu bối cảnh, hiểu biết sâu hơn. Chuẩn bị triển khai Sau khi xác định tiêu chí, cấu hình, bạn xác định các bên liên quan, trạng thái và thời gian mong muốn. Chuẩn bị triển khai bằng cách:\nKế hoạch dự án, timeline: Xây dựng kế hoạch, tiêu chí thành công, phạm vi, mốc chính, thời gian triển khai thực tế. Đề xuất dòng thời gian: Trước khi bật: Cấu hình GuardDuty, các bên thứ ba Security Hub, lên kế hoạch tài nguyên Xin phê duyệt thử nghiệm POC từ đội tài khoản AWS hay đội Dịch vụ Ngày 0 – Bật dịch vụ Tuần 1 – Mở các case CIRT phản ứng Tuần 2 – Kết nối công cụ ITSM Tuần 3 – Tập luyện tabletop Tuần 4 – Rà soát báo cáo CIRT cung cấp Xác định các bên liên quan: CISO, nhóm bảo mật thông tin, SOC, đội phản ứng sự cố, kỹ sư bảo mật, tài chính, pháp lý, tuân thủ, MSSP ngoài, đại diện business unit. Phát triển ma trận RACI: Vẽ biểu đồ RACI xác định vai trò, trách nhiệm, tạo thuận lợi cho trách nhiệm giải trình, kênh giao tiếp phù hợp. Cấu hình quyền truy cập tài khoản quản lý: Đảm bảo ủy quyền để phân quyền quản trị. Xem thêm Permissions required to designate a delegated Security Incident Response administrator account. Thiết lập vai trò IAM/quyền: Dùng AWS Identity and Access Management (IAM) để áp dụng kiểm soát truy cập dựa trên vai trò (kết nối RACI chart), gồm quản lý case, leo thang, vai trò chỉ đọc sử dụng chính sách quản lý AWS. Chi tiết ở AWS Managed Policies Kích hoạt Security Incident Response Khi chuẩn bị xong, bạn đã sẵn sàng bật dịch vụ.\nTruy cập Security Incident Response trong tài khoản quản lý:\nVào tài khoản quản lý tổ chức, truy cập AWS Management Console, tìm Security Incident Response trên thanh tìm kiếm. Chọn Sign up. Đảm bảo đã chọn Use delegated administrator account (khuyên dùng), nhập số tài khoản quản trị vào trường Account ID, chọn Next. Đăng nhập vào tài khoản quản trị được ủy quyền đã cấu hình ở bước 3, tìm Security Incident Response rồi chọn Sign up. Hoàn thành thiết lập ở tài khoản quản trị viên được ủy quyền:\nĐịnh nghĩa chi tiết thành viên: Chọn vùng nhà của bạn dưới Region selection. Đối với Membership name, nhập một tên phù hợp tuân theo tiêu chuẩn đặt tên của tổ chức bạn. Dưới Membership contacts, nhập thông tin Primary và Secondary contact. Thêm Membership tags theo chiến lược gắn thẻ của tổ chức bạn. Chọn Next. Cấu hình quyền cho phản ứng chủ động: Service permissions for proactive response đã được kích hoạt, nhưng bạn có thể vô hiệu hóa tính năng này nếu cần. Chọn By choosing this option… và chọn Next. Xem xét quyền dịch vụ và chọn Next. Xem xét cấu hình thành viên và chi tiết, sau đó chọn Sign up. Vai trò liên kết dịch vụ được tạo với phản ứng chủ động không thể được tạo trong tài khoản quản lý thông qua quy trình lên tàu này. Xem AWS Security Incident Response User Guide để triển khai vai trò liên kết dịch vụ đến tài khoản quản lý. Xem hướng dẫn chi tiết ở video hướng dẫn thiết lập trên YouTube..\nNhiều tổ chức có các quy trình và bộ ứng dụng được thiết lập tốt cho IR và quản lý mối đe dọa bảo mật. Để phù hợp với các thiết lập có sẵn này, AWS đã phát triển các tích hợp với các ứng dụng ITSM và quản lý trường hợp phổ biến. Các bản phát hành ban đầu của chúng tôi cho phép tích hợp hai chiều hoàn toàn với cả Jira và ServiceNow, với nhiều hơn nữa đang trên đường.\nChúng tôi đã cung cấp hướng dẫn đầy đủ quy trình thiết lập tại GitHub.\nTối ưu hóa giá trị từ ngày đầu tiên Ngay sau khi kích hoạt dịch vụ, Security Incident Response bắt đầu thu thập các phát hiện GuardDuty và Security Hub (từ các đối tác bảo mật) của bạn. Các phát hiện của bạn được tự động phân loại và giám sát bằng cách sử dụng logic đánh giá xác định; dựa trên metadata độc đáo của tổ chức bạn và chu vi bảo mật, các mối đe dọa có mức độ ưu tiên cao được leo thang đến trung tâm chỉ huy Security Incident Response của bạn để điều tra ngay lập tức. Trong khi tổ chức của bạn nhận được bảo hiểm 24/7 từ đầu, việc thực hiện các tối ưu hóa được khuyến nghị này sẽ tăng cường đáng kể độ chính xác phát hiện mối đe dọa, giảm tích cực giả, tăng tốc thời gian phản ứng và tăng cường tư thế bảo mật tổng thể của bạn thông qua bảo vệ tùy chỉnh được căn chỉnh với rủi ro kinh doanh cụ thể và yêu cầu tuân thủ của bạn.\nĐể tối đa hóa giá trị ngay lập tức từ Security Incident Response, chúng tôi đề xuất sử dụng khả năng phản ứng của nó bắt đầu từ ngày một. Khi đội của bạn gặp phải hoạt động đáng ngờ hoặc yêu cầu điều tra chuyên môn, bạn có thể tạo một trường hợp được AWS hỗ trợ thông qua cổng thông tin dịch vụ để tương tác trực tiếp với các chuyên gia AWS CIRT. Các chuyên gia bảo mật này một cách hiệu quả mở rộng khả năng của đội bạn, cung cấp kiến thức chuyên môn và hướng dẫn để giúp bạn nhanh chóng hiểu, ngăn chặn và khắc phục các mối quan tâm bảo mật tiềm ẩn. Quyền truy cập theo yêu cầu này vào AWS CIRT có thể giảm thời gian giải quyết trung bình của bạn, giảm thiểu tác động tiềm ẩn và đảm bảo bạn có hỗ trợ chuyên nghiệp ngay cả đối với các kịch bản bảo mật phức tạp có thể khác làm choáng ngợp tài nguyên nội bộ.\nVí dụ truy vấn hỗ trợ phản ứng:\nPhát hiện IP đáng ngờ trong môi trường, thực hiện các API call đa dạng. Bạn hỗ trợ điều tra được không? Tài khoản mới tạo 2 ngày trước, được thông báo qua quy tắc Amazon EventBridge và tích hợp endpoint detection response (EDR), bạn giúp xác định phạm vi, tìm ai tạo? Tạo bằng cách nào? Người dùng AWS Identity and Access Management (IAM) thực hiện API call xuyên Region, tạo resource ở Region không dùng. Giải pháp EDR phát hiện hành vi bất thường trên website production, cho thấy vi phạm tiềm tàng. EDR phát hiện tải web-shell nghi ngờ và hoạt động – cần giúp điều tra, cô lập. Người dùng trái phép thực hiện API ngoài quyền hạn—hỗ trợ phát hiện leo thang quyền. Cần giúp phân tích log bảo mật từ AWS WAF và Amazon Elastic Compute Cloud (Amazon EC2) instances. Có chỉ số compromise hoặc mẫu lạ không? Các bước tiếp theo Nếu bạn quyết định tiến hành với AWS Security Incident Response và triển khai một POC, chúng tôi khuyến nghị các mục hành động sau:\nXác định xem bạn có phê duyệt và ngân sách để sử dụng Security Incident Response không. Các thỏa thuận giá ưu đãi, giảm giá và thử nghiệm dựa trên hiệu suất có sẵn. Cấu hình và triển khai GuardDuty để giúp duy trì bảo hiểm toàn diện và có liên quan trên các tài khoản quản lý và thành viên, dịch vụ quan trọng và workload của bạn. Xác minh rằng các công cụ bảo mật bên thứ ba (như CrowdStrike, Lacework hoặc Trend Micro) được tích hợp đúng cách với Security Hub. Giao tiếp các thay đổi công cụ phản ứng sự cố bảo mật với các đội tổ chức có liên quan. Kết luận Trong bài viết này, chúng tôi đã chỉ cho bạn cách lập kế hoạch và thực hiện một POC AWS Security Incident Response. Bạn đã học cách làm như vậy thông qua các giai đoạn, bao gồm xác định tiêu chí thành công, cấu hình Security Incident Response và xác thực rằng Security Incident Response đáp ứng nhu cầu kinh doanh của bạn.\nLà một khách hàng, hướng dẫn này sẽ giúp bạn chạy một POC thành công với Security Incident Response. Nó hướng dẫn bạn đánh giá giá trị và các yếu tố để xem xét khi quyết định thực hiện các tính năng hiện tại.\nTài nguyên bổ sung Security Incident Response – Getting Started Guide Configuring security tool integrations through Security Hub Managing Security Incident Response events with Amazon EventBridge Amazon GuardDuty best practices AWS Security Hub best practices AWS Security Incident Response Technical Guide (best practices) AWS Managed Services Offering AWS Security Incident Response Blog: The customer’s journey to accelerating the incident Response lifecycle Nếu có phản hồi về bài này, gửi bình luận ở Comments. Nếu có câu hỏi về bài này, hãy liên hệ AWS Support.\nKyle Shields\nKyle là Kiến trúc sư Giải pháp Chuyên gia Bảo mật tập trung phát hiện mối đe dọa và phản ứng sự cố tại AWS. Hiện nay, anh giúp khách hàng doanh nghiệp AWS vận hành Security Incident Response, cải thiện tư thế bảo mật.\nMatt Meck\nMatt là chuyên gia bảo mật WW với 10 năm kinh nghiệm trong công nghệ AI, an ninh mạng, 3 năm tại AWS về Lĩnh vực Detection \u0026amp; Response. Đặt ở NY, yêu thích thiên nhiên, anh dành thời gian chơi bóng đá, trượt tuyết, chinh phục các đỉnh núi mới.\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"Giải phóng giá trị dữ liệu phi cấu trúc với Amazon Bedrock Data Automation bởi Vani Eswarappa và Rupesh Mishra vào ngày 29/09/2025 trong Amazon Bedrock Knowledge Bases, Amazon Comprehend, Amazon DataZone, Amazon EventBridge, Amazon OpenSearch Service, Amazon Rekognition, Amazon Simple Storage Service (S3), Amazon Textract, AWS Glue, AWS Lambda, AWS Marketplace, Healthcare, Industries | Permalink\nCác tổ chức trong mọi ngành đang gặp khó khăn với sự gia tăng dữ liệu phi cấu trúc—hình ảnh, tài liệu văn bản, PDF, tệp âm thanh \u0026amp; video, và các định dạng chuyên biệt như chuỗi gen. Khác với dữ liệu có cấu trúc, dữ liệu phi cấu trúc thường thiếu tổ chức chuẩn hóa, khiến việc phát hiện, truy cập, và khai phá ý nghĩa từ nguồn dữ liệu giá trị này trở nên khó khăn.a\nTại Amazon Web Services (AWS), chúng tôi ghi nhận những khó khăn tương tự ở các viện nghiên cứu và các tổ chức y tế khi tìm giải pháp lưu trữ, tìm kiếm và khai thác kho dữ liệu phi cấu trúc của mình.\nChúng tôi sẽ khám phá cách giải pháp sử dụng Amazon Bedrock Data Automation, một tính năng của Amazon Bedrock, có thể mang lại:\nGiải pháp tổng thể để quản lý dữ liệu phi cấu trúc Tự động hóa quá trình lưu trữ dữ liệu Cải thiện chất lượng dữ liệu Triển khai chính sách quản trị Truy cập nhanh các sản phẩm dữ liệu giá trị Chúng tôi cũng làm rõ cách AWS và giải pháp đối tác giúp xử lý khử định danh (de-identification) cho dữ liệu phi cấu trúc, bằng cách làm mờ hoặc xóa thông tin nhận diện khỏi văn bản, PDF, hình ảnh và tài liệu khác. Và vì khử định danh đôi khi cần thiết cho phát triển AI, nghiên cứu, chính sách công và các ứng dụng khác.\nThách thức quản lý dữ liệu phi cấu trúc Khách hàng các ngành chia sẻ những thách thức cơ bản liên quan đến tổ chức dữ liệu, tích hợp và khả năng truy cập. Chúng tôi đã nhận diện nhiều khó khăn phổ biến mà tổ chức phải đối mặt với dữ liệu phi cấu trúc:\nLưu trữ phân mảnh: Dữ liệu bị phân tán trên các storage bucket, workspace cục bộ, hệ thống file và các giải pháp lưu trữ khác nhau. Khả năng phát hiện hạn chế: Nếu thiếu metadata phù hợp, việc trích xuất và catalog hóa dữ liệu phi cấu trúc giá trị sẽ làm các tài sản bị ẩn và không được khai thác hết tiềm năng. Tính phức tạp khi tích hợp: Khó kết nối thông tin liên quan giữa các loại dữ liệu đa phương thức. Vấn đề về quản trị: Khi khối lượng dữ liệu tăng, việc đảm bảo lineage, kiểm soát truy cập và governance ngày càng khó khăn. Khử định danh dữ liệu: Việc cân bằng nhu cầu insight từ dữ liệu với yêu cầu nghiêm ngặt về riêng tư \u0026amp; tuân thủ là thách thức lớn ở nhiều ngành, đặc biệt khi cần độ chính xác đáp ứng quy định pháp lý. Amazon Bedrock Data Automation cho catalog hóa dữ liệu phi cấu trúc Amazon Bedrock Data Automation là một tính năng mạnh mẽ của Amazon Bedrock, dùng để tự động phân loại, tìm kiếm, và trích xuất insight từ dữ liệu đa phương thức phi cấu trúc như tài liệu, hình ảnh, audio và video bằng AI. Hãy xem nó đáp ứng những vấn đề then chốt như thế nào.\nBedrock Data Automation giúp chuẩn hóa quá trình trích xuất insight giá trị từ các loại dữ liệu phi cấu trúc như hình ảnh y tế, báo cáo hồ sơ bệnh án (PDF, hình ảnh), tệp audio \u0026amp; video. Dịch vụ này trích xuất metadata kỹ thuật và kinh doanh qua blueprint tùy chỉnh, giúp dữ liệu phi cấu trúc được phát hiện dễ dàng nhờ khả năng tìm kiếm toàn diện. Đối với các tổ chức nghiên cứu/y tế, điều này nghĩa là hình ảnh, bản scan và dữ liệu nghiên cứu có thể catalog hóa tự động và tìm kiếm dễ dàng mà không cần gán tag thủ công.\nKhi tích hợp với các dịch vụ AWS khác (như AWS Glue và Amazon SageMaker Unified Studio), Bedrock Data Automation tạo điều kiện xây dựng giải pháp phân tích tổng thể qua cái nhìn tích hợp cho các tài sản dữ liệu vốn trước đây bị silo hóa.\nFigure 1 – Giải pháp kiến trúc lưu trữ dữ liệu phi cấu trúc cấp cao\nGiải pháp catalog hóa dữ liệu phi cấu trúc: Cách hoạt động Giải pháp sử dụng kiến trúc nhiều tầng. Dưới đây là explanation flow trình bày ở Figure 1.\n1 – Quá trình nạp dữ liệu và khử định danh ban đầu\nDữ liệu từ các nguồn phi cấu trúc, đa phương thức sẽ được chuyển sang Amazon Simple Storage Service (Amazon S3), đóng vai trò điểm ingest dữ liệu chính. AWS cung cấp một danh mục dịch vụ chuyển dữ liệu dùng để truyền dữ liệu từ nhiều nguồn doanh nghiệp phi cấu trúc đến Amazon S3 và các dịch vụ AWS khác.\nĐối với các tổ chức cần dữ liệu đã khử định danh cho các trường hợp sử dụng khác nhau, có thể sử dụng kiến trúc event-driven kết hợp Amazon EventBridge và AWS Lambda. Họ có thể gọi các dịch vụ khử định danh AWS và các giải pháp trên AWS Marketplace để khử định danh dữ liệu.\nTổ chức cũng có thể tự phát triển giải pháp khử định danh trên AWS bằng cách kết hợp nhiều dịch vụ AWS. Có nhiều lựa chọn hỗ trợ như Amazon Textract, Amazon Comprehend, AWS Glue, Amazon Rekognition, Amazon Bedrock và các dịch vụ khác. Dữ liệu đã khử định danh sẽ được lưu vào Amazon S3.\nAWS Marketplace cung cấp một catalog số hóa các giải pháp bên thứ ba đã được xác minh cho các tình huống khử định danh ở nhiều ngành khác nhau. Ví dụ, với ngành healthcare, AWS Marketplace có các giải pháp đối tác cho clinical text deidentification, PDF deidentification và DICOM image and metadata deidentification\u0026hellip; Các giải pháp này có thể triển khai cho các transform jobs theo thời gian thực hoặc batch với các lựa chọn khác nhau trên AWS.\n2 – Data processing pipeline\nAmazon S3 kích hoạt các events qua Amazon EventBridge, đây là pha xử lý tiếp theo. Amazon EventBridge quản lý workflow event-driven và quá trình tự động hóa. EventBridge sẽ gọi Lambda functions để xử lý dữ liệu đã khử định danh và tiếp tục gọi Bedrock Data Automation để xử lý tài liệu, hình ảnh, file audio và video phi cấu trúc.\nBedrock Data Automation cung cấp năng lực AI qua foundation models cùng các tính năng tự động hóa dữ liệu. Nó trích xuất metadata mặc định và metadata tuỳ chỉnh bằng blueprint do khách hàng cung cấp. Dữ liệu xử lý sẽ lưu vào một S3 bucket. Ngoài ra, Bedrock Data Automation có thể tiếp tục kích hoạt EventBridge cho các xử lý downstream với dữ liệu và metadata đã trích xuất.\n3 – Knowledge management\nDữ liệu đã xử lý từ Amazon S3 sẽ chuyển vào Amazon Bedrock Knowledge Bases. Ứng dụng Generative AI và chatbot cung cấp giao diện tương tác ngôn ngữ tự nhiên và phản hồi tự động, giúp dữ liệu trở nên dễ truy cập và hành động cho người dùng cuối.\n4 – Centralized data storage and distribution layer\nChúng tôi sử dụng nhiều tầng lưu trữ để phục vụ các nhu cầu khác nhau của khách hàng. Khi triển khai ứng dụng Generative AI và chatbot, chúng tôi lưu dữ liệu xử lý từ Amazon S3 vào Amazon Bedrock Knowledge Bases. Để xây dựng centralized metadata store, AWS Glue ETL jobs sẽ xử lý dữ liệu incoming từ Bedrock Data Automation, trích xuất metadata và lưu vào một AWS Glue Catalog.\nAmazon DataZone nhập metadata từ AWS Glue Catalog và cung cấp một portal hợp nhất cho người dùng khám phá, chia sẻ, quản trị dữ liệu dù lưu trữ ở đâu. Nó dùng data catalog để cung cấp repository trung tâm cho metadata và ngữ cảnh vận hành của tài sản dữ liệu. Người dùng có thể khám phá, hiểu tài sản từ nhiều nguồn dữ liệu khác nhau. Ngoài ra, chúng tôi sử dụng Amazon DynamoDB làm storage layer cho metadata, tích hợp với Amazon OpenSearch Service.\n5 – Analytics layer\nKhi các tài sản đã nằm trong catalog DataZone, người dùng có thể truy vấn, phân tích dữ liệu đó bằng Amazon Athena hoặc Amazon Redshift Query Editor. Điều này cho phép thực hiện analytics phức tạp quy mô lớn và toàn diện về hoạt động business intelligence. Việc tích hợp Amazon OpenSearch Service với DynamoDB cung cấp năng lực tìm kiếm mạnh mẽ và khả năng phân tích gần real-time.\nBảo mật và tuân thủ Kiến trúc giải pháp này đảm bảo dữ liệu PHI (Protected Health Information) được khử định danh đúng chuẩn trước khi xử lý tiếp. Sử dụng lưu trữ riêng cho dữ liệu gốc và dữ liệu đã khử định danh. Amazon DataZone quản lý governance, kiểm soát truy cập và phân loại để xác minh quản lý dữ liệu và tuân thủ hiệu quả.\nCác bước tiếp theo Hãy chuyển đổi hành trình quản trị dữ liệu của bạn với giải pháp mà chúng tôi vừa trình bày sử dụng tính năng Amazon Bedrock Data Automation.\nChúng tôi khuyến nghị trước khi bắt đầu:\nLập bản đồ landscape dữ liệu phi cấu trúc Định nghĩa rõ tiêu chí thành công cho nhu cầu của tổ chức bạn Bắt đầu pilot tập trung với tài sản dữ liệu giá trị nhất để chứng minh giá trị ngay Triển khai rộng toàn tổ chức dựa trên thành công ban đầu Truy cập GitHub Repository: Guidance for Multimodal Data Processing để bắt đầu ngay hôm nay.\nKết luận Khi dữ liệu phi cấu trúc tiếp tục tăng trưởng mạnh mẽ trong mọi ngành, các tổ chức triển khai giải pháp catalog hóa và quản lý hiệu quả sẽ sở hữu lợi thế cạnh tranh lớn. Tính năng Amazon Bedrock Data Automation là một phương pháp mạnh mẽ, dễ mở rộng, có thể biến vấn đề quản lý dữ liệu phi cấu trúc thành tài sản chiến lược khi triển khai.\nDù bạn là tổ chức nghiên cứu hay healthcare, Bedrock Data Automation của chúng tôi giúp bạn phân loại, tìm kiếm và khai thác insight từ dữ liệu phi cấu trúc phức tạp. Giải pháp đảm bảo governance chuẩn và kiểm soát truy cập đúng, đồng thời unlock toàn bộ tiềm năng tài sản dữ liệu.\nLiên hệ AWS Representative để biết cách chúng tôi có thể giúp tăng tốc doanh nghiệp của bạn.\nĐọc thêm Amazon Bedrock Data Automation: Amazon Bedrock Data Automation to transform unstructured data into actionable insights AWS Glue Documentation Amazon DataZone User Guide Vani Eswarappa Vani Eswarappa là Principal Architect tại AWS, có kinh nghiệm về Containers, AI/ML, Enterprise Architecture. Là một technical leader, Vani làm việc với khách hàng AWS về hành trình cloud nhằm đáp ứng nhu cầu kinh doanh. Khi không làm việc, cô thích dành thời gian bên gia đình và khám phá địa điểm mới ngoài trời.\nRupesh Mishra Rupesh Mishra là Health AI/ML Specialist Solutions Architect tại AWS, với hơn 15 năm kinh nghiệm lâm sàng và kỹ thuật trong ngành healthcare và công nghệ. Anh nỗ lực nâng cao kết quả điều trị thông qua công nghệ và cộng tác cùng khách hàng, đối tác AWS các sáng kiến AI, ML, generative AI. Thời gian rảnh anh thích chơi thể thao, ở bên gia đình, du lịch và khám phá món ăn.\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.1-create-iam-role-and-policy-for-lambda/","title":"Cài đặt IAM Role và Policy cho Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt IAM Role và Policy cho Lambda.\nTạo IAM Role cho Lambda Mở IAM Console\nĐiều hướng tới https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Services → IAM Create Role:\nChọn tùy chọn Role trên menu bên trái. Sau đó nhấn Create role. Chọn trusted entity:\nTrusted entity type: AWS Service Use case: Lambda Nhấn \u0026ldquo;Next\u0026rdquo; Đính kèm permissions policies:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập dashboard-query-role Description: Nhập Execution role for Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AthenaActions\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;athena:StartQueryExecution\u0026#34;, \u0026#34;athena:GetQueryExecution\u0026#34;, \u0026#34;athena:GetQueryResults\u0026#34;, \u0026#34;athena:StopQueryExecution\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;GlueCatalogRead\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:GetDatabase\u0026#34;, \u0026#34;glue:GetDatabases\u0026#34;, \u0026#34;glue:GetTable\u0026#34;, \u0026#34;glue:GetTables\u0026#34;, \u0026#34;glue:GetPartitions\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;S3SourceAndResultAccess\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::vel-athena-results\u0026#34;, \u0026#34;arn:aws:s3:::vel-athena-results/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-cloudtrail-logs/*\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty\u0026#34;, \u0026#34;arn:aws:s3:::vel-processed-guardduty/*\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted\u0026#34;, \u0026#34;arn:aws:s3:::cloudwatch-formatted/*\u0026#34; ] } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập lambda-query-policy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.1-setup-s3/","title":"Cài đặt S3 Bucket cho Dashboard","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một S3 để chứa các file web và folder. Quan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu (ví dụ: us-east-1) trong tất cả tên bucket.\nTên Bucket static-dashboard-bucket-ACCOUNT_ID-REGION - Lưu trữ các file web và folder đã build\nHướng dẫn tạo Bucket Mở Amazon S3 Console\nĐiều hướng tới https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo;\nCài đặt tạo Bucket:\nGiữ các cài đặt như mặc định: Bucket name: Nhập static-dashboard-bucket-ACCOUNT_ID-REGION Ví dụ: static-dashboard-bucket-123456789012-us-east-1 Ownership: ACLs disabled Block Public Access: Block all public access Bucket versioning: Disable Tags (Tùy chọn): Thêm nếu bạn muốn Encryption: SSE-S3 Bucket key: Enable Nhấn Create bucket Xác minh tạo bucket:\nBạn sẽ thấy một thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 bucket của bạn Tải lên files và folder:\nTruy cập Github để lấy nội dung web và tải lên S3 "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.1-cloudtrail-etl/","title":"Mã CloudTrail ETL","tags":[],"description":"","content":" import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.1-create-kinesis-data-firehose/","title":"Tạo Kinesis Data Firehose","tags":[],"description":"","content":"Tạo Kinesis Data Firehose Delivery Streams Tạo cloudtrail-firehose-stream Mở Kinesis Console → Delivery streams → Create delivery stream\nCấu hình:\nSource: Direct PUT Destination: Amazon S3 Stream name: cloudtrail-firehose-stream S3 bucket: processed-cloudtrail-logs-ACCOUNT_ID-REGION Prefix: processed-cloudtrail/date=!{timestamp:yyyy-MM-dd}/ Error prefix: processed-cloudtrail/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ Buffer size: 10 MB Buffer interval: 300 seconds Compression: GZIP IAM role: CloudTrailFirehoseRole Create delivery stream\nTạo vpc-dns-firehose-stream Stream name: vpc-dns-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: vpc-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: vpc-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) Tạo vpc-flow-firehose-stream Stream name: vpc-flow-firehose-stream S3 bucket: processed-cloudwatch-logs-ACCOUNT_ID-REGION Prefix: eni-flow-logs/date=!{timestamp:yyyy-MM-dd}/ Error prefix: eni-flow-logs/errors/date=!{timestamp:yyyy-MM-dd}/error-type=!{firehose:error-output-type}/ IAM role: CloudWatchFirehoseRole (Cài đặt buffer/compression giống như trên) "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.1-create-lambda-excecution-roles/","title":"Tạo Lambda Execution Roles","tags":[],"description":"","content":"Tạo CloudTrailETLLambdaServiceRole Mở IAM Console:\nĐiều hướng đến https://console.aws.amazon.com/iam/ Hoặc: AWS Management Console → Tìm kiếm \u0026ldquo;IAM\u0026rdquo; → Nhấn \u0026ldquo;IAM\u0026rdquo; Điều hướng đến Roles:\nỞ thanh bên trái, nhấn \u0026ldquo;Roles\u0026rdquo; Nhấn \u0026ldquo;Create role\u0026rdquo;\nChọn trusted entity:\nTrusted entity type: Chọn \u0026ldquo;AWS service\u0026rdquo; Use case: Chọn \u0026ldquo;Lambda\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nTrong hộp tìm kiếm, nhập AWSLambdaBasicExecutionRole Đánh dấu vào ô bên cạnh \u0026ldquo;AWSLambdaBasicExecutionRole\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên, xem lại, và tạo:\nRole name: Nhập CloudTrailETLLambdaServiceRole Description: Nhập Execution role for CloudTrail ETL Lambda function Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nSau khi tạo, bạn sẽ ở trang chi tiết role Nhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Nhấn \u0026ldquo;Add permissions\u0026rdquo; → \u0026ldquo;Create inline policy\u0026rdquo; Tạo inline policy:\nNhấn vào tab \u0026ldquo;JSON\u0026rdquo; Dán policy sau (thay thế ACCOUNT_ID và REGION): { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/cloudtrail-firehose-stream\u0026#34; } ] } Nhấn \u0026ldquo;Next\u0026rdquo;\nTên Policy:\nPolicy name: Nhập CloudTrailETLPolicy Nhấn \u0026ldquo;Create policy\u0026rdquo; Xác minh tạo role:\nBạn sẽ thấy role với cả managed và inline policies được đính kèm Tạo các Lambda Roles còn lại Làm theo quy trình tương tự cho mỗi role dưới đây (các bước 3-11):\nGuardDutyETLLambdaServiceRole\nRole name: GuardDutyETLLambdaServiceRole Description: Execution role for GuardDuty ETL Lambda function Managed policy: AWSLambdaBasicExecutionRole Inline policy name: GuardDutyETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;kms:Decrypt\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:kms:REGION:ACCOUNT_ID:key/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;glue:CreatePartition\u0026#34;, \u0026#34;glue:GetPartition\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:catalog\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:database/security_logs\u0026#34;, \u0026#34;arn:aws:glue:REGION:ACCOUNT_ID:table/security_logs/processed_guardduty\u0026#34; ] } ] } CloudWatchETLLambdaServiceRole\nRole name: CloudWatchETLLambdaServiceRole Description: Execution role for VPC DNS logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-dns-firehose-stream\u0026#34; } ] } CloudWatchENIETLLambdaServiceRole\nRole name: CloudWatchENIETLLambdaServiceRole Description: Execution role for VPC Flow logs ETL Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchENIETLPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;firehose:PutRecord\u0026#34;, \u0026#34;firehose:PutRecordBatch\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:firehose:REGION:ACCOUNT_ID:deliverystream/vpc-flow-firehose-stream\u0026#34; } ] } CloudWatchExportLambdaServiceRole\nRole name: CloudWatchExportLambdaServiceRole Description: Execution role for CloudWatch log export Lambda Managed policy: AWSLambdaBasicExecutionRole Inline policy name: CloudWatchExportPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateExportTask\u0026#34;, \u0026#34;logs:DescribeExportTasks\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34;, \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } ParseFindingsLambdaServiceRole\nRole name: ParseFindingsLambdaServiceRole Description: Execution role for parsing GuardDuty findings Managed policy: AWSLambdaBasicExecutionRole Không cần inline policy IsolateEC2LambdaServiceRole\nRole name: IsolateEC2LambdaServiceRole Description: Execution role for isolating compromised EC2 instances Managed policy: AWSLambdaBasicExecutionRole Inline policy name: IsolateEC2Policy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeInstances\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } QuarantineIAMLambdaServiceRole\nRole name: QuarantineIAMLambdaServiceRole Description: Execution role for quarantining compromised IAM users Managed policy: AWSLambdaBasicExecutionRole Inline policy name: QuarantineIAMPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:AttachUserPolicy\u0026#34;, \u0026#34;iam:ListAttachedUserPolicies\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:iam::ACCOUNT_ID:user/*\u0026#34;, \u0026#34;arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy\u0026#34; ] } ] } AlertDispatchLambdaServiceRole\nRole name: AlertDispatchLambdaServiceRole Description: Execution role for dispatching alerts via SNS/SES/Slack Managed policy: AWSLambdaBasicExecutionRole Inline policy name: AlertDispatchPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:REGION:ACCOUNT_ID:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ses:SendEmail\u0026#34;, \u0026#34;ses:SendRawEmail\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.1-set-up-s3-buckets/","title":"Thiết lập S3 buckets","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 5 S3 buckets phục vụ làm nền tảng cho hệ thống Phản hồi Sự cố Tự động (Auto Incident Response system).\nQuan trọng: Thay thế ACCOUNT_ID bằng AWS Account ID của bạn và REGION bằng region mục tiêu của bạn (ví dụ: us-east-1) trong tất cả các tên bucket.\nTên Bucket incident-response-log-list-bucket-ACCOUNT_ID-REGION - Bucket thu thập log chính processed-cloudtrail-logs-ACCOUNT_ID-REGION - Lưu trữ CloudTrail logs đã xử lý athena-query-results-ACCOUNT_ID-REGION - Lưu trữ kết quả truy vấn Athena processed-cloudwatch-logs-ACCOUNT_ID-REGION - Lưu trữ CloudWatch logs đã xử lý processed-guardduty-findings-ACCOUNT_ID-REGION - Lưu trữ GuardDuty findings đã xử lý Hướng dẫn tạo Bucket Mở Amazon S3 Console Truy cập https://console.aws.amazon.com/s3/ Hoặc: AWS Management Console → Services → S3 Nhấn vào \u0026ldquo;Create bucket\u0026rdquo; Cấu hình chung: Bucket name: Nhập incident-response-log-list-bucket-ACCOUNT_ID-REGION Ví dụ: incident-response-log-list-bucket-123456789012-us-east-1 AWS Region: Chọn region mục tiêu của bạn (ví dụ: US East (N. Virginia) us-east-1) Object Ownership:\nGiữ mặc định: ACLs disabled (recommended) Cài đặt Block Public Access cho bucket này:\nChọn \u0026ldquo;Block all public access\u0026rdquo; Đảm bảo tất cả 4 tùy chọn phụ đều được chọn: ✓ Block public access to buckets and objects granted through new access control lists (ACLs) ✓ Block public access to buckets and objects granted through any access control lists (ACLs) ✓ Block public access to buckets and objects granted through new public bucket or access point policies ✓ Block public and cross-account access to buckets and objects through any public bucket or access point policies Bucket Versioning:\nChọn \u0026ldquo;Enable\u0026rdquo; Tags (tùy chọn):\nThêm tags nếu muốn Ví dụ: Key=Purpose, Value=IncidentResponse Mã hóa mặc định (Default encryption):\nEncryption type: Chọn \u0026ldquo;Server-side encryption with Amazon S3 managed keys (SSE-S3)\u0026rdquo; Bucket Key: Giữ mặc định (Enabled) Cài đặt nâng cao (Advanced settings):\nGiữ nguyên tất cả mặc định Nhấn \u0026ldquo;Create bucket\u0026rdquo;\nXác minh tạo bucket:\nBạn sẽ thấy thông báo thành công Bucket sẽ xuất hiện trong danh sách S3 buckets của bạn Lặp lại các bước 2-10 cho 4 buckets còn lại:\nprocessed-cloudtrail-logs-ACCOUNT_ID-REGION athena-query-results-ACCOUNT_ID-REGION processed-cloudwatch-logs-ACCOUNT_ID-REGION processed-guardduty-findings-ACCOUNT_ID-REGION Xác minh tất cả 5 buckets đã được tạo:\nĐiều hướng đến S3 Console Bạn sẽ thấy tất cả 5 buckets được liệt kê "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.1-workshop-overview/","title":"Tổng quan","tags":[],"description":"","content":"Các thành phần hệ thống Phản hồi sự cố và Điều tra số tự động (Auto Incident Response and Forensics) là một kiến trúc sử dụng các dịch vụ tự động hóa để thu thập, xử lý và tự động phản hồi các phát hiện bảo mật, giảm thiểu thời gian cần thiết cho sự can thiệp của con người và hỗ trợ nhân viên bảo mật trong việc trực quan hóa và phân tích log. Hệ thống này được xây dựng dựa trên AWS Security Services (CloudTrail, GuardDuty, VPC Flow Logs, CloudWatch) đưa dữ liệu vào một Data Lake tập trung (S3/Glue/Athena) để phân tích. Tự động hóa cốt lõi được điều khiển bởi AWS EventBridge rules kích hoạt AWS Step Functions workflows, sau đó thực thi AWS Lambda functions để thực hiện các hành động cách ly và cảnh báo. Tổng quan về Workshop Trong workshop này, bạn sẽ triển khai một hệ thống đa giai đoạn để đạt được tự động hóa bảo mật từ đầu đến cuối. Bao gồm:\nThiết lập nền tảng (Foundation Setup): Tạo các S3 buckets và IAM roles chuyên dụng để hỗ trợ tất cả các dịch vụ. Thiết lập giám sát (Monitoring Setup): Kích hoạt và cấu hình các log bảo mật chính (CloudTrail, GuardDuty, VPC Flow Logs) để chuyển dữ liệu đến điểm thu thập log trung tâm. Thiết lập xử lý (Processing Setup): Triển khai Kinesis Firehose, Lambda ETLs, và Glue/Athena tables để chuyển đổi log thô thành một security data lake dễ dàng truy vấn. Thiết lập tự động hóa (Automation Setup): Tạo Isolation Security Group, SNS Topic, Incident Response Lambda Functions, và Step Functions State Machine thực thi các hành động cách ly tự động khi GuardDuty phát hiện các vấn đề. Thiết lập Dashboard (Dashboard Setup): Lưu trữ một giao diện web tĩnh dựa trên S3 an toàn được tăng tốc bởi CloudFront và bảo vệ bởi Cognito để cung cấp cho các nhà phân tích khả năng trực quan hóa thời gian thực của dữ liệu điều tra (forensic data) và khả năng truy vấn trực tiếp qua API Gateway. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/2-proposal/","title":"Bản đề xuất","tags":[],"description":"","content":"\nHệ thống Ứng phó Sự cố và Điều tra Số Tự động trên AWS Proposal Link (Google Docs): Proposal 1. Tóm tắt Điều hành Nhóm của chúng tôi đang xây dựng một giải pháp ứng phó sự cố và điều tra số tự động như một phần của chương trình thực tập AWS First Cloud Journey. Ý tưởng rất đơn giản—khi một vấn đề bảo mật xảy ra trong AWS, chúng tôi muốn hệ thống phản ứng tự động mà không cần chờ đợi sự can thiệp thủ công.\nChúng tôi đang tạo ra một nền tảng tự động phát hiện các phát hiện bảo mật từ GuardDuty, cô lập các tài nguyên bị ảnh hưởng, thu thập bằng chứng pháp y thông qua việc thu thập dữ liệu toàn diện, và cung cấp các phân tích và bảng điều khiển để các đội bảo mật có thể điều tra những gì đã xảy ra. Mọi thứ được xây dựng bằng Infrastructure-as-Code với AWS CDK, vì vậy khách hàng có thể dễ dàng triển khai nó vào tài khoản AWS của riêng họ.\n2. Báo cáo Vấn đề Vấn đề là gì? Tần suất và sự tinh vi ngày càng tăng của các mối đe dọa mạng đặt ra những rủi ro đáng kể cho các tổ chức dựa vào cơ sở hạ tầng đám mây. Quy trình ứng phó sự cố thủ công thường chậm chạp, không nhất quán và dễ mắc lỗi của con người, có thể dẫn đến thời gian ngừng hoạt động hệ thống kéo dài, vi phạm dữ liệu và tổn thất tài chính. Dự án nhằm giải quyết những thách thức này bằng cách phát triển một hệ thống ứng phó sự cố tự động, đáng tin cậy và có khả năng mở rộng.\nGiải pháp Các trường hợp sử dụng chính bao gồm phát hiện việc sử dụng trái phép thông tin xác thực AWS, xác định các EC2 instance bị xâm nhập, và đảm bảo dữ liệu pháp y được thu thập, xử lý và lưu trữ đúng cách để điều tra. Kiến trúc của chúng tôi tích hợp VPC Flow Logs, CloudTrail, CloudWatch và GuardDuty để phát hiện các mối đe dọa, trong khi Step Functions điều phối quy trình ứng phó tự động bao gồm cô lập EC2, tách khỏi ASG, tạo Snapshot và cách ly IAM. Tất cả bằng chứng được thu thập và xử lý thông qua Lambda ETL tùy chỉnh và Data Firehose, sử dụng Athena để phân tích pháp y. Hệ thống cũng bao gồm alert dispatching, notification bằng email và Slack, và cho chúng ta cái dashboard để analyze và điều tra chuyện đã xảy ra.\nLợi ích và Tỷ suất Lợi nhuận (ROI) Phát hiện mối đe dọa nhanh chóng: Phản ứng tự động giúp giảm thiểu khoảng thời gian dễ bị tổn thương. Thu thập bằng chứng toàn diện: Tự động hóa việc thu thập dữ liệu pháp y, tạo điều kiện cho các cuộc điều tra nhanh hơn. Hiệu quả về chi phí: Tận dụng các dịch vụ serverless của AWS giúp giảm thiểu chi phí cơ sở hạ tầng. Cải thiện tư thế bảo mật: Thông qua giám sát liên tục và cảnh báo thời gian thực. Thông tin chi tiết hữu ích: Các bảng điều khiển và phân tích trao quyền cho các đội bảo mật. Khả năng mở rộng: Thích ứng với các tổ chức có quy mô và khối lượng sự cố khác nhau. 3. Kiến trúc Giải pháp Giải pháp của chúng tôi sử dụng một kiến trúc đa giai đoạn toàn diện cho việc ứng phó sự cố và điều tra số tự động:\nCác Dịch vụ AWS Được Sử dụng Amazon GuardDuty: Liên tục theo dõi các mối đe dọa bảo mật và hoạt động đáng ngờ. AWS Step Functions: Điều phối quy trình ứng phó sự cố. AWS Lambda: Chạy mã tự động hóa để cô lập và xử lý dữ liệu. Amazon EventBridge: Định tuyến các phát hiện từ GuardDuty đến Step Functions. Amazon S3: Lưu trữ bằng chứng pháp y và lưu trữ bảng điều khiển tĩnh. Amazon Athena: Cho phép thực hiện các truy vấn SQL trên các tập dữ liệu pháp y. Amazon API Gateway: Tạo điều kiện giao tiếp giữa bảng điều khiển và backend. Amazon Cognito: Bảo mật quyền truy cập cho người dùng bảng điều khiển. Amazon CloudFront: Tăng tốc độ phân phối bảng điều khiển trên toàn cầu. Amazon SNS \u0026amp; SES: Xử lý thông báo qua tin nhắn và email. AWS CloudTrail: Ghi nhật ký tất cả các hành động để kiểm toán. Amazon CloudWatch: Giám sát và bảng điều khiển. Amazon EC2: Các instance tùy chọn để phân tích. AWS KMS: Quản lý khóa để mã hóa. Amazon Kinesis Data Firehose: Truyền dữ liệu đến S3. Thiết kế Thành phần Lớp Thu thập Dữ liệu \u0026amp; Phát hiện: Thu thập các sự kiện từ VPC Flow Logs, CloudTrail, CloudWatch, EC2 và GuardDuty. Lớp Xử lý Sự kiện: Alert Dispatch, EventBridge định tuyến các phát hiện đến Step Functions; các sự kiện được phân loại theo loại. Điều phối Ứng phó Tự động (Orchestration): Step Functions xử lý phân tích, ra quyết định, cô lập EC2, bảo vệ chấm dứt, tách ASG, tạo snapshot và cách ly IAM. Lớp Xử lý Dữ liệu \u0026amp; Phân tích: ETL pipeline với Lambda và Data Firehose xử lý nhật ký thô vào S3; Athena truy vấn dữ liệu. Lớp Bảng điều khiển \u0026amp; Phân tích: Bảng điều khiển React lưu trữ trên S3 với xác thực Cognito, sử dụng dữ liệu qua API Gateway và Athena. 4. Triển khai Kỹ thuật Các Giai đoạn Triển khai Chúng tôi sử dụng Agile Scrum với các sprint 1 tuần trong vòng 6 tuần:\nSprint 1: Nền tảng \u0026amp; Thiết lập (VPC, Security Groups, Đào tạo). Sprint 2: Điều phối Cốt lõi (Step Functions, Lambda, tích hợp GuardDuty). Sprint 3: Dữ liệu \u0026amp; Phân tích (S3, Athena, ETL pipeline). Sprint 4: Bảng điều khiển \u0026amp; UI (Trang web tĩnh, API Gateway, CloudFront). Sprint 5: Kiểm thử \u0026amp; Tối ưu hóa (Cognito, Kiểm thử hiệu suất, Mô phỏng). Sprint 6: Tài liệu \u0026amp; Bàn giao (Hướng dẫn, Demo, Hoàn thiện). Yêu cầu Kỹ thuật Frontend \u0026amp; Bảng điều khiển: HTML/CSS/JS tùy chỉnh được lưu trữ trên S3, phục vụ qua CloudFront. Backend \u0026amp; Xử lý: Python 3.12 cho Lambda, Step Functions để điều phối. Dữ liệu \u0026amp; Lưu trữ: S3 cho bằng chứng, Athena để truy vấn, Firehose để truyền dữ liệu. Cơ sở hạ tầng: Tất cả được định nghĩa trong AWS CDK (Python). Bảo mật: GuardDuty để phát hiện, IAM cho quyền hạn tối thiểu, KMS để mã hóa. 5. Thời gian biểu \u0026amp; Cột mốc Dòng thời gian Dự án Dòng thời gian Dự án\nTuần 6-7 (Nền tảng \u0026amp; Thiết lập) Hoạt động: Đào tạo nhóm về GuardDuty/Step Functions, đánh giá thiết kế kiến trúc, thiết lập VPC và bảo mật. Sản phẩm bàn giao: Tài liệu kiến trúc v1, hoàn thành đào tạo nhóm, kho lưu trữ GitHub được thiết lập. Tuần 7-9 (Điều phối Cốt lõi) Hoạt động: Phát triển quy trình Step Functions, lập trình hàm Lambda cho tất cả các hành động ứng phó, tích hợp EventBridge, thiết lập SNS/SES, kiểm thử tích hợp. Sản phẩm bàn giao: Định nghĩa máy trạng thái Step Functions, hơn 7 hàm Lambda có tài liệu, tích hợp GuardDuty, hệ thống thông báo, API Gateway. Tuần 10 (Dữ liệu \u0026amp; Phân tích) Hoạt động: Thiết lập lưu trữ pháp y S3, tạo bảng Athena, phát triển đường ống ETL, thư viện truy vấn SQL. Sản phẩm bàn giao: Hơn 15 truy vấn Athena được ghi lại, sách hướng dẫn phân tích pháp y, lưu trữ dữ liệu đã xử lý. Tuần 11 (Bảng điều khiển \u0026amp; UI) Hoạt động: Phát triển bảng điều khiển tĩnh, xác thực Cognito, thiết lập API Gateway, cấu hình CloudFront CDN, tích hợp bảng điều khiển. Sản phẩm bàn giao: Bảng điều khiển lưu trữ trên S3, hệ thống xác thực, giao diện truy vấn, tích hợp kết quả thời gian thực. Tuần 12 (Kiểm thử, Xác thực \u0026amp; Tối ưu hóa) Hoạt động: Kiểm thử thủ công, quét bảo mật bao gồm các kịch bản sự cố mô phỏng (hơn 5 quy trình), kiểm thử hiệu suất, mô phỏng tấn công. Tối ưu hóa dữ liệu với truy vấn Athena và Data Firehose. Sản phẩm bàn giao: Kết quả quét bảo mật, video mô phỏng sự cố, tối ưu hóa dữ liệu. Tuần 13 (Tài liệu \u0026amp; Bàn giao) Hoạt động: Hướng dẫn triển khai, tài liệu API, các phiên chuyển giao kiến thức, demo cuối cùng, dọn dẹp GitHub. Sản phẩm bàn giao: Kho lưu trữ GitHub hoàn chỉnh (công khai), hướng dẫn triển khai, buổi trình diễn workshop trực tiếp. 6. Ước tính Ngân sách Bạn có thể tìm thấy ước tính ngân sách chi tiết trên AWS Pricing Calculator.\nChi phí Cơ sở hạ tầng Chi phí triển khai hàng tháng điển hình (Bậc miễn phí / Quy mô nhỏ): ~$5.01\nGuardDuty: ~$1.80/tháng S3: ~$1.07/tháng KMS: ~$1.12/tháng CloudTrail: ~$0.55/tháng Athena: ~$0.29/tháng Amazon Simple Email Service (SES): ~$0.09/tháng Amazon API Gateway: ~$0.05/tháng Amazon Data firehose: ~$0.04/tháng Lambda, Step Functions, SNS: Thường nằm trong giới hạn Bậc miễn phí cho mức sử dụng thông thường. Lưu ý: Chi phí giả định mức sử dụng thông thường từ 20-150 sự cố mỗi tháng.\n7. Đánh giá Rủi ro Ma trận Rủi ro Tắc nghẽn Hiệu suất: Khối lượng dữ liệu lớn làm chậm các truy vấn. Vi phạm Bảo mật: Xâm phạm chính dữ liệu pháp y. Vượt quá Chi phí: Ghi nhật ký không kiểm soát hoặc vòng lặp vô hạn. Chiến lược Giảm thiểu Hiệu suất: Giám sát Athena/Firehose; tối ưu hóa truy vấn; điều chỉnh tài nguyên động. Bảo mật: Mã hóa (KMS), vai trò IAM nghiêm ngặt, ghi nhật ký kiểm toán. Chi phí: Cảnh báo ngân sách AWS, phát hiện bất thường chi phí, giới hạn tự động mở rộng. Khôi phục sau Thảm họa: Sao lưu, quy trình chuyển đổi dự phòng và các biện pháp dự phòng. 8. Kết quả Dự kiến Cải tiến Kỹ thuật Ứng phó Tự động: Cô lập không chạm (zero-touch) các tài nguyên bị xâm nhập. Tốc độ: Giảm thời gian điều tra từ hàng giờ xuống còn vài phút. Độ tin cậy: Thu thập bằng chứng nhất quán, có thể lặp lại mà không có lỗi của con người. Giá trị Dài hạn Kiến trúc Có thể Mở rộng: Nền tảng cho tự động hóa bảo mật trong tương lai. Kiến thức: Năng lực của nhóm về bảo mật AWS nâng cao và các khái niệm serverless. Tài sản Có thể Tái sử dụng: Một giải pháp có thể triển khai cho các khách hàng hoặc nhóm AWS khác. Trạng thái: Sẵn sàng cho Xem xét \u0026amp; Phê duyệt Mã Dự án: AWS-FCJ-IR-FORENSICS-2025\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/4-eventparticipated/4.2-event2/","title":"Sự kiện 2","tags":[],"description":"","content":"Báo cáo Tóm tắt: “AWS Cloud Mastery Series #1 - AI/ML/GenAI trên AWS” Mục tiêu Sự kiện Sự kiện nhằm cung cấp một cái nhìn tổng quan về khả năng của AI, Machine Learning (ML) và Generative AI (GenAI) trên AWS. Các mục tiêu cụ thể bao gồm:\nKhám phá các khái niệm nền tảng của Generative AI và các ứng dụng của nó. Trình diễn việc sử dụng các dịch vụ và công cụ AWS cho quy trình làm việc AI/ML. Nêu bật các phương pháp hay nhất (best practices) để tích hợp AI/ML vào môi trường sản xuất. Diễn giả Sự kiện có sự tham gia của một nhóm đa dạng các chuyên gia giàu kinh nghiệm đã chia sẻ kiến thức chuyên môn của họ:\nLam Tuan Kiet – Senior DevOps Engineer, FPT Software Danh Hoang Hieu Nghi – AI Engineer, Renova Cloud Dinh Le Hoang Anh – Cloud Engineer Trainee, First Cloud AI Journey Van Hoang Kha – Cloud Security Engineer, AWS Community Builder Điểm nổi bật Chính Generative AI với Amazon Bedrock Phiên họp đã cung cấp một sự khám phá sâu về Amazon Bedrock, một dịch vụ được quản lý hoàn toàn để triển khai và mở rộng các mô hình nền tảng (foundation models). Các chủ đề chính bao gồm:\nFoundation Models: Khác với các mô hình truyền thống, các mô hình nền tảng được đào tạo trước trên các tập dữ liệu khổng lồ và có thể được điều chỉnh cho một loạt các nhiệm vụ. Amazon Bedrock cung cấp các mô hình từ các công ty AI hàng đầu như OpenAI, Anthropic, và Cohere.\nPrompt Engineering: Các kỹ thuật để tạo ra các lời nhắc hiệu quả nhằm tối ưu hóa phản hồi của mô hình:\nZero-Shot Prompting: Không cung cấp bối cảnh hoặc ví dụ trước. Few-Shot Prompting: Bao gồm một vài ví dụ để hướng dẫn mô hình. Chain of Thought (CoT): Kết hợp các bước suy luận để cải thiện chất lượng phản hồi. Retrieval Augmented Generation (RAG): Một kỹ thuật nâng cao phản hồi của mô hình bằng cách truy xuất thông tin liên quan từ các nguồn dữ liệu bên ngoài:\nRetrieval (Truy xuất): Lấy dữ liệu liên quan từ cơ sở tri thức. Augmentation (Tăng cường): Thêm dữ liệu đã truy xuất làm bối cảnh cho lời nhắc. Generation (Tạo sinh): Tạo phản hồi dựa trên lời nhắc đã được tăng cường. Các trường hợp sử dụng: Chatbot theo ngữ cảnh, tìm kiếm cá nhân hóa, tóm tắt dữ liệu thời gian thực, và cải thiện việc tạo nội dung. Amazon Titan Embedding: Một mô hình nhẹ được thiết kế cho các nhiệm vụ truy xuất độ chính xác cao. Nó dịch văn bản thành các embedding số và hỗ trợ hơn 100 ngôn ngữ, làm cho nó trở nên lý tưởng cho các ứng dụng đa ngôn ngữ.\nCác dịch vụ AI được đào tạo trước trên AWS AWS cung cấp một bộ các dịch vụ AI sẵn sàng sử dụng để giải quyết các nhu cầu kinh doanh phổ biến:\nAmazon Rekognition: Phân tích hình ảnh và video. Amazon Translate: Phát hiện và dịch văn bản. Amazon Textract: Trích xuất văn bản và bố cục từ tài liệu. Amazon Transcribe: Chuyển đổi giọng nói thành văn bản. Amazon Polly: Tổng hợp văn bản thành giọng nói. Amazon Comprehend: Phân tích văn bản để tìm thông tin chi tiết và mối quan hệ. Amazon Kendra: Khả năng tìm kiếm thông minh. Amazon Lookout: Phát hiện bất thường trong các chỉ số, thiết bị và hình ảnh. Amazon Personalize: Đề xuất cá nhân hóa cho người dùng. Amazon Bedrock AgentCore Phiên họp đã giới thiệu Amazon Bedrock AgentCore, một nền tảng để triển khai và mở rộng quy mô các tác nhân AI một cách an toàn trong sản xuất. Các tính năng chính bao gồm:\nBộ nhớ: Cho phép các tác nhân ghi nhớ các tương tác trong quá khứ và học hỏi theo thời gian. Kiểm soát Danh tính và Truy cập: Đảm bảo thực thi an toàn các quy trình tác nhân. Tích hợp Công cụ: Hỗ trợ các công cụ như trình duyệt và trình thông dịch mã cho các quy trình làm việc phức tạp. Khả năng quan sát: Cung cấp thông tin chi tiết về các tương tác của tác nhân để kiểm toán và gỡ lỗi. Khung xây dựng Tác nhân: Bao gồm CrewAI, LangChain, OpenAI Agents SDK, và nhiều hơn nữa. Demo Trực tiếp: AMZPhoto Bản demo đã giới thiệu một ứng dụng nhận dạng khuôn mặt được xây dựng bằng các dịch vụ AI của AWS. Ứng dụng đã chứng minh sự tích hợp liền mạch của Amazon Rekognition để phân tích hình ảnh.\nBài học Chính Amazon Bedrock như một Trung tâm GenAI: Bedrock đơn giản hóa việc truy cập vào các mô hình nền tảng từ các nhà cung cấp hàng đầu, cho phép phát triển nhanh chóng các giải pháp AI. Prompt Engineering và RAG: Các kỹ thuật nhắc nhở hiệu quả và tạo sinh tăng cường truy xuất có thể nâng cao đáng kể hiệu suất mô hình. Titan Embeddings cho Tìm kiếm: Amazon Titan Embedding là một công cụ mạnh mẽ để truy xuất thông tin với độ chính xác cao. Dịch vụ AI được đào tạo trước: AWS cung cấp một loạt các dịch vụ để giải quyết các nhu cầu AI/ML đa dạng, từ phân tích hình ảnh đến đề xuất cá nhân hóa. AgentCore cho AI Sẵn sàng Sản xuất: Bedrock AgentCore giải quyết các thách thức trong việc triển khai các tác nhân AI ở quy mô lớn, đảm bảo bảo mật, khả năng mở rộng và khả năng quan sát. Áp dụng Kiến thức vào Công việc Kiến thức thu được từ sự kiện này có thể được áp dụng theo một số cách:\nTích hợp Mô hình Nền tảng: Kết hợp các mô hình nền tảng vào các dự án trong tương lai để nâng cao khả năng AI. Tối ưu hóa Quy trình làm việc với RAG: Sử dụng tạo sinh tăng cường truy xuất để cải thiện chất lượng của các giải pháp định hướng AI. Tận dụng Dịch vụ Đào tạo trước: Sử dụng các dịch vụ AI của AWS như Rekognition và Textract để tự động hóa các nhiệm vụ lặp lại và cải thiện hiệu quả. Xây dựng Tác nhân AI có thể mở rộng: Khám phá Bedrock AgentCore để triển khai các tác nhân AI an toàn và có thể mở rộng trong môi trường sản xuất. Trải nghiệm Sự kiện Sự kiện rất hấp dẫn và nhiều thông tin, với các diễn giả chuẩn bị kỹ lưỡng và các phiên tương tác. Những điểm nổi bật chính của trải nghiệm bao gồm:\nPhiên Hỏi \u0026amp; Đáp: Một thành viên trong nhóm đã nêu một câu hỏi quan trọng về việc xử lý khối lượng cảnh báo lớn trong kiến trúc sử dụng SNS cho các phát hiện của GuardDuty. Giải pháp được đưa ra là tích hợp SQS để xếp hàng các sự kiện, đảm bảo không bỏ sót cảnh báo nào. Kahoot Quiz: Đã lọt vào top 3 cho đến khi Ragnarok bắt đầu\u0026hellip; Kết nối (Networking): Đã thành lập một nhóm không chính thức, \u0026ldquo;Mèo Cam Đeo Khăn,\u0026rdquo; hợp tác với các người tham dự khác, thúc đẩy kết nối và cơ hội hợp tác trong tương lai. Hình ảnh Sự kiện "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.2-week2/","title":"Nhật ký Tuần 2","tags":[],"description":"","content":"Mục tiêu Tuần 2: Nắm vững các loại EC2 instance, tùy chọn mua và placement groups. Triển khai các chính sách IAM nâng cao để giới hạn khu vực và thực thi MFA. Lưu trữ website tĩnh trên Amazon S3 với ghi nhật ký truy cập và lập phiên bản. Tăng tốc phân phối nội dung sử dụng Amazon CloudFront và định tuyến tên miền với Route 53. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành việc hạn chế IAM tạo EC2 từ khu vực khác. (Hạn chế sử dụng dịch vụ theo Khu vực AWS) - Học cách phân tích yêu cầu tính toán và chọn họ instance phù hợp. - Khởi chạy các instance trong cùng và khác họ để kiểm tra Chính sách IAM EC2 - Học cách hạn chế một số EBS volume nhất định và thông tin chung về các loại EBS volume - Kiểm tra chính sách bằng cách khởi chạy một EC2 với loại EBS volume không được phép. - Học cách giới hạn quyền truy cập vào tài nguyên bằng cách chỉ cho phép truy cập từ các IP nhất định - Học cách giới hạn quyền xóa tài nguyên theo khoảng thời gian 15/09/2025 15/09/2025 Amazon EC2 instance types Introduction to Amazon EC2 Amazon EC2 instance types IAM policy testing with the IAM policy simulator IAM Policy Simulator 3 - Tạo một EC2 và SSH vào nó sử dụng MobaXterm và tạo một S3 bucket - Tải lên tệp sử dụng accesskey/secretaccesskey: + Tạo một IAM user với access key + Tải tệp lên S3 bucket - Tải lên tệp với các vai trò đủ điều kiện trên EC2: + Tạo một role cho EC2 + Tải tệp lên S3 bucket thông qua EC2 role. 16/09/2025 16/09/2025 Granting authorization for an application to access AWS services with an IAM role. 4 - Tìm hiểu về Cloud 9 IDE, nó là gì (Không thể sử dụng vì tôi không có quyền truy cập.) - Thông tin về S3: + Biết sự khác biệt giữa S3 Bucket và S3 Object + Biết về các lớp lưu trữ (storage classes) và những thứ khác. - Tạo một S3 bucket và host một trang web tĩnh: + Tạo một S3 bucket và tải dữ liệu lên + Bật Static website hosting và bỏ chọn Block all public access + Thay đổi cài đặt quyền của bucket và đặt các đối tượng công khai bằng ACL + Truy cập thành công trang web tĩnh 17/09/2025 17/09/2025 How to migrate from AWS Cloud9 to AWS IDE Toolkits or AWS CloudShell Get started with AWS Cloud 9 Starting with Amazon S3 5 - Tăng tốc Trang web Tĩnh với Cloudfront: + Chặn tất cả truy cập công khai + Tạo và cấu hình một Cloudfront distribution (Giao diện mới không cho phép chọn Default root object và Price class khi tạo, để thay đổi, chọn distribution của bạn, nhấp vào tab General, tìm Settings và nhấp Edit, sau đó bạn có thể thấy các tùy chọn còn thiếu ở đó.) + Truy cập thành công vào trang web + Kiểm tra thời gian tải bằng cách kiểm tra trang web, luồng sẽ là: Inspect -\u0026gt; Network -\u0026gt; Refresh page Bạn có thể thấy thời gian ở phía xa bên phải của tài liệu Cloudfront (đối với tôi là 29ms), khi bạn nhấp vào tài liệu Cloudfront, bạn có thể thấy PoP nào đang trả về trang web Của tôi là HKG1-P2 (Hong Kong) - Bucket Versioning: + Đọc và bật Bucket Versioning + Kiểm tra nó bằng cách chỉnh sửa tệp index.html và tải nó lên S3 bucket rồi kiểm tra Cloudfront - Di chuyển các đối tượng từ một S3 sang cái khác: + Tạo một S3 Bucket mới + Tính toán kích thước của toàn bộ bucket để so sánh sau khi di chuyển + Di chuyển thành công bucket + Tính toán kích thước để đảm bảo không mất dữ liệu nào Vì tò mò, tôi đã thử thay đổi Origin domain của Cloudfront distribution, thêm một Bucket policy trong permissions và bật Static website hosting trên S3 Bucket mới và nó hoạt động tuyệt vời! - Sao chép thành công các đối tượng bên trong một S3 Bucket sang khu vực khác. Ghi chú và Các phương pháp tốt nhất 18/09/2025 18/09/2025 Starting with Amazon S3 Restrict access to an Amazon S3 origin AWS Global Infrastructure - Expenses: + Amazon S3 Price +\tAmazon CloudFront Pricing\t+ Amazon Price Kết quả đạt được Tuần 2: Đã triển khai một website tĩnh trên S3 với chặn truy cập công khai được cấu hình chính xác. Tạo các chính sách IAM giới hạn hoạt động trong các khu vực cụ thể (ví dụ: ap-southeast-1) để tuân thủ. Cấu hình một CloudFront distribution với OAC (Origin Access Control) để phục vụ nội dung S3 riêng tư một cách an toàn. Bật tính năng S3 Versioning và sao chép dữ liệu sang một khu vực phụ để thử nghiệm khôi phục sau thảm họa. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/","title":"Cài đặt IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo IAM role và Policy cho Lambda. Sau đó bạn sẽ tạo Lambda Function để thực thi truy vấn.\nNội dung Tạo Lambda Execution Roles và Policy Tạo Lambda Function "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.2-setup-lambda/5.7.2.2-create-lambda-function/","title":"Cài đặt Lambda","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Lambda sử dụng Python để thực thi truy vấn dùng dịch vụ Athena.\nTạo Lambda Function Mở Lambda Console\nĐiều hướng tới https://console.aws.amazon.com/lambda/ Hoặc: AWS Management Console → Services → Lambda Tạo Function:\nNhấn Create Function Trong mục cài đặt tạo mới, sử dụng cài đặt sau: Chọn Author from scratch Name: dashboard-query Runtime: Python 3.12 Architecture: x86_64 Change default execution role: Use an existing role Chọn dashboard-query-role Nhấn Create Thêm mã nguồn (code):\nTrong code editor copy và paste đoạn mã bên dưới sau đó nhấn Deploy: import boto3 import time import os import json athena = boto3.client(\u0026#39;athena\u0026#39;) RESOURCE_MAP = { \u0026#39;/logs/cloudtrail\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_cloudtrail\u0026#39; }, \u0026#39;/logs/guardduty\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;processed_guardduty\u0026#39; }, \u0026#39;/logs/vpc\u0026#39;: { \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;vpc_logs\u0026#39; }, \u0026#39;/logs/eni_logs\u0026#39;:{ \u0026#39;db\u0026#39;: \u0026#39;security_logs\u0026#39;, \u0026#39;table\u0026#39;: \u0026#39;eni_flow_logs\u0026#39; } } OUTPUT_BUCKET_NAME = os.environ.get(\u0026#34;ATHENA_OUTPUT_BUCKET\u0026#34;) REGION = os.environ.get(\u0026#34;REGION\u0026#34;) OUTPUT_BUCKET = f\u0026#39;s3://{OUTPUT_BUCKET_NAME}/\u0026#39; def lambda_handler(event, context): print(\u0026#34;Received event:\u0026#34;, json.dumps(event)) resource_path = event.get(\u0026#39;resource\u0026#39;) config = RESOURCE_MAP.get(resource_path) if not config: return api_response(400, {\u0026#39;error\u0026#39;: f\u0026#39;Unknown resource path: {resource_path}\u0026#39;}) database_name = config[\u0026#39;db\u0026#39;] table_name = config[\u0026#39;table\u0026#39;] query_params = event.get(\u0026#39;queryStringParameters\u0026#39;, {}) or {} if config[\u0026#39;table\u0026#39;] == \u0026#39;processed_cloudtrail\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by eventtime desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;processed_guardduty\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by date desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;vpc_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp desc\u0026#34;\u0026#34;\u0026#34; elif config[\u0026#39;table\u0026#39;] == \u0026#39;eni_flow_logs\u0026#39;: query_string = f\u0026#34;\u0026#34;\u0026#34;SELECT * FROM {table_name} where \u0026#34;date\u0026#34; \u0026gt;= cast((current_date - interval \u0026#39;3\u0026#39; day) as varchar) order by timestamp_str desc\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Querying DB: {database_name}, Table: {table_name}, Output: {OUTPUT_BUCKET}\u0026#34;) try: response = athena.start_query_execution( QueryString=query_string, QueryExecutionContext={\u0026#39;Database\u0026#39;: database_name}, ResultConfiguration={\u0026#39;OutputLocation\u0026#39;: OUTPUT_BUCKET} ) query_execution_id = response[\u0026#39;QueryExecutionId\u0026#39;] status = \u0026#39;RUNNING\u0026#39; while status in [\u0026#39;RUNNING\u0026#39;, \u0026#39;QUEUED\u0026#39;]: response = athena.get_query_execution(QueryExecutionId=query_execution_id) status = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;][\u0026#39;State\u0026#39;] if status in [\u0026#39;FAILED\u0026#39;, \u0026#39;CANCELLED\u0026#39;]: reason = response[\u0026#39;QueryExecution\u0026#39;][\u0026#39;Status\u0026#39;].get(\u0026#39;StateChangeReason\u0026#39;, \u0026#39;Unknown\u0026#39;) return api_response(500, {\u0026#39;error\u0026#39;: f\u0026#39;Query Failed: {reason}\u0026#39;}) time.sleep(1) results = athena.get_query_results(QueryExecutionId=query_execution_id) return api_response(200, results) except Exception as e: print(f\u0026#34;Error: {str(e)}\u0026#34;) return api_response(500, {\u0026#39;error\u0026#39;: str(e)}) def api_response(code, body): return { \u0026#34;statusCode\u0026#34;: code, \u0026#34;headers\u0026#34;: { \u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;, \u0026#34;Access-Control-Allow-Origin\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Access-Control-Allow-Methods\u0026#34;: \u0026#34;GET, OPTIONS\u0026#34; }, \u0026#34;body\u0026#34;: json.dumps(body) } "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.10-cleanup/5.10.2-cdk-cleanup/","title":"Dọn dẹp CDK","tags":[],"description":"","content":"Clean up (CDK) Hướng dẫn này đảm bảo bạn hủy bỏ (decommission) chính xác tất cả các tài nguyên được cung cấp bởi AWS CDK stack và dọn dẹp dữ liệu được tạo thủ công để tránh các khoản phí phát sinh.\nGiai đoạn 1: Dọn dẹp dữ liệu thủ công (Trước khi CDK Destroy) CDK tự động xóa hầu hết các tài nguyên nhưng không xóa nội dung trong S3 buckets. Bạn phải làm trống nội dung của các buckets này trước khi chạy lệnh cdk destroy.\nTên Resource Mục đích Hành động yêu cầu incident-response-log-list-bucket Nguồn Log Chính Làm trống nội dung processed-cloudwatch-logs ETL Destination Làm trống nội dung processed-guardduty-findings ETL Destination Làm trống nội dung processed-cloudtrail-logs ETL Destination Làm trống nội dung athena-query-results Kết quả truy vấn Athena Làm trống nội dung aws-incident-response-automation-dashboard React Dashboard S3 Bucket Làm trống nội dung Hướng dẫn làm trống Buckets:\nMở Amazon S3 Console trong trình duyệt của bạn. Đối với mỗi buckets được liệt kê ở trên (tìm tên dựa trên AWS Account ID và Region của bạn): Nhấn vào tên bucket. Điều hướng đến tab \u0026ldquo;Objects\u0026rdquo;. Nhấn nút \u0026ldquo;Empty\u0026rdquo;. Làm theo các lời nhắc để xác nhận xóa vĩnh viễn tất cả các objects. Giai đoạn 2: CDK Stack Destruction Bước này sử dụng CDK CLI để phá hủy tất cả các tài nguyên được cung cấp bởi CloudFormation stack.\nĐảm bảo môi trường ảo (Virtual Environment) đang hoạt động\nNếu bạn đã tắt môi trường Python, hãy kích hoạt lại nó (ví dụ: source .venv/bin/activate). Điều hướng đến Project Root\nĐảm bảo bạn đang ở thư mục chính nơi chứa file cdk.json. Thực thi lệnh Destroy\nChạy lệnh để phá hủy tất cả các stacks đã triển khai. Khi được nhắc, gõ y để chấp nhận việc xóa. $ cdk destroy --all Giai đoạn 3: Dọn dẹp sau khi phá hủy Bước này giải quyết việc dọn dẹp thủ công các tài nguyên còn sót lại.\nXóa các S3 Buckets còn lại\nLệnh cdk destroy sẽ xóa các S3 buckets trống. Nếu còn sót lại bucket nào (do kiểm tra cuối cùng hoặc bảo vệ dịch vụ), hãy xóa chúng ngay bây giờ qua S3 Console. Vô hiệu hóa Amazon GuardDuty\nVào GuardDuty Console → Settings → General. Xác minh dịch vụ đã bị vô hiệu hóa để đảm bảo ngừng tính phí. Xóa Cognito User và Pool\nVào Cognito Console → User pools. Xóa test user bạn đã tạo. Xóa User Pool đã tạo cho dashboard. Xóa SES Identity\nVào Amazon SES Console → Verified Identities. Xóa sender email identity (sender_email) bạn đã xác minh. Hủy kích hoạt môi trường ảo\nHủy kích hoạt môi trường ảo Python: $ deactivate "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.2-prerequiste/","title":"Điều kiện tiên quyết","tags":[],"description":"","content":"Các yêu cầu về Truy cập và Thông tin Trước khi tiến hành thiết lập Hệ thống Phản hồi Sự cố và Điều tra số AWS Tự động (Automated AWS Incident Response and Forensics System), hãy đảm bảo bạn đã thu thập đủ các thông tin và quyền truy cập cần thiết dưới đây.\n🔑 Truy cập \u0026amp; Định danh Tài khoản AWS với Quyền Quản trị (Administrative Access) Bạn cần toàn quyền quản trị để tạo tài nguyên trên nhiều dịch vụ AWS. Truy cập vào AWS Management Console. AWS Account ID của bạn Định dạng: số có 12 chữ số (ví dụ: 123456789012). Placeholder: Thay thế ACCOUNT_ID trong toàn bộ hướng dẫn. AWS Region Mục tiêu Chọn region nơi bạn sẽ triển khai hệ thống (ví dụ: us-east-1). Placeholder: Thay thế REGION trong toàn bộ hướng dẫn. VPC ID Một VPC có ít nhất một subnet được yêu cầu cho VPC Flow Logs. Placeholder: Thay thế YOUR_VPC_ID trong hướng dẫn. Địa chỉ Email đã xác thực Amazon SES Cần thiết để gửi và nhận thông báo qua email. Xác thực địa chỉ này trong SES Console. Placeholder: Thay thế YOUR_VERIFIED_EMAIL@example.com. Slack Webhook URL (Tùy chọn) Nếu bạn muốn nhận thông báo qua Slack, hãy lấy webhook URL từ Slack workspace của bạn. Placeholder: Thay thế YOUR_SLACK_WEBHOOK_URL. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.2-guardduty-etl/","title":"Mã GuardDuty ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime from urllib.parse import unquote_plus s3_client = boto3.client(\u0026#39;s3\u0026#39;) DATABASE_NAME = os.environ.get(\u0026#34;DATABASE_NAME\u0026#34;, \u0026#34;security_logs\u0026#34;) TABLE_NAME_GUARDDUTY = os.environ.get(\u0026#34;TABLE_NAME_GUARDDUTY\u0026#34;, \u0026#34;processed_guardduty\u0026#34;) S3_LOCATION_GUARDDUTY = os.environ.get(\u0026#34;S3_LOCATION_GUARDDUTY\u0026#34;, \u0026#34;s3://vel-processed-guardduty/processed-guardduty/\u0026#34;) DESTINATION_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;, \u0026#34;vel-processed-guardduty\u0026#34;) def promote_network_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) net_conn_action = action.get(\u0026#39;networkConnectionAction\u0026#39;, {}) if net_conn_action: remote_ip = net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;) or \\ net_conn_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV6\u0026#39;) return { \u0026#39;remote_ip\u0026#39;: remote_ip, \u0026#39;remote_port\u0026#39;: net_conn_action.get(\u0026#39;remotePortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), \u0026#39;connection_direction\u0026#39;: net_conn_action.get(\u0026#39;connectionDirection\u0026#39;), \u0026#39;protocol\u0026#39;: net_conn_action.get(\u0026#39;protocol\u0026#39;), } dns_action = action.get(\u0026#39;dnsRequestAction\u0026#39;, {}) if dns_action: return {\u0026#39;dns_domain\u0026#39;: dns_action.get(\u0026#39;domain\u0026#39;), \u0026#39;dns_protocol\u0026#39;: dns_action.get(\u0026#39;protocol\u0026#39;)} port_probe_action = action.get(\u0026#39;portProbeAction\u0026#39;, {}) if port_probe_action and port_probe_action.get(\u0026#39;portProbeDetails\u0026#39;): detail = port_probe_action[\u0026#39;portProbeDetails\u0026#39;][0] return { \u0026#39;scanned_ip\u0026#39;: detail.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), \u0026#39;scanned_port\u0026#39;: detail.get(\u0026#39;localPortDetails\u0026#39;, {}).get(\u0026#39;port\u0026#39;), } return {} def promote_api_details(finding_service): if not finding_service: return {} action = finding_service.get(\u0026#39;action\u0026#39;, {}) aws_api_action = action.get(\u0026#39;awsApiCallAction\u0026#39;, {}) if aws_api_action: return { \u0026#39;aws_api_service\u0026#39;: aws_api_action.get(\u0026#39;serviceName\u0026#39;), \u0026#39;aws_api_name\u0026#39;: aws_api_action.get(\u0026#39;api\u0026#39;), \u0026#39;aws_api_caller_type\u0026#39;: aws_api_action.get(\u0026#39;callerType\u0026#39;), \u0026#39;aws_api_error\u0026#39;: aws_api_action.get(\u0026#39;errorCode\u0026#39;), \u0026#39;aws_api_remote_ip\u0026#39;: aws_api_action.get(\u0026#39;remoteIpDetails\u0026#39;, {}).get(\u0026#39;ipAddressV4\u0026#39;), } return {} def promote_resource_details(finding_resource): if not finding_resource: return {} instance_details = finding_resource.get(\u0026#39;instanceDetails\u0026#39;, {}) if instance_details: return { \u0026#39;target_resource_arn\u0026#39;: instance_details.get(\u0026#39;arn\u0026#39;), \u0026#39;instance_id\u0026#39;: instance_details.get(\u0026#39;instanceId\u0026#39;), \u0026#39;resource_region\u0026#39;: instance_details.get(\u0026#39;awsRegion\u0026#39;), \u0026#39;instance_type\u0026#39;: instance_details.get(\u0026#39;instanceType\u0026#39;), \u0026#39;image_id\u0026#39;: instance_details.get(\u0026#39;imageId\u0026#39;), \u0026#39;instance_tags\u0026#39;: instance_details.get(\u0026#39;tags\u0026#39;) } access_key_details = finding_resource.get(\u0026#39;accessKeyDetails\u0026#39;, {}) if access_key_details: return { \u0026#39;access_key_id\u0026#39;: access_key_details.get(\u0026#39;accessKeyId\u0026#39;), \u0026#39;principal_id\u0026#39;: access_key_details.get(\u0026#39;principalId\u0026#39;), \u0026#39;user_name\u0026#39;: access_key_details.get(\u0026#39;userName\u0026#39;), } s3_details = finding_resource.get(\u0026#39;s3BucketDetails\u0026#39;, []) if s3_details: return { \u0026#39;target_resource_arn\u0026#39;: s3_details[0].get(\u0026#39;arn\u0026#39;), \u0026#39;s3_bucket_name\u0026#39;: s3_details[0].get(\u0026#39;name\u0026#39;), } return {} def process_guardduty_log(bucket, key): response = s3_client.get_object(Bucket=bucket, Key=key) if key.endswith(\u0026#39;.gz\u0026#39;): content = gzip.decompress(response[\u0026#39;Body\u0026#39;].read()).decode(\u0026#39;utf-8\u0026#39;) else: content = response[\u0026#39;Body\u0026#39;].read().decode(\u0026#39;utf-8\u0026#39;) processed_findings = [] for line in content.splitlines(): if not line: continue try: finding = json.loads(line) except json.JSONDecodeError: print(f\u0026#34;Skipping malformed JSON line in {key}\u0026#34;); continue finding_type = finding.get(\u0026#39;type\u0026#39;, \u0026#39;UNKNOWN\u0026#39;) finding_service = finding.get(\u0026#39;service\u0026#39;, {}) network_fields = promote_network_details(finding_service) api_fields = promote_api_details(finding_service) resource_fields = promote_resource_details(finding.get(\u0026#39;resource\u0026#39;, {})) created_at_str = finding.get(\u0026#39;createdAt\u0026#39;) event_last_seen_str = finding_service.get(\u0026#39;eventLastSeen\u0026#39;) dt_obj = datetime.now() if event_last_seen_str: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(event_last_seen_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass elif created_at_str: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%S.%fZ\u0026#39;) except ValueError: try: dt_obj = datetime.strptime(created_at_str, \u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) except ValueError: pass processed_record = { \u0026#39;finding_id\u0026#39;: finding.get(\u0026#39;id\u0026#39;), \u0026#39;finding_type\u0026#39;: finding_type, \u0026#39;title\u0026#39;: finding.get(\u0026#39;title\u0026#39;), \u0026#39;severity\u0026#39;: finding.get(\u0026#39;severity\u0026#39;), \u0026#39;account_id\u0026#39;: finding.get(\u0026#39;accountId\u0026#39;), \u0026#39;region\u0026#39;: finding.get(\u0026#39;region\u0026#39;), \u0026#39;created_at\u0026#39;: created_at_str, \u0026#39;event_last_seen\u0026#39;: event_last_seen_str, **network_fields, **api_fields, **resource_fields, \u0026#39;date\u0026#39;: dt_obj.strftime(\u0026#39;%Y-%m-%d\u0026#39;), \u0026#39;service_raw\u0026#39;: json.dumps(finding_service), \u0026#39;resource_raw\u0026#39;: json.dumps(finding.get(\u0026#39;resource\u0026#39;, {})), \u0026#39;metadata_raw\u0026#39;: json.dumps(finding.get(\u0026#39;metadata\u0026#39;, {})), } processed_findings.append(processed_record) return processed_findings def save_processed_data(processed_events, source_key): if not processed_events: return first_event = processed_events[0] date_str = first_event.get(\u0026#39;date\u0026#39;, datetime.now().strftime(\u0026#39;%Y-%m-%d\u0026#39;)) original_filename = source_key.split(\u0026#39;/\u0026#39;)[-1].replace(\u0026#39;.gz\u0026#39;, \u0026#39;\u0026#39;).replace(\u0026#39;.json\u0026#39;, \u0026#39;\u0026#39;) output_key = f\u0026#34;processed-guardduty/date={date_str}/{original_filename}_processed.jsonl.gz\u0026#34; json_lines = \u0026#34;\u0026#34; for event in processed_events: event_to_dump = event.copy() json_lines += json.dumps(event_to_dump) + \u0026#34;\\n\u0026#34; compressed_data = gzip.compress(json_lines.encode(\u0026#39;utf-8\u0026#39;)) s3_client.put_object( Bucket=DESTINATION_BUCKET, Key=output_key, Body=compressed_data, ContentType=\u0026#39;application/jsonl\u0026#39;, ContentEncoding=\u0026#39;gzip\u0026#39; ) print(f\u0026#34;Saved processed data to: s3://{DESTINATION_BUCKET}/{output_key}\u0026#34;) def lambda_handler(event, context): for record in event[\u0026#39;Records\u0026#39;]: bucket = record[\u0026#39;s3\u0026#39;][\u0026#39;bucket\u0026#39;][\u0026#39;name\u0026#39;] key = unquote_plus(record[\u0026#39;s3\u0026#39;][\u0026#39;object\u0026#39;][\u0026#39;key\u0026#39;]) print(f\u0026#34;Processing GuardDuty finding file: s3://{bucket}/{key}\u0026#34;) try: processed_findings = process_guardduty_log(bucket, key) save_processed_data(processed_findings, key) print(f\u0026#34;Successfully processed {len(processed_findings)} findings from {key}\u0026#34;) except Exception as e: print(f\u0026#34;Error processing {key}: {str(e)}\u0026#34;) raise e return { \u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: json.dumps(\u0026#39;GuardDuty findings processed successfully\u0026#39;) } "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.2-create-aws-glue-database-and-tables/","title":"Tạo AWS Glue Database và Tables","tags":[],"description":"","content":"Tạo AWS Glue Database và Tables Tạo Database Mở Glue Console → Databases → Add database\nDatabase name: security_logs\nCreate database\nTạo Tables (Sử dụng Athena DDL) Mở Athena Console\nĐặt vị trí lưu kết quả truy vấn (query result location): s3://athena-query-results-ACCOUNT_ID-REGION/\nChọn database: security_logs\nTạo bảng processed_cloudtrail Chạy DDL này trong Athena (thay thế ACCOUNT_ID và REGION):\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_cloudtrail ( `eventtime` string, `eventname` string, `eventsource` string, `awsregion` string, `sourceipaddress` string, `useragent` string, `useridentity` struct\u0026lt; type:string, invokedby:string, principalid:string, arn:string, accountid:string, accesskeyid:string, username:string, sessioncontext:struct\u0026lt; attributes:map\u0026lt;string,string\u0026gt;, sessionissuer:struct\u0026lt; type:string, principalid:string, arn:string, accountid:string, username:string \u0026gt; \u0026gt;, inscopeof:struct\u0026lt; issuertype:string, credentialsissuedto:string \u0026gt; \u0026gt;, `requestparameters` string, `responseelements` string, `resources` array\u0026lt;struct\u0026lt;arn:string,type:string\u0026gt;\u0026gt;, `recipientaccountid` string, `serviceeventdetails` string, `errorcode` string, `errormessage` string, `hour` string, `usertype` string, `username` string, `isconsolelogin` boolean, `isfailedlogin` boolean, `isrootuser` boolean, `isassumedrole` boolean, `ishighriskevent` boolean, `isprivilegedaction` boolean, `isdataaccess` boolean, `target_bucket` string, `target_key` string, `target_username` string, `target_rolename` string, `target_policyname` string, `new_access_key` string, `new_instance_id` string, `target_group_id` string, `identity_principalid` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudtrail-logs-ACCOUNT_ID-REGION/processed-cloudtrail/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng processed_guardduty Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.processed_guardduty ( `finding_id` string, `finding_type` string, `title` string, `severity` double, `account_id` string, `region` string, `created_at` string, `event_last_seen` string, `remote_ip` string, `remote_port` int, `connection_direction` string, `protocol` string, `dns_domain` string, `dns_protocol` string, `scanned_ip` string, `scanned_port` int, `aws_api_service` string, `aws_api_name` string, `aws_api_caller_type` string, `aws_api_error` string, `aws_api_remote_ip` string, `target_resource_arn` string, `instance_id` string, `instance_type` string, `image_id` string, `instance_tags` string, `resource_region` string, `access_key_id` string, `principal_id` string, `user_name` string, `s3_bucket_name` string, `service_raw` string, `resource_raw` string, `metadata_raw` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/\u0026#39; TBLPROPERTIES ( \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39;, \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-guardduty-findings-ACCOUNT_ID-REGION/processed-guardduty/date=${date}/\u0026#39; ); Tạo bảng vpc_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.vpc_logs ( `version` string, `account_id` string, `region` string, `vpc_id` string, `query_timestamp` string, `query_name` string, `query_type` string, `query_class` string, `rcode` string, `answers` string, `srcaddr` string, `srcport` int, `transport` string, `srcids_instance` string, `timestamp` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;ignore.malformed.json\u0026#39; = \u0026#39;true\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/vpc-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); Tạo bảng eni_flow_logs Chạy DDL này trong Athena:\nCREATE EXTERNAL TABLE IF NOT EXISTS security_logs.eni_flow_logs ( `version` int, `account_id` string, `interface_id` string, `srcaddr` string, `dstaddr` string, `srcport` int, `dstport` int, `protocol` int, `packets` bigint, `bytes` bigint, `start_time` bigint, `end_time` bigint, `action` string, `log_status` string, `timestamp_str` string ) PARTITIONED BY ( `date` string ) ROW FORMAT SERDE \u0026#39;org.openx.data.jsonserde.JsonSerDe\u0026#39; WITH SERDEPROPERTIES ( \u0026#39;serialization.format\u0026#39; = \u0026#39;1\u0026#39; ) LOCATION \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/\u0026#39; TBLPROPERTIES ( \u0026#39;projection.enabled\u0026#39; = \u0026#39;true\u0026#39;, \u0026#39;projection.date.type\u0026#39; = \u0026#39;date\u0026#39;, \u0026#39;projection.date.format\u0026#39; = \u0026#39;yyyy-MM-dd\u0026#39;, \u0026#39;projection.date.range\u0026#39; = \u0026#39;2025-01-01,NOW\u0026#39;, \u0026#39;projection.date.interval\u0026#39; = \u0026#39;1\u0026#39;, \u0026#39;projection.date.interval.unit\u0026#39; = \u0026#39;DAYS\u0026#39;, \u0026#39;storage.location.template\u0026#39; = \u0026#39;s3://processed-cloudwatch-logs-ACCOUNT_ID-REGION/eni-flow-logs/date=${date}/\u0026#39;, \u0026#39;classification\u0026#39; = \u0026#39;json\u0026#39;, \u0026#39;compressionType\u0026#39; = \u0026#39;gzip\u0026#39; ); "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.2-create-service-roles/","title":"Tạo Service Roles","tags":[],"description":"","content":"Tạo Firehose Roles Tạo CloudTrailFirehoseRole Mở IAM Console → Roles → Create role\nChọn trusted entity:\nTrusted entity type: AWS service Use case: Chọn \u0026ldquo;Kinesis\u0026rdquo; → \u0026ldquo;Kinesis Firehose\u0026rdquo; Nhấn \u0026ldquo;Next\u0026rdquo; Thêm permissions:\nBỏ qua việc thêm managed policies (chúng ta sẽ thêm inline policy) Nhấn \u0026ldquo;Next\u0026rdquo; Đặt tên và tạo:\nRole name: CloudTrailFirehoseRole Description: Allows Firehose to write CloudTrail logs to S3 Nhấn \u0026ldquo;Create role\u0026rdquo; Thêm inline policy:\nPolicy name: FirehosePolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo CloudWatchFirehoseRole Role name: CloudWatchFirehoseRole Description: Allows Firehose to write CloudWatch logs to S3 Trusted entity: Kinesis Firehose Inline policy name: FirehosePolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:PutObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/*\u0026#34; ] } ] } Tạo Step Functions Role Tạo StepFunctionsRole Tạo role:\nTrusted entity: Step Functions Role name: StepFunctionsRole Description: Execution role for Incident Response Step Functions Thêm HAI inline policies:\nPolicy 1: LambdaInvokePolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;lambda:InvokeFunction\u0026#34;, \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-parse-findings-lambda\u0026#34;, \u0026#34;arn:aws:lambda:REGION:ACCOUNT_ID:function:ir-quarantine-iam-lambda\u0026#34; ] } ] } Policy 2: EC2AutoScalingPolicy\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;autoscaling:DescribeAutoScalingInstances\u0026#34;, \u0026#34;autoscaling:DetachInstances\u0026#34;, \u0026#34;autoscaling:UpdateAutoScalingGroup\u0026#34;, \u0026#34;ec2:CreateSnapshot\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:DescribeVolumes\u0026#34;, \u0026#34;ec2:ModifyInstanceAttribute\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo EventBridge Role Tạo IncidentResponseStepFunctionsEventRole Role name: IncidentResponseStepFunctionsEventRole Description: Allows EventBridge to trigger Step Functions Trusted entity: EventBridge Inline policy name: StartStepFunctionsPolicy Inline policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;states:StartExecution\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:REGION:ACCOUNT_ID:stateMachine:IncidentResponseStepFunctions\u0026#34; } ] } Tạo VPC Flow Logs Role Tạo FlowLogsIAMRole Tạo role:\nTrusted entity: EC2 (will edit trust policy - sẽ chỉnh sửa trust policy sau) Role name: FlowLogsIAMRole Chỉnh sửa trust relationship thành:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;vpc-flow-logs.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } Thêm inline policy: Policy name: FlowLogsPolicy Policy JSON: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;logs:CreateLogGroup\u0026#34;, \u0026#34;logs:CreateLogStream\u0026#34;, \u0026#34;logs:DescribeLogGroups\u0026#34;, \u0026#34;logs:DescribeLogStreams\u0026#34;, \u0026#34;logs:PutLogEvents\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Tạo Glue Role Tạo GlueCloudWatchRole Role name: GlueCloudWatchRole Description: Allows Glue to access S3 and CloudWatch Logs Trusted entity: Glue Managed policies (đính kèm 3 policies): AWSGlueServiceRole CloudWatchLogsReadOnlyAccess AmazonS3FullAccess Không cần inline policies "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.2-set-up-s3-buckets-policies/","title":"Thiết lập S3 buckets policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ cấu hình bucket policy cho bucket log chính để cho phép CloudTrail, GuardDuty, và CloudWatch Logs ghi log.\nCấu hình Bucket Policy Điều hướng đến bucket log chính: Trong S3 Console, nhấn vào incident-response-log-list-bucket-ACCOUNT_ID-REGION Mở tab Permissions:\nNhấn vào tab \u0026ldquo;Permissions\u0026rdquo; Cuộn đến Bucket policy:\nCuộn xuống phần \u0026ldquo;Bucket policy\u0026rdquo; Nhấn \u0026ldquo;Edit\u0026rdquo; Dán bucket policy: Copy JSON policy sau Quan trọng: Thay thế ACCOUNT_ID và REGION bằng giá trị thực tế của bạn trong policy { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowGuardDutyGetBucketLocation\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;guardduty.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketLocation\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:guardduty:REGION:ACCOUNT_ID:detector/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsGetBucketAcl\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudWatchLogsPutObject\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;logs.REGION.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:logs:REGION:ACCOUNT_ID:log-group:*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailAclCheck\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } }, { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudTrailWrite\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudtrail.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/AWSLogs/ACCOUNT_ID/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34;, \u0026#34;aws:SourceAccount\u0026#34;: \u0026#34;ACCOUNT_ID\u0026#34; }, \u0026#34;ArnLike\u0026#34;: { \u0026#34;aws:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudtrail:REGION:ACCOUNT_ID:trail/*\u0026#34; } } } ] } Nhấn \u0026ldquo;Save changes\u0026rdquo;\nXác minh policy đã lưu: Bạn sẽ thấy policy hiển thị trong phần Bucket policy\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/4-eventparticipated/4.3-event3/","title":"Sự kiện 3","tags":[],"description":"","content":"Báo cáo Tóm tắt: “AWS Cloud Mastery Series #2 - DevOps trên AWS” Tổng quan Sự kiện Phiên thứ hai của chuỗi AWS Cloud Mastery tập trung vào các thực tiễn và công cụ DevOps có sẵn trên AWS. Sự kiện nhằm cung cấp cho người tham dự sự hiểu biết vững chắc về các nguyên tắc DevOps, Cơ sở hạ tầng dưới dạng Mã (IaC), dịch vụ container, và các giải pháp giám sát để xây dựng các hệ thống dựa trên đám mây có khả năng mở rộng, tin cậy và dễ bảo trì.\nMục tiêu Sự kiện Các mục tiêu chính của sự kiện là:\nGiới thiệu các dịch vụ AWS DevOps, bao gồm các đường ống CI/CD. Khám phá các khái niệm và công cụ Cơ sở hạ tầng dưới dạng Mã (IaC) như AWS CloudFormation, AWS CDK, và Terraform. Cung cấp thông tin chi tiết về các dịch vụ container trên AWS, bao gồm Amazon ECS, EKS, và App Runner. Nêu bật tầm quan trọng của việc giám sát và khả năng quan sát sử dụng các dịch vụ AWS như CloudWatch và AWS X-Ray. Diễn giả Sự kiện có sự tham gia của một nhóm các AWS Community Builders và chuyên gia đám mây giàu kinh nghiệm:\nTruong Quang Tinh – Platform Engineer, TymeX Bao Huynh – AWS Community Builder Nguyen Khanh Phuc Thinh – AWS Community Builder Tran Dai Vi – AWS Community Builder Huynh Hoang Long – AWS Community Builder Pham Hoang Quy – AWS Community Builder Nghiem Le – AWS Community Builder Dinh Le Hoang Anh – Cloud Engineer Trainee, First Cloud AI Journey Điểm nổi bật Chính Tư duy DevOps Phiên họp bắt đầu với phần giới thiệu về văn hóa DevOps và các nguyên tắc cốt lõi của nó:\nHợp tác: Phá vỡ rào cản giữa đội ngũ phát triển và vận hành. Tự động hóa: Hợp lý hóa các nhiệm vụ lặp đi lặp lại để cải thiện hiệu quả. Học tập Liên tục: Khuyến khích thử nghiệm và học hỏi từ thất bại. Đo lường: Sử dụng các chỉ số để theo dõi tiến độ và tối ưu hóa quy trình. Các vai trò chính trong DevOps:\nKỹ sư DevOps Kỹ sư Cloud Kỹ sư Nền tảng (Platform Engineer) Kỹ sư Độ tin cậy Trang web (SRE) Chỉ số Thành công:\nTần suất và tình trạng triển khai Sự ổn định và độ tin cậy của hệ thống Cải thiện sự linh hoạt và trải nghiệm khách hàng Biện minh cho các khoản đầu tư công nghệ Thực tiễn Tốt nhất:\nNÊN (DO) KHÔNG NÊN (DON\u0026rsquo;T) Bắt đầu với các nguyên tắc cơ bản Mắc kẹt trong hướng dẫn (tutorial hell) Học bằng cách xây dựng dự án thực tế Copy-paste một cách mù quáng Tài liệu hóa mọi thứ So sánh tiến độ của bạn với người khác Làm chủ từng thứ một Bỏ cuộc sau thất bại Nâng cao kỹ năng mềm - Tích hợp Liên tục: Các thành viên trong nhóm tích hợp công việc của họ thường xuyên, hướng tới Chuyển giao và Triển khai liên tục\nCơ sở hạ tầng dưới dạng Mã (IaC) Sự kiện đã cung cấp cái nhìn sâu sắc về Cơ sở hạ tầng dưới dạng Mã (IaC) và lợi ích của nó:\nTự động hóa: Giảm sự can thiệp thủ công và các lỗi tiềm ẩn. Khả năng mở rộng: Dễ dàng mở rộng cơ sở hạ tầng lên hoặc xuống dựa trên nhu cầu. Khả năng tái tạo: Đảm bảo môi trường nhất quán từ phát triển đến sản xuất. Hợp tác: Tăng cường làm việc nhóm giữa phát triển và vận hành. AWS CloudFormation: Công cụ IaC gốc của AWS, cho phép người dùng định nghĩa và cung cấp cơ sở hạ tầng AWS bằng cách sử dụng định dạng mẫu khai báo (YAML hoặc JSON).\nStack: Một tập hợp các tài nguyên AWS được quản lý như một đơn vị duy nhất. CloudFormation Template: Một tệp mô tả các tài nguyên cơ sở hạ tầng cần thiết cho một ứng dụng hoặc dịch vụ cụ thể. Drift Detection: Xác định và sửa chữa sự khác biệt giữa cấu hình thực tế của stack và cấu hình mong đợi của nó. AWS Cloud Development Kit (CDK): Một khung phát triển phần mềm mã nguồn mở cho phép người dùng định nghĩa cơ sở hạ tầng đám mây bằng ngôn ngữ lập trình tùy chọn.\nConstruct: Khối xây dựng cơ bản của AWS CDK, đại diện cho một đơn vị triển khai duy nhất. AWS Amplify: Một nền tảng phát triển để xây dựng các ứng dụng di động và web an toàn, có thể mở rộng.\nTerraform: Một công cụ IaC mã nguồn mở cho phép người dùng định nghĩa và cung cấp cơ sở hạ tầng trung tâm dữ liệu bằng ngôn ngữ cấu hình cấp cao.\nĐiểm mạnh: Hỗ trợ đa đám mây, quản lý trạng thái, và hệ sinh thái mô-đun lớn. Tiêu chí chọn Công cụ IaC:\nYêu cầu dự án: đám mây đơn vs. đa đám mây Ch chuyên môn của nhóm: tập trung vào nhà phát triển hay vận hành Hệ sinh thái và hỗ trợ cộng đồng Dịch vụ Container trên AWS Sự kiện bao gồm các dịch vụ container khác nhau do AWS cung cấp và cách chúng phù hợp với bối cảnh DevOps:\nDocker: Một nền tảng để phát phát triển, vận chuyển và chạy các ứng dụng trong container. Amazon ECR (Elastic Container Registry): Một registry container Docker được quản lý hoàn toàn giúp dễ dàng lưu trữ, quản lý và triển khai các image container Docker. Amazon ECS (Elastic Container Service): Một dịch vụ điều phối container được quản lý hoàn toàn hỗ trợ các container Docker. Amazon EKS (Elastic Kubernetes Service): Một dịch vụ được quản lý giúp đơn giản hóa việc chạy Kubernetes trên AWS mà không cần cài đặt và vận hành control plane hoặc node Kubernetes của riêng bạn. AWS App Runner: Một dịch vụ giúp dễ dàng triển khai nhanh chóng các ứng dụng web và API được container hóa. Điều phối Container với ECS và EKS:\nECS: Dịch vụ điều phối container gốc của AWS, tích hợp chặt chẽ với các dịch vụ AWS khác. EKS: Một dịch vụ Kubernetes được quản lý, cung cấp sự linh hoạt và kiểm soát của Kubernetes mà không cần chi phí vận hành. Giám sát \u0026amp; Khả năng quan sát Phiên cuối cùng tập trung vào các giải pháp giám sát và khả năng quan sát có sẵn trên AWS:\nAmazon CloudWatch: Một dịch vụ giám sát và khả năng quan sát cung cấp dữ liệu và thông tin chi tiết có thể hành động để giám sát các ứng dụng, phản ứng với các thay đổi hiệu suất toàn hệ thống, và tối ưu hóa sử dụng tài nguyên. AWS X-Ray: Một dịch vụ giúp các nhà phát triển phân tích và gỡ lỗi các ứng dụng phân tán, sản xuất, chẳng hạn như những ứng dụng được xây dựng bằng kiến trúc vi dịch vụ. Các tính năng Chính:\nCloudWatch Metrics: Giám sát và thu thập các chỉ số từ tài nguyên AWS và ứng dụng. CloudWatch Alarms: Tự động phản ứng với các thay đổi trong tài nguyên AWS của bạn. CloudWatch Logs: Giám sát, lưu trữ và truy cập các tệp nhật ký từ các phiên bản Amazon EC2, AWS CloudTrail và các nguồn khác. X-Ray Tracing: Phân tích và gỡ lỗi các ứng dụng phân tán, cung cấp thông tin chi tiết về các tắc nghẽn hiệu suất và lỗi. Trải nghiệm Sự kiện Sự kiện này rất quan trọng đối với dự án của chúng tôi vì nó giải quyết kế hoạch thêm IaC bằng CDK, thay vì sử dụng ClickOps để dễ bảo trì và tái tạo. Ngoài ra, một số thông tin chi tiết hơn về CloudWatch đã giúp ích rất nhiều cho tính năng giám sát dữ liệu của chúng tôi.\nCác diễn giả đã trả lời câu hỏi của nhóm chúng tôi:\nHỏi: Dự án của chúng tôi cho đến nay hoàn toàn được xây dựng bằng ClickOps, và chúng tôi đang có kế hoạch sử dụng CDK. Có công cụ nào có thể quét và chuyển cơ sở hạ tầng hiện tại của chúng tôi thành CDK hoặc CloudFormation thay vì tái tạo lại cơ sở hạ tầng từ đầu bằng IaC không?\nĐáp: Rất tiếc là không, chưa có công cụ nào có thể hỗ trợ vấn đề đó, nhóm của bạn sẽ phải xây dựng lại cơ sở hạ tầng từ đầu. Nếu bạn tình cờ tìm thấy một công cụ có thể hỗ trợ, vui lòng chia sẻ với chúng tôi.\nHỏi: Chúng tôi nhận thấy rằng AWS X-Ray được sử dụng với CloudWatch tương tự như CloudTrail trong phương pháp theo dõi của nó, bạn có thể giải thích thêm về sự khác biệt giữa chúng không?\nĐáp: X-Ray được sử dụng cho CloudWatch và dùng để theo dõi các tài nguyên và dịch vụ mà hệ thống đã tương tác, trong khi CloudTrail thường được sử dụng để theo dõi các hành động của người dùng AWS.\nHỏi: Dự án của chúng tôi được xây dựng xung quanh GuardDuty Findings, bạn có kinh nghiệm nào về cách kích hoạt Findings một cách đáng tin cậy cho các kịch bản demo không?\nĐáp: Theo kinh nghiệm của tôi, tôi biết rằng Guard Duty Findings có thể được kích hoạt bởi các hoạt động quét cổng nhưng tôi chắc chắn cũng có những cách khác.\nĐáp: Guard Duty có thể được cấu hình để có danh sách mối đe dọa chứa các quy tắc tùy chỉnh để kích hoạt các phát hiện khi có hoạt động liên quan đến các miền hoặc IP độc hại đã định cấu hình.\nSự kiện này cũng là lần đầu tiên một số diễn giả trình bày về một chủ đề:\nCác phần DevOps và IaC được trình bày tốt. Phần Giám sát \u0026amp; Khả năng quan sát không tuyệt vời lắm và chúng tôi có thể nhận thấy sự lo lắng của diễn giả nhưng vẫn mang lại giá trị lớn bất kể điều đó. Một số hình ảnh sự kiện "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.3-week3/","title":"Nhật ký Tuần 3","tags":[],"description":"","content":"Mục tiêu Tuần 3: Học quy trình VM Import/Export để di chuyển máy ảo on-premises lên AWS. Triển khai ứng dụng web đa tầng (FCJ Management) với tính sẵn sàng cao (High Availability). Thực hiện Auto Scaling Groups và Application Load Balancers để tăng khả năng phục hồi. Hiểu cách sử dụng AWS CLI nâng cao cho các tác vụ import và cấu hình IAM role. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành Understanding Research Methods trên Coursera cho môn học khác của tôi (ENW493c) 22/09/2025 22/09/2025 3 - Chưa thể truy cập Lightsail hiện tại nên tôi bỏ qua - Hoàn thành Research Methodologies trên Coursera (ENW493c) - Hoàn thành MOOC Giáo dục và Phát triển nguồn nhân lực số trên Coursera (Chương trình KS57) 23/09/2025 23/09/2025 4 - Hoàn thành Imported/Exported VM đầu cuối giữa VMware Workstation và Amazon EC2. + Tạo một máy ảo Ubuntu sử dụng VMware Workstation và cấu hình OpenSSH để truy cập từ xa bên trong hệ điều hành khách. + Xuất VM từ VMware Workstation dưới dạng gói OVF/VMDK để chuẩn bị di chuyển. + Tạo một S3 import bucket trong AWS Management Console và tải tệp VMDK từ máy cục bộ lên Amazon S3. + Cài đặt và cấu hình AWS CLI trên máy trạm, sau đó tạo vmimport IAM role (trust policy + permissions) sử dụng aws iam create-role và aws iam put-role-policy. + Sử dụng aws ec2 import-image từ AWS CLI để chuyển đổi đối tượng VMDK trong S3 thành một AMI (CẢNH BÁO!!!: Sử dụng các phiên bản LTS 5.x cũ hơn.), sau đó khởi chạy một EC2 instance từ AMI đã import trong EC2 console. + Tạo một S3 export bucket và cấu hình bucket ACL của nó trong S3 console để tài khoản dịch vụ vm-import-export@amazon.com có thể ghi các hình ảnh VM đã xuất. + Chạy aws ec2 create-instance-export-task từ AWS CLI để xuất một EC2 instance/AMI sang S3 export bucket dưới dạng hình ảnh VM để tái sử dụng trong VMware hoặc các trình ảo hóa khác. 24/09/2025 24/09/2025 Installing or updating to the latest version of the AWS CLI Authenticating using IAM user credentials for the AWS CLI VM Import/Export Requirements VIRTUAL MACHINE (VM) IMPORT/EXPORT – AWS Study Group VM Import/Export – What it is and capabilities VM Import/Export Requirements and supported formats Import a VM to Amazon EC2 as an image using VM Import/Export Export an EC2 instance as a VM using VM Import/Export Required permissions for VM Import/Export (vmimport role) 5 Thiết kế và triển khai ngăn xếp ứng dụng quản lý FCJ trên AWS sử dụng EC2, RDS, và Application Load Balancer.\n+ Xem lại các mục tiêu workshop FCJ Management with Auto Scaling Group và kiến trúc tổng thể để hiểu các thành phần AWS cần thiết và luồng lưu lượng truy cập.\n+ Xây dựng cơ sở hạ tầng mạng bằng cách tạo một VPC riêng, các subnet công khai, một Internet Gateway, và cấu hình route tables để truy cập internet cho ứng dụng FCJ.\n+ Khởi chạy một máy chủ ứng dụng FCJ EC2 từ Amazon Linux/Ubuntu AMI, gắn một security group với các quy tắc HTTP/SSH, và xác minh kết nối cơ bản qua IP công khai.\n+ Cài đặt và cấu hình Node.js, npm, và PM2 trên EC2 instance, sao chép mã nguồn ứng dụng FCJ Management, và thiết lập nó như một quy trình PM2 được quản lý để đảm bảo khả năng phục hồi.\n+ Cung cấp một Amazon RDS instance cho cơ sở dữ liệu FCJ, chọn engine và loại instance cần thiết, cấu hình networking/security groups, và kích hoạt kết nối từ FCJ EC2 instance.\n+ Khởi tạo lược đồ cơ sở dữ liệu FCJ và tải dữ liệu mẫu bằng cách chạy các tập lệnh SQL để ứng dụng có thể thực hiện các thao tác CRUD đầu cuối trong quá trình thử nghiệm.\n+ Xác minh kết nối toàn bộ ngăn xếp bằng cách khởi động ứng dụng FCJ trên EC2, kết nối với RDS, và xác nhận rằng các tính năng cốt lõi hoạt động qua HTTP trước khi giới thiệu bất kỳ cân bằng tải hoặc mở rộng nào. 25/09/2025 26/09/2025 Deploying FCJ Management with Auto Scaling Group – AWS Study Group\nPreparation - Deploying FCJ Management with Auto Scaling Group\nDeploy Web Server\nLaunch a Database Instance with RDS\nSetup data for Database 6 Triển khai tính sẵn sàng cao và tự động mở rộng (auto scaling) cho ứng dụng Quản lý FCJ sử dụng Launch Templates, ALB, và nhiều chiến lược mở rộng.\n+ Tạo một AMI từ FCJ EC2 instance đã cấu hình và xây dựng một EC2 Launch Template ghi lại AMI ID, loại instance, networking, security groups, và user data cho các lần triển khai lặp lại.\n+ Cấu hình một Application Load Balancer và Target Group, đăng ký các instance FCJ làm mục tiêu, và xác thực health checks cũng như định tuyến qua tên DNS của ALB.\n+ Thiết lập một EC2 Auto Scaling Group (ASG) sử dụng Launch Template, gắn nó vào Target Group, và xác nhận rằng các instance mới tham gia ALB và phục vụ lưu lượng truy cập chính xác.\n+ Triển khai mở rộng thủ công bằng cách điều chỉnh công suất mong muốn của ASG, quan sát các instance FCJ mới khởi chạy, và xác thực phân phối tải và trạng thái sức khỏe qua ALB.\n+ Cấu hình các hành động mở rộng theo lịch trình để tự động tăng dung lượng trong một khoảng thời gian \u0026ldquo;cao điểm\u0026rdquo; xác định và giảm sau đó, sau đó kiểm tra xem lịch trình đã thực thi như mong đợi chưa.\n+ Triển khai mở rộng động (target‑tracking) dựa trên các số liệu như mức sử dụng CPU hoặc số lượng yêu cầu, chạy kiểm tra tải qua ALB, và quan sát hành vi tự động mở rộng và thu hẹp.\n+ Chuẩn bị các chỉ số CloudWatch tùy chỉnh cho mở rộng dự đoán, tạo chính sách mở rộng dự đoán trên ASG, và xem lại biểu đồ dự báo so với công suất thực tế để hiểu cách các quyết định mở rộng trong tương lai được tạo ra.\n+ Thực hiện kiểm tra đầu cuối của tất cả các chế độ mở rộng (thủ công, theo lịch trình, động, dự đoán), giám sát các sự kiện vòng đời và số liệu instance, và ghi lại các cân nhắc về chi phí cho tài nguyên EC2, RDS, và ALB. 26/09/2025 26/09/2025 Create Launch Template\nSetting Up Load Balancer\nCreate Auto Scaling Group\nTest - Deploying FCJ Management with Auto Scaling Group\nTest solutions - Deploying FCJ Management with Auto Scaling Group\nRead metrics of predictive scaling solution Kết quả đạt được Tuần 3: Đã import thành công một máy ảo Ubuntu cục bộ vào AWS dưới dạng AMI sử dụng vai trò vmimport và AWS CLI. Triển khai Ứng dụng Quản lý FCJ với kiến trúc VPC an toàn (Subnet Công khai/Riêng tư). Cấu hình một Auto Scaling Group phía sau ALB, chứng minh khả năng mở rộng (scale-out) khi nhu cầu tăng đột biến. Xác minh kết nối cơ sở dữ liệu giữa các instance EC2 và lớp cơ sở dữ liệu RDS an toàn bên trong các subnet riêng tư. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/3-blogstranslated/","title":"Các bài blogs đã dịch","tags":[],"description":"","content":"Tại đây sẽ là phần liệt kê, giới thiệu các blogs mà tôi đã dịch:\nBlog 1 - Building a High-Performance Exchange Market Data Broadcasting Platform on AWS Blog này khám phá cách SMC Global Securities Ltd. hiện đại hóa hạ tầng giao dịch của họ bằng AWS. Bài viết trình bày chi tiết việc triển khai hệ thống phát sóng dữ liệu tài chính mạnh mẽ, sử dụng AWS Transit Gateway, Fortinet SD-WAN và công nghệ multicast để xử lý dữ liệu thị trường thời gian thực một cách hiệu quả.\nBlog 2 - Optimize Security Operations with AWS Security Incident Response Blog này cung cấp cái nhìn sâu sắc về việc nâng cao hoạt động bảo mật bằng AWS Security Incident Response. Bài viết đề cập đến việc tích hợp các dịch vụ như Amazon GuardDuty và AWS Security Hub để phát hiện, phân tích và phản ứng với các mối đe dọa bảo mật một cách hiệu quả.\nBlog 3 - Unlocking the Value of Unstructured Data with Amazon Bedrock Data Automation Blog này thảo luận về cách Amazon Bedrock Data Automation giúp các tổ chức quản lý dữ liệu phi cấu trúc. Bài viết làm nổi bật việc tự động hóa lưu trữ dữ liệu, quản trị và trích xuất thông tin từ các định dạng dữ liệu đa dạng như hình ảnh, âm thanh và video.\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.3-setup-api-gateway/","title":"Cài đặt API Gateway","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một API Gateway để định tuyến cuộc gọi api từ dashboard tới Lambda.\nTạo API Gateway Mở API Gateway Console\nĐiều hướng tới https://console.aws.amazon.com/apigateway/ Hoặc: AWS Management Console → Services → API Gateway Tạo API:\nNhấn Create API Chọn REST API và nhấn Build Sử dụng cài đặt này để tạo: Chọn New API Name: dashboard-api API endpoint type: Regional Security policy: SecurityPolicy_TLS13_1_3_2025_09 Endpoint access mode: Basic IP address type: IPv4 Tạo Resources:\nBật CORS cho root resource Nhấn Create resource và đặt tên là logs Sau đó nhấn vào tài nguyên /logs vừa tạo và nhấn Create Resource để tạo tài nguyên con của /logs Đặt tên là cloudtrail và bật CORS Lặp lại ba lần nữa cho eni_logs, guardduty và vpc Tạo methods:\nNhấn vào /cloudtrail vừa tạo và nhấn Create method\nTrong phần tạo method, sử dụng cài đặt này:\nMethod type: GET Intergration type: Lambda function Bật Lambda proxy intergration chọn Buffered Lambda function: chọn region của bạn, tìm kiếm dashboard-query và chọn nó Timout: 29000 Lặp lại ba lần nữa cho eni_logs, guardduty và vpc\nTriển khai API (Deploy API):\nNhấn Deploy API ở góc phải Trong phần deploy API, sử dụng cài đặt này: Stage: New stage Name: prod Nhấn Deploy "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.3-cloudwatch-etl/","title":"Mã CloudWatch ETL","tags":[],"description":"","content":"import json import boto3 import gzip import re import os from datetime import datetime, timezone s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose= boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CẤU HÌNH (CONFIG) # -------------------------------------------------- SOURCE_PREFIX = \u0026#34;exportedlogs/vpc-dns-logs/\u0026#34; FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) VPC_RE = re.compile(r\u0026#34;/(vpc-[0-9A-Za-z\\-]+)\u0026#34;) ISO_TS_RE = re.compile(r\u0026#34;^\\d{4}-\\d{2}-\\d{2}T\u0026#34;) def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def flatten_once(d): out = {} for k, v in (d or {}).items(): if isinstance(v, dict): for k2, v2 in v.items(): out[f\u0026#34;{k}_{k2}\u0026#34;] = v2 else: out[k] = v return out def safe_int(x): try: return int(x) except: return None def parse_dns_line(line): raw = line.strip() if not raw: return None json_part = raw prefix_ts = None if ISO_TS_RE.match(raw): try: prefix_ts, rest = raw.split(\u0026#34; \u0026#34;, 1) json_part = rest except: pass if not json_part.startswith(\u0026#34;{\u0026#34;): idx = json_part.find(\u0026#34;{\u0026#34;) if idx != -1: json_part = json_part[idx:] try: obj = json.loads(json_part) except: return None flat = flatten_once(obj) if prefix_ts: flat[\u0026#34;_prefix_ts\u0026#34;] = prefix_ts return flat def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] if not key.startswith(SOURCE_PREFIX) or not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping file: {key}\u0026#34;) continue print(f\u0026#34;Processing S3 file: {key}\u0026#34;) # Trích xuất VPC ID từ đường dẫn file (Extract VPC ID from file path) vpc_id_match = VPC_RE.search(key) vpc_id = vpc_id_match.group(1) if vpc_id_match else \u0026#34;unknown\u0026#34; # Đọc và xử lý nội dung file (Read and process file content) content = read_gz(bucket, key) if not content: continue for line in content.splitlines(): r = parse_dns_line(line) if not r: continue # Tạo flattened JSON record (Create flattened JSON record) out = { \u0026#34;version\u0026#34;: r.get(\u0026#34;version\u0026#34;), \u0026#34;account_id\u0026#34;: r.get(\u0026#34;account_id\u0026#34;), \u0026#34;region\u0026#34;: r.get(\u0026#34;region\u0026#34;), \u0026#34;vpc_id\u0026#34;: r.get(\u0026#34;vpc_id\u0026#34;, vpc_id), \u0026#34;query_timestamp\u0026#34;: r.get(\u0026#34;query_timestamp\u0026#34;), \u0026#34;query_name\u0026#34;: r.get(\u0026#34;query_name\u0026#34;), \u0026#34;query_type\u0026#34;: r.get(\u0026#34;query_type\u0026#34;), \u0026#34;query_class\u0026#34;: r.get(\u0026#34;query_class\u0026#34;), \u0026#34;rcode\u0026#34;: r.get(\u0026#34;rcode\u0026#34;), \u0026#34;answers\u0026#34;: json.dumps(r.get(\u0026#34;answers\u0026#34;), ensure_ascii=False), \u0026#34;srcaddr\u0026#34;: r.get(\u0026#34;srcaddr\u0026#34;), \u0026#34;srcport\u0026#34;: safe_int(r.get(\u0026#34;srcport\u0026#34;)), \u0026#34;transport\u0026#34;: r.get(\u0026#34;transport\u0026#34;), \u0026#34;srcids_instance\u0026#34;: r.get(\u0026#34;srcids_instance\u0026#34;), \u0026#34;timestamp\u0026#34;: (r.get(\u0026#34;query_timestamp\u0026#34;) or r.get(\u0026#34;timestamp\u0026#34;) or r.get(\u0026#34;_prefix_ts\u0026#34;)) } # Thêm dòng mới cho định dạng JSONL (Add newline for JSONL format) json_row = json.dumps(out, ensure_ascii=False) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Gửi đến Firehose theo batch 500 (Send to Firehose in batches of 500) if firehose_records: total_records = len(firehose_records) print(f\u0026#34;Sending {total_records} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total_records, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed\u0026#34;) except Exception as e: print(f\u0026#34;Firehose error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;total_records\u0026#34;: len(firehose_records)} "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/5.3.3.3-create-iam-policy/","title":"Tạo IAM Policy","tags":[],"description":"","content":"Tạo IAM Quarantine Policy Tạo IrQuarantineIAMPolicy Điều hướng đến IAM Console → Policies → Create policy\nPolicy JSON:\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } Policy name: IrQuarantineIAMPolicy Description: Deny-all policy for quarantining compromised IAM users "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/5.3.3-create-iam-roles-and-policies/","title":"Tạo IAM Roles và Policies","tags":[],"description":"","content":"Trong phần này, bạn sẽ tạo 17 IAM roles cùng với các policies liên quan cho Lambda functions, Firehose streams, Step Functions, và các dịch vụ khác.\nTổng quan về IAM Roles Lambda Execution Roles (9 roles):\nCloudTrailETLLambdaServiceRole GuardDutyETLLambdaServiceRole CloudWatchETLLambdaServiceRole CloudWatchENIETLLambdaServiceRole CloudWatchExportLambdaServiceRole ParseFindingsLambdaServiceRole IsolateEC2LambdaServiceRole QuarantineIAMLambdaServiceRole AlertDispatchLambdaServiceRole Service Roles (6 roles): 10. CloudTrailFirehoseRole 11. CloudWatchFirehoseRole 12. StepFunctionsRole 13. IncidentResponseStepFunctionsEventRole 14. FlowLogsIAMRole 15. GlueCloudWatchRole\nIAM Policy (1 policy): 16. IrQuarantineIAMPolicy\nNội dung Tạo Lambda Execution Roles Tạo Service Roles Tạo IAM Policy "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/5.5.3-create-lambda-function-etl-processing/","title":"Tạo Lambda Function - Xử lý ETL","tags":[],"description":"","content":"Tạo Lambda Functions - Xử lý ETL Trong phần này, bạn sẽ tạo 5 Lambda functions để xử lý logs và gửi chúng đến Kinesis Firehose hoặc S3.\nincident-response-cloudtrail-etl Runtime: Python 3.12 Handler: CloudTrailETL.lambda_handler Role: CloudTrailETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: FIREHOSE_STREAM_NAME=cloudtrail-firehose-stream Code: cloudtrail-etl incident-response-guardduty-etl Runtime: Python 3.12 Handler: guardduty_etl.lambda_handler Role: GuardDutyETLLambdaServiceRole Timeout: 300s, Memory: 128MB Env: DESTINATION_BUCKET, S3_LOCATION_GUARDDUTY, DATABASE_NAME, TABLE_NAME_GUARDDUTY Code: guardduty-etl cloudwatch-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_etl.lambda_handler Role: CloudWatchETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-dns-firehose-stream Code: cloudwatch-etl cloudwatch-eni-etl-lambda Runtime: Python 3.12 Handler: cloudwatch_eni_etl.lambda_handler Role: CloudWatchENIETLLambdaServiceRole Env: FIREHOSE_STREAM_NAME=vpc-flow-firehose-stream Code: cloudwatch-eni-etl cloudwatch-export-lambda Runtime: Python 3.12 Handler: cloudwatch_autoexport.lambda_handler Role: CloudWatchExportLambdaServiceRole Env: DESTINATION_BUCKET=incident-response-log-list-bucket-ACCOUNT_ID-REGION Code: cloudwatch-autoexport Cấu hình CloudWatch Logs Subscription Filter Cấu hình Subscription Filter Mở CloudWatch Console.\nỞ ngăn điều hướng bên trái, chọn Log Management.\nNhấn vào centralized log group: /aws/incident-response/centralized-logs.\nTạo Subscription Filter:\nNhấn vào tab \u0026ldquo;Subscription filters\u0026rdquo;. Nhấn \u0026ldquo;Create Lambda subscription filter\u0026rdquo;. Cấu hình Destination:\nDestination Lambda function: Chọn function cloudwatch-export-lambda. Log format: Chọn \u0026ldquo;Other\u0026rdquo;. (Điều này đảm bảo dữ liệu log thô được chuyển đi hiệu quả để Lambda xử lý). Cấu hình Log Format và Filter:\nSubscription filter name: Nhập tên mô tả, ví dụ, VPC-Log-Export-Filter. Filter pattern: Để trống trường này blank. (Đảm bảo tất cả logs trong group đều được xử lý). Nhấn \u0026ldquo;Start streaming\u0026rdquo;.\nCấu hình S3 Event Notifications S3 Console → incident-response-log-list-bucket-ACCOUNT_ID-REGION → Properties → Event notifications\nTạo 4 notifications với Event types/Object creation/✅All object create events:\nCloudTrailETLTrigger: Prefix AWSLogs/ACCOUNT_ID/CloudTrail/ → Lambda incident-response-cloudtrail-etl VPCDNSLogsTrigger: Prefix exportedlogs/vpc-dns-logs/ → Lambda cloudwatch-etl-lambda VPCFlowLogsTrigger: Prefix exportedlogs/vpc-flow-logs/ → Lambda cloudwatch-eni-etl-lambda GuardDutyFindingsTrigger: Prefix AWSLogs/ACCOUNT_ID/GuardDuty/ → Lambda incident-response-guardduty-etl "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.3-foundation-setup/","title":"Thiết lập nền tảng","tags":[],"description":"","content":"Giai đoạn Thiết lập nền tảng ban đầu này xây dựng các điều kiện tiên quyết cốt lõi cho Hệ thống Phản hồi Sự cố Tự động, tập trung vào việc triển khai lưu trữ chuyên dụng và ủy quyền bảo mật thiết yếu. Điều này bắt buộc phải tạo năm Amazon S3 buckets an toàn để thu thập và xử lý log tập trung, áp dụng Bucket Policy cần thiết để phân phối log an toàn, và định nghĩa 17 IAM roles cùng chính sách cách ly (quarantine policy) để thực thi quyền truy cập đặc quyền tối thiểu (least-privilege access) trên tất cả các dịch vụ AWS được tích hợp.\nNội dung Thiết lập Amazon S3 Bucket Cấu hình S3 Bucket Policy cho Primary Log Bucket Tạo IAM Roles và Policies "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/4-eventparticipated/4.4-event4/","title":"Sự kiện 4","tags":[],"description":"","content":"Báo cáo Tóm tắt: “AWS Cloud Mastery Series #3: AWS Well-Architected – Security Pillar Workshop” Tổng quan Sự kiện Phiên thứ ba của chuỗi AWS Cloud Mastery tập trung vào AWS Well-Architected Framework, cụ thể là Trụ cột Bảo mật (Security Pillar). Hội thảo này cung cấp cho người tham dự cái nhìn sâu sắc về năm lĩnh vực chính của bảo mật đám mây: Quản lý Danh tính và Truy cập (IAM), Phát hiện và Giám sát Liên tục, Bảo vệ Cơ sở hạ tầng, Bảo vệ Dữ liệu, và Ứng phó Sự cố. Sự kiện cũng giới thiệu sáng kiến AWS Cloud Club, nhằm mục đích thúc đẩy các kỹ năng điện toán đám mây và xây dựng một cộng đồng vững mạnh các chuyên gia đám mây.\nMục tiêu Sự kiện Hội thảo nhằm đạt được các mục tiêu sau:\nGiới thiệu sáng kiến AWS Cloud Club và lợi ích của nó đối với sinh viên và chuyên gia. Cung cấp sự hiểu biết chi tiết về năm trụ cột của bảo mật đám mây: Quản lý Danh tính và Truy cập (IAM) Phát hiện và Giám sát Liên tục Bảo vệ Cơ sở hạ tầng Bảo vệ Dữ liệu Ứng phó Sự cố Chia sẻ các thực tiễn tốt nhất để triển khai các biện pháp bảo mật trên AWS. Nêu bật các trường hợp sử dụng thực tế và các giải pháp bảo mật tiên tiến. Diễn giả Sự kiện có sự tham gia của một nhóm đa dạng các AWS Cloud Club Captains, AWS Community Builders, và các chuyên gia trong ngành, bao gồm:\nLe Vu Xuan An – AWS Cloud Club Captain, HCMUTE Tran Duc Anh – AWS Cloud Club Captain, SGU Tran Doan Cong Ly – AWS Cloud Club Captain, PTIT Danh Hoang Hieu Nghi – AWS Cloud Club Captain, HUFLIT Huynh Hoang Long – AWS Community Builder Dinh Le Hoang Anh – AWS Community Builder Van Hoang Kha – Cloud Security Engineer, AWS Community Builder Mendel Grabski (Long) – Ex-Head of Security \u0026amp; DevOps, Cloud Security Solution Architect Tinh Truong – Platform Engineer, TymeX, AWS Community Builder Điểm nổi bật Chính 1. Sáng kiến AWS Cloud Club Sự kiện bắt đầu với phần giới thiệu về AWS Cloud Club, một chương trình được thiết kế để:\nGiúp sinh viên và chuyên gia khám phá và phát triển kỹ năng điện toán đám mây của họ. Phát triển khả năng lãnh đạo kỹ thuật và cơ hội cố vấn. Xây dựng các kết nối có ý nghĩa trong cộng đồng AWS toàn cầu. Lợi ích của việc tham gia AWS Cloud Club:\nTrải nghiệm AWS thực tế thông qua các hội thảo và dự án. Cố vấn từ các chuyên gia AWS. Hỗ trợ sự nghiệp lâu dài và cơ hội kết nối mạng. Các AWS Cloud Club tham gia:\nHCMUTE SGU PTIT HUFLIT 2. Quản lý Danh tính \u0026amp; Truy cập (IAM) IAM là một dịch vụ AWS nền tảng để quản lý quyền truy cập an toàn vào các tài nguyên AWS. Phiên họp bao gồm:\nCác khái niệm Cốt lõi: Users (Người dùng), Groups (Nhóm), Roles (Vai trò), và Policies (Chính sách). Xác thực (Authentication) và Ủy quyền (Authorization). Thực tiễn Tốt nhất: Áp dụng Nguyên tắc Đặc quyền Tối thiểu. Xóa các khóa truy cập root sau khi tạo tài khoản. Tránh sử dụng ký tự đại diện (*) trong các chính sách. Sử dụng AWS Single Sign-On (SSO) để quản lý truy cập tập trung. Các tính năng IAM Nâng cao:\nService Control Policies (SCPs): Các chính sách toàn tổ chức xác định các quyền tối đa có sẵn cho các tài khoản. Permission Boundaries: Giới hạn các quyền tối đa mà một người dùng hoặc vai trò có thể có. Xác thực Đa yếu tố (MFA): TOTP (Time-based One-Time Password): Yêu cầu nhập thủ công mã 6 chữ số. FIDO2 (Fast Identity Online): Sử dụng quét sinh trắc học hoặc token phần cứng để xác thực. Xoay vòng Thông tin xác thực với AWS Secrets Manager:\nTự động hóa việc xoay vòng thông tin xác thực bằng quy trình 4 bước: Tạo, Đặt, Kiểm tra, và Hoàn tất Bí mật. Tích hợp với EventBridge để lập lịch và tự động hóa. 3. Phát hiện \u0026amp; Giám sát Liên tục Phiên họp này nhấn mạnh tầm quan trọng của khả năng hiển thị thời gian thực và phát hiện mối đe dọa chủ động:\nKhả năng hiển thị Bảo mật Đa lớp: Sự kiện Quản lý: Các cuộc gọi API và hành động trên bảng điều khiển. Sự kiện Dữ liệu: Truy cập đối tượng S3 và thực thi Lambda. Sự kiện Hoạt động Mạng: VPC Flow Logs để giám sát cấp mạng. Kiến trúc Hướng Sự kiện với EventBridge: Xử lý sự kiện thời gian thực để cảnh báo và phản ứng tự động. Tích hợp với Lambda, SNS, và SQS cho các quy trình làm việc bảo mật. Detection-as-Code: Sử dụng các truy vấn CloudTrail Lake để săn tìm mối đe dọa nâng cao. Các quy tắc phát hiện được kiểm soát phiên bản quản lý trong kho lưu trữ mã. 4. GuardDuty – Phát hiện Mối đe dọa Thông minh GuardDuty cung cấp khả năng phát hiện mối đe dọa liên tục sử dụng ba nguồn dữ liệu chính:\nNguồn Dữ liệu Cái nó Giám sát Ví dụ CloudTrail Events Hành động IAM, thay đổi quyền Tắt ghi nhật ký để che giấu dấu vết. VPC Flow Logs Lưu lượng mạng EC2 gửi dữ liệu đến máy chủ C2 botnet. DNS Logs Truy vấn DNS Phần mềm độc hại truy vấn các miền đào tiền ảo. Các gói Bảo vệ Nâng cao:\nS3 Protection: Phát hiện các mẫu truy cập bất thường và quét phần mềm độc hại. EKS Protection: Giám sát nhật ký kiểm toán Kubernetes để tìm truy cập trái phép. Malware Protection: Quét các volume EBS để tìm các instance bị xâm nhập. RDS Protection: Phát hiện các cuộc tấn công brute-force vào cơ sở dữ liệu. Lambda Protection: Giám sát lưu lượng mạng từ các hàm Lambda. 5. Bảo vệ Cơ sở hạ tầng Phiên họp bao gồm các kiểm soát bảo mật mạng chính:\nSecurity Groups (SG): Tường lửa trạng thái (stateful) ở cấp độ instance. Network ACLs (NACLs): Tường lửa không trạng thái (stateless) ở cấp độ subnet. AWS Network Firewall: Cung cấp ngăn chặn xâm nhập và lọc đầu ra. 6. Bảo vệ Dữ liệu \u0026amp; Quản trị Phiên họp nêu bật các dịch vụ AWS để bảo mật dữ liệu:\nMã hóa với KMS: Bảo vệ dữ liệu bằng các khóa do khách hàng quản lý. AWS Secrets Manager: Tự động hóa xoay vòng thông tin xác thực. Quản lý Chứng chỉ với ACM: Cung cấp chứng chỉ công khai miễn phí với khả năng tự động gia hạn. 7. Ứng phó Sự cố Phiên cuối cùng tập trung vào việc chuẩn bị và ứng phó với các sự cố bảo mật:\nThực tiễn Tốt nhất: Sử dụng thông tin xác thực tạm thời. Tránh để lộ các bucket S3 trực tiếp. Quản lý cơ sở hạ tầng thông qua IaC. Quy trình Ứng phó Sự cố: Chuẩn bị Phát hiện \u0026amp; Phân tích Ngăn chặn Loại bỏ \u0026amp; Phục hồi Đánh giá sau Sự cố Trải nghiệm Sự kiện Hội thảo này rất phù hợp với dự án của chúng tôi về Tự động Ứng phó Sự cố và Điều tra Số. Những bài học chính bao gồm:\nĐộ trễ của GuardDuty: Các phát hiện mất tới 5 phút do phân tích tập dữ liệu lớn. Các công cụ bên thứ ba như Open Clarity có thể cung cấp các phát hiện gần thời gian thực. Hỗ trợ từ Chuyên gia: Mendel Grabski đã cung cấp những thông tin giá trị và bày tỏ sự quan tâm đến việc hỗ trợ dự án của chúng tôi. Hình ảnh Sự kiện Ảnh nhóm với Mendel Grabski và Van Hoang Kha. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.4-week4/","title":"Nhật ký Tuần 4","tags":[],"description":"","content":"Mục tiêu Tuần 4: Xây dựng CloudWatch Dashboard tùy chỉnh để trực quan hóa nhật ký và số liệu. Triển khai tự động hóa tối ưu hóa chi phí sử dụng Lambda và EventBridge. Thực hiện di chuyển cơ sở dữ liệu không đồng nhất (MSSQL sang MySQL) sử dụng AWS SCT. Hoàn thiện đề xuất dự án nhóm và ước tính chi phí tài nguyên. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Xây dựng bảng điều khiển CloudWatch để trực quan hóa các số liệu chính và cảnh báo từ workshop AWS CloudWatch.\n+ Mở CloudWatch console, điều hướng đến Dashboards, và tạo một bảng điều khiển tùy chỉnh mới với tên mô tả.\n+ Thêm các tiện ích số liệu hiển thị số liệu đếm lỗi tùy chỉnh được tạo từ bộ lọc số liệu CloudWatch Logs, điều chỉnh khoảng thời gian và thống kê để dễ đọc.\n+ Đặt các tiện ích cảnh báo trên bảng điều khiển để hiển thị trạng thái thời gian thực của cảnh báo bắt nguồn từ nhật ký, liên kết nhật ký, số liệu, và cảnh báo trong một chế độ xem.\n+ Sắp xếp và thay đổi kích thước các tiện ích trên lưới 24 ô để làm nổi bật các thành phần quan sát quan trọng và lưu bảng điều khiển để tái sử dụng. 29/09/2025 29/09/2025 AWS CloudWatch Workshop :: AWS Account Setup\nCloudWatch Dashboards :: AWS Account Setup\nUsing Amazon CloudWatch dashboards - AWS Documentation\nCreating a customized CloudWatch dashboard - AWS Documentation 3 - Hoàn thành Being a researcher (in Information Science and Technology) trên Coursera (ENW493c) 30/09/2025 30/09/2025 4 - Hoàn thành Advanced Writing trên Coursera (ENW493c) 01/10/2025 01/10/2025 5 Tự động hóa tối ưu hóa chi phí EC2 sử dụng các hàm Lambda, thẻ (tags), và thông báo Slack để kiểm soát khởi động/dừng.\n+ Tạo một VPC, subnets, và security group riêng để host một EC2 instance phòng lab mục tiêu cho việc lập lịch tự động.\n+ Khởi chạy và gắn thẻ một EC2 instance với thẻ tối ưu hóa chi phí (ví dụ, environment_auto) để chỉ các instance cụ thể bị ảnh hưởng bởi tự động hóa.\n+ Cấu hình một Slack Incoming Webhook và kênh để nhận thông báo thời gian thực từ AWS Lambda về các hành động khởi động/dừng EC2.\n+ Tạo một IAM execution role cho Lambda với quyền mô tả, khởi động, và dừng các EC2 instance được gắn thẻ và ghi log.\n+ Triển khai hai hàm Lambda (start/stop) lọc các EC2 instance theo thẻ, gọi các API StartInstances/StopInstances, và đăng các tin nhắn có cấu trúc lên Slack.[10]\n+ Kiểm tra quy trình đầu cuối bằng cách gọi các hàm, xác thực thay đổi trạng thái EC2 trong bảng điều khiển, và xác nhận thông báo Slack làm cơ sở cho giải pháp được lập lịch sử dụng EventBridge/CloudWatch Events.\n- Thảo luận với nhóm về những việc cần làm với dự án của chúng tôi và cách chúng tôi có thể triển khai Slack 02/10/2025 02/10/2025 Optimize EC2 cost with Lambda - AWS Study Group\nDefining Lambda function permissions with an execution role\nHow to Schedule EC2 Instances to Stop/Start Automatically\nUse AWS Lambda to send Slack notifications for running Amazon EC2 instances 6 - Tham gia sự kiện AI-Driven Development Life Cycle: Reimagining Software Engineering 03/10/2025 04/10/2025 Kết quả đạt được Tuần 4: Đã thiết kế và triển khai CloudWatch Dashboard tùy chỉnh để giám sát sức khỏe ứng dụng và tỷ lệ lỗi. Phát triển giải pháp tối ưu hóa chi phí serverless sử dụng Lambda để tự động dừng/chạy các EC2 instance, tích hợp với thông báo Slack. Di chuyển thành công cơ sở dữ liệu MSSQL cũ sang Amazon MySQL sử dụng AWS Schema Conversion Tool (SCT), giải quyết các vấn đề tương thích. Phối hợp với nhóm để hoàn thiện đề xuất dự án đồ án và đảm bảo quyền truy cập quản trị cho tất cả các thành viên. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/4-eventparticipated/","title":"Các sự kiện đã tham gia","tags":[],"description":"","content":"Trong quá trình thực tập, em đã tham gia một số sự kiện. Mỗi sự kiện là một trải nghiệm đáng nhớ mang lại những kiến thức mới, thú vị và bổ ích, cùng với những món quà và những khoảnh khắc tuyệt vời.\nSự kiện 1 Tên sự kiện: AI-Driven Development Life Cycle: Reimagining Software Engineering\nThời gian: 18/09/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 2 Tên sự kiện: AWS Cloud Mastery Series #1 - AI/ML/GenAI trên AWS\nThời gian: 15/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 3 Tên sự kiện: AWS Cloud Mastery Series #2 - DevOps trên AWS\nThời gian: 17/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\nSự kiện 4 Tên sự kiện: AWS Cloud Mastery Series #3: AWS Well-Architected – Workshop Trụ cột Bảo mật\nThời gian: 29/11/2025\nĐịa điểm: Tầng 26, tòa nhà Bitexco, số 02 đường Hải Triều, Thành phố Hồ Chí Minh\nVai trò: Người tham dự\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.4-setup-cloudfront/","title":"Cài đặt Cloudfront","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ cài đặt một Cloudfront để cache, định tuyến và truy cập web.\nTạo Cloudfront Distribution Mở Cloudfront Console\nĐiều hướng tới https://console.aws.amazon.com/cloudfront/ Hoặc: AWS Management Console → Services → Cloudfront Tạo Distribution:\nNhấn nút Create distribution Trong phần tạo distribution, sử dụng cài đặt này: Chọn plan: Free plan Name: Static Dashboard Website CloudFront Origin type: Amazom S3 S3 Origin: Chọn static-dashboard-bucket Giữ phần còn lại như mặc định Bật security: Sử dụng cái này nếu bạn chọn free plan Xem lại và nhấn Create distribution Cài đặt chung (General setting):\nSau khi tạo xong, trên tab General của Cloudfront nhấn vào Edit Tại Default root object nhập index.html Description: Static Dashboard Distribution Nhấn Save change Tạo API Gateway origin:\nNhấn Origins trên các tab menu Sau đó nhấn Create origin Trong phần tạo origin, sử dụng cài đặt này: Origin domain: chọn dashboard-api Protocol: HTTPS only HTTPS port: 443 Minimum Origin SSL protocol: TLSv1.2 Origin path: /prod Nhấn Create origin Tạo behaviors cho API Gateway:\nNhấn Behaviors trên các tab menu Sau đó nhấn Create behavior Trong phần tạo behavior, sử dụng cài đặt này: Path pattern: /logs/* Origin và origin groups: chọn dashboard-api Để các cài đặt còn lại như mặc định Nhấn Create behavior Cập nhật S3 policy để hoạt động với Cloudfront:\nNhấn Origins trên các tab menu, chọn tên origin s3-static-dashboard Nhấn Edit Tại phần Origin access controll nhấn Go to S3 bucket permissions Kiểm tra xem quyền S3 của bạn có giống thế này không, nếu không hãy copy và paste nó vào quyền S3 của bạn (Thay đổi ACCOUNT_ID, ACCOUNT_REGION và CLOUDFRONT_ID thành của bạn): { \u0026#34;Version\u0026#34;: \u0026#34;2008-10-17\u0026#34;, \u0026#34;Id\u0026#34;: \u0026#34;PolicyForCloudFrontPrivateContent\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;AllowCloudFrontServicePrincipal\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;cloudfront.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;s3:GetObject\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-static-dashboard-[ACCOUNT_ID]-[ACCOUNT_REGION]/*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;ArnLike\u0026#34;: { \u0026#34;AWS:SourceArn\u0026#34;: \u0026#34;arn:aws:cloudfront::[ACCOUNT_ID]:distribution/[CLOUDFRONT_ID]\u0026#34; } } } ] } Nhấn Save change Tạo error pages:\nNhấn Error pages trên các tab menu Nhấn Create custom error page Trong phần tạo custom error page, sử dụng cài đặt này: HTTP error code: 403: Forbident Error caching minimum TTL: 300 Customize error response: Yes Response page path: /index.html HTTP Response code: 200: OK Lặp lại bước này cho 404 code "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.4-cloudwatch-eni-etl/","title":"Mã CloudWatch ENI ETL","tags":[],"description":"","content":" import json import boto3 import gzip import os from datetime import datetime s3 = boto3.client(\u0026#34;s3\u0026#34;) firehose = boto3.client(\u0026#34;firehose\u0026#34;) # -------------------------------------------------- # CONFIGURATION # -------------------------------------------------- FIREHOSE_STREAM_NAME = os.environ.get(\u0026#34;FIREHOSE_STREAM_NAME\u0026#34;) # ----------------------------- UTILS ----------------------------- def read_gz(bucket, key): obj = s3.get_object(Bucket=bucket, Key=key) with gzip.GzipFile(fileobj=obj[\u0026#34;Body\u0026#34;]) as f: return f.read().decode(\u0026#34;utf-8\u0026#34;, errors=\u0026#34;replace\u0026#34;) def safe_int(x): try: return int(x) except: return None def parse_flow_log_line(line): parts = line.strip().split(\u0026#39; \u0026#39;) if len(parts) \u0026lt; 14: return None try: start_timestamp = safe_int(parts[10]) time_str = None if start_timestamp: dt_object = datetime.fromtimestamp(start_timestamp) time_str = dt_object.strftime(\u0026#39;%Y-%m-%d %H:%M:%S\u0026#39;) record = { \u0026#34;version\u0026#34;: safe_int(parts[0]), # Cột 1: version (int) \u0026#34;account_id\u0026#34;: parts[1], # Cột 2: account_id (STRING) \u0026#34;interface_id\u0026#34;: parts[2], # Cột 3: eni-... \u0026#34;srcaddr\u0026#34;: parts[3], \u0026#34;dstaddr\u0026#34;: parts[4], \u0026#34;srcport\u0026#34;: safe_int(parts[5]), \u0026#34;dstport\u0026#34;: safe_int(parts[6]), \u0026#34;protocol\u0026#34;: safe_int(parts[7]), \u0026#34;packets\u0026#34;: safe_int(parts[8]), \u0026#34;bytes\u0026#34;: safe_int(parts[9]), \u0026#34;start_time\u0026#34;: start_timestamp, # Cột 11 \u0026#34;end_time\u0026#34;: safe_int(parts[11]), \u0026#34;action\u0026#34;: parts[12], \u0026#34;log_status\u0026#34;: parts[13], \u0026#34;timestamp_str\u0026#34;: time_str } return record except Exception as e: print(f\u0026#34;Error parsing line: {e}\u0026#34;) return None def lambda_handler(event, context): print(f\u0026#34;Received S3 Event. Records: {len(event.get(\u0026#39;Records\u0026#39;, []))}\u0026#34;) firehose_records = [] # Duyệt qua các file S3 gửi về (Iterate through files sent from S3) for record in event.get(\u0026#34;Records\u0026#34;, []): if \u0026#34;s3\u0026#34; not in record: continue bucket = record[\u0026#34;s3\u0026#34;][\u0026#34;bucket\u0026#34;][\u0026#34;name\u0026#34;] key = record[\u0026#34;s3\u0026#34;][\u0026#34;object\u0026#34;][\u0026#34;key\u0026#34;] # Chỉ xử lý file .gz (Process .gz files only) if not key.endswith(\u0026#34;.gz\u0026#34;): print(f\u0026#34;Skipping non-gz: {key}\u0026#34;) continue print(f\u0026#34;Processing: {key}\u0026#34;) # Đọc nội dung (Read content) content = read_gz(bucket, key) if not content: continue # Parse từng dòng log (Parse each log line) for line in content.splitlines(): rec = parse_flow_log_line(line) if not rec: continue # Chuyển thành JSON string và thêm xuống dòng (\\n) (Convert to JSON string and add newline) json_row = json.dumps(rec) + \u0026#34;\\n\u0026#34; firehose_records.append({\u0026#39;Data\u0026#39;: json_row}) # Đẩy sang Firehose (Batching 500 dòng) (Push to Firehose - batching 500 lines) if firehose_records: total = len(firehose_records) print(f\u0026#34;Flushing {total} records to Firehose...\u0026#34;) batch_size = 500 for i in range(0, total, batch_size): batch = firehose_records[i:i + batch_size] try: response = firehose.put_record_batch( DeliveryStreamName=FIREHOSE_STREAM_NAME, Records=batch ) if response[\u0026#39;FailedPutCount\u0026#39;] \u0026gt; 0: print(f\u0026#34;Warning: {response[\u0026#39;FailedPutCount\u0026#39;]} records failed.\u0026#34;) except Exception as e: print(f\u0026#34;Firehose API Error: {e}\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;ok\u0026#34;, \u0026#34;count\u0026#34;: len(firehose_records)} "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.4-monitoring-setup/","title":"Thiết lập giám sát","tags":[],"description":"","content":"Giai đoạn Thiết lập giám sát này kích hoạt và cấu hình ba nguồn log cốt lõi để phát hiện mối đe dọa. Giai đoạn này bao gồm việc bật CloudTrail cho các sự kiện quản lý và dữ liệu toàn diện, kích hoạt GuardDuty để xuất các phát hiện bảo mật sang S3 bucket chính, và thiết lập VPC Flow Logs trên mạng của bạn để gửi tất cả metadata lưu lượng truy cập đến CloudWatch Log Group chuyên dụng. Điều này đảm bảo luồng dữ liệu log liên tục, tập trung luôn sẵn sàng cho việc xử lý và phản hồi tự động.\nTạo CloudWatch Log Group Mở CloudWatch Console → Log Management → Create log group Cấu hình:\nLog group name: /aws/incident-response/centralized-logs Retention: 90 ngày KMS key: None Nhấn \u0026ldquo;Create\u0026rdquo;\nBật AWS CloudTrail Mở CloudTrail Console → Trail → Create trail Thuộc tính Trail:\nTrail name: incident-responses-cloudtrail-ACCOUNT_ID-REGION Storage location: Sử dụng S3 bucket hiện có S3 bucket: Chọn incident-response-log-list-bucket-ACCOUNT_ID-REGION của bạn Log file SSE-KMS encryption: Disable (Tắt) Log file validation: Enabled (Bật) Nhấn next Chọn log events:\nEvents Chọn Management events, Data events Management events: Tất cả (Read + Write) Data events: S3 - Log tất cả events Nhấn next đến bước 4 và Create Trail Advanced event selectors: Loại trừ log buckets:\nNhấn vào Trail sau đó cuộn xuống Data Event và nhấn Edit Thiết lập như hình với định dạng dưới đây: -arn:aws:s3:::incident-response-log-list-bucket-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-guardduty-findings-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudtrail-logs-ACCOUNT_ID-REGION\n-arn:aws:s3:::athena-query-results-ACCOUNT_ID-REGION/\n-arn:aws:s3:::processed-cloudwatch-logs-ACCOUNT_ID-REGION/\nLưu thay đổi Bật Amazon GuardDuty Mở GuardDuty Console → Get Started → Enable GuardDuty\nCấu hình cài đặt:\nFinding export frequency: Update CWE và S3 mỗi 15 phút S3 export: incident-response-log-list-bucket-ACCOUNT_ID-REGION KMS encryption: Chọn hoặc tạo KMS key Bật VPC Flow Logs Mở VPC Console → Your VPCs → Chọn VPC của bạn\nActions → Create flow log\nCấu hình:\nFilter: All (Tất cả) Aggregation interval: 10 phút Destination: CloudWatch Logs Log group: /aws/incident-response/centralized-logs IAM role: FlowLogsIAMRole Log format: Default (Mặc định) Tạo flow log\nBật VPC DNS Query Logging Cấu hình Resolver Query Logging Mở Amazon Route 53 Console.\nỞ thanh điều hướng bên trái, chọn VPC Resolver -\u0026gt; Query logging.\nNhấn \u0026ldquo;Configure query logging\u0026rdquo;.\nCấu hình:\nName: Nhập tên mô tả, ví dụ: IR-DNS-Query-Log-Config. Destination for query logs: CloudWatch Logs log group Log group: Chọn \u0026ldquo;Existing log group\u0026rdquo; và chọn: /aws/incident-response/centralized-logs Nhấn \u0026ldquo;Configure query logging\u0026rdquo;.\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.5-week5/","title":"Nhật ký Tuần 5","tags":[],"description":"","content":"Mục tiêu Tuần 5: Thiết lập môi trường DNS lai (Hybrid DNS) sử dụng Route 53 Resolver Endpoints (Inbound/Outbound). Tích hợp AWS Managed Microsoft AD với các mô phỏng on-premises thông qua RD Gateway. Thành thạo việc giảm thiểu các thao tác thủ công bằng cách thực hiện các tác vụ cốt lõi qua AWS CLI. Dịch các bài blog kỹ thuật để làm sâu sắc thêm hiểu biết về các khái niệm đám mây. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Hoàn thành thiết lập đầu cuối môi trường DNS lai sử dụng Route 53 Resolver với AWS Managed Microsoft AD và RD Gateway.\n+ Khởi chạy mẫu CloudFormation được cung cấp để tạo một VPC tùy chỉnh, các subnet công khai/riêng tư trên hai Availability Zones, Internet Gateway, và NAT Gateways để truy cập ra ngoài từ các subnet riêng tư.\n+ Cấu hình một Remote Desktop Gateway (RDGW) EC2 instance trong subnet công khai, điều chỉnh security groups để kiểm soát truy cập RDP/ICMP, và xác minh kết nối từ xa từ máy trạm cục bộ.\n+ Triển khai AWS Managed Microsoft AD, gia nhập RDGW vào miền được quản lý, và xác nhận xác thực miền từ máy chủ phiên RD. + Tạo Route 53 Resolver outbound endpoints trong các subnet riêng tư và các quy tắc chuyển tiếp để khối lượng công việc VPC có thể phân giải tên miền kiểu on-premises thông qua các máy chủ DNS AD được quản lý. + Tạo Route 53 Resolver inbound endpoints và các quy tắc để cho phép các trình chuyển tiếp DNS bên ngoài hoặc on-premises phân giải tên máy chủ AWS riêng tư trong VPC, hoàn thành luồng DNS lai. + Kiểm tra phân giải tên DNS từ RDGW instance để đảm bảo các truy vấn cho cả bản ghi riêng tư AWS và miền kiểu on-premises được định tuyến chính xác qua các Resolver endpoints và AD DNS đã cấu hình. 06/10/2025 06/10/2025 AWS Managed Microsoft AD - AWS Directory Service\nWhat is Route 53 VPC Resolver?\nNAT Gateways - Amazon VPC 3 Dịch Blog 1 và Blog 2 07/10/2025 07/10/2025 Blog 1\nBlog 2 4 Hoàn thành thực hành AWS CLI đầu cuối trên các dịch vụ cốt lõi (S3, SNS, IAM, VPC, EC2) sử dụng hồ sơ xác thực SSO.\n+ Sử dụng AWS CLI với Amazon S3 để tạo và kiểm tra các S3 bucket và đối tượng thay vì thực hiện các hành động đó trong console.\n+ Thực hành AWS CLI với Amazon SNS bằng cách tạo chủ đề (topics), thêm đăng ký email, và gửi thông báo thử nghiệm.\n+ Quản lý các định danh IAM qua AWS CLI, tạo người dùng/nhóm và xử lý các khóa truy cập thông qua dòng lệnh.\n+ Xây dựng mạng với VPC và Internet Gateway sử dụng AWS CLI, tạo một VPC tùy chỉnh, subnets, và định tuyến công khai để truy cập internet.\n+ Khởi chạy và quản lý một EC2 instance qua AWS CLI, kiểm tra kết nối SSH, và chấm dứt instance sau khi thực hành.\n+ Chạy tất cả các bài lab sử dụng aws login thay vì các khóa truy cập tĩnh từ aws configure. 08/10/2025 08/10/2025 Getting Started with the AWS CLI\nGetting started with Amazon S3 using the AWS CLI\nAccessing Amazon SNS in the AWS CLI\nIAM examples using AWS CLI\nGetting started with Amazon VPC using the AWS CLI\nUsing Amazon EC2 in the AWS CLI\nConfiguring IAM Identity Center authentication with the AWS CLI 5 Dịch Blog 3 09/10/2025 09/10/2025 Blog 3 6 - Hoàn thành Introduction to Research for Essay Writing trên Coursera (ENW493c) 10/10/2025 10/10/2025 Kết quả đạt được Tuần 5: Triển khai thành công kiến trúc DNS Lai cho phép phân giải liền mạch giữa on-premises và AWS (Route 53 Resolver). Có kinh nghiệm thực tế với việc tích hợp AWS Managed Microsoft AD và Remote Desktop Gateway. Chứng minh sự thành thạo hoàn toàn trong việc quản lý tài nguyên AWS cốt lõi (VPC, EC2, S3, IAM) chỉ thông qua CLI. Nâng cao kỹ năng giao tiếp kỹ thuật thông qua việc dịch ba bài blog chuyên sâu về kỹ thuật đám mây. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/5.7.5-setup-cognito/","title":"Cài đặt Cognito","tags":[],"description":"","content":"Trong hướng dẫn này, bạn sẽ tạo một Cognito user pool để đăng nhập dashboard.\nTạo Cognito User Pool Mở Amazon Cognito Console\nĐiều hướng tới https://console.aws.amazon.com/cognito/ Hoặc: AWS Management Console → Services → Cognito Tạo user pool:\nNhấn Create user pool Trong phần tạo user pool, sử dụng cài đặt này: Application type: Single-page application (SPA) Application name: dashboard-user-pool-client Options for sign-in identifiers: Email và Username Self-registration: Enable self-registration Required attributes for sign-up: email Add a return URL: Vào Cloudfront, chọn cái bạn vừa tạo và copy Distribution domain name và dán vào đây (Ví dụ: https://d2bvvvpr6s4eyd.cloudfront.net) Nhấn Create user directory Sau khi tạo, cuộn xuống và nhấn Go to overview Cấu hình User pool App clients:\nChọn App clients trên menu bên trái Chọn dashboard-user-pool-client Trong phần App client information, nhấn Edit Nhấn Save change Cấu hình Managed login pages:\nTrong phần Managed login pages configuration, nhấn Edit Nhấn Add sign-out URL tại phần Allowed sign-out URLs Copy URL trên callbacks URL và dán vào Allowed sign-out URLs Cuộn xuống OpenID Connect scopes thêm Profile vào scopes Nhấn Save change Tạo một user:\nTrên menu bên trái, chọn tùy chọn User Nhấn Create user Nhập thông tin người dùng của bạn Nhấn Create user "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.5-cloudwatch-autoexport/","title":"Mã CloudWatch Autoexport","tags":[],"description":"","content":" import json import base64 import gzip from io import BytesIO import boto3 import os import time s3 = boto3.client(\u0026#39;s3\u0026#39;) # --- CONFIGURATION (CẤU HÌNH) --- RAW_S3_BUCKET = os.environ.get(\u0026#34;DESTINATION_BUCKET\u0026#34;) # The log group pattern constant is no longer used for filtering, but is kept for reference. # VPC_DNS_LOG_PATTERN = \u0026#39;/aws/route53/query/\u0026#39; def is_vpc_dns_log(log_message): try: json_body = json.loads(log_message.strip()) if \u0026#39;query_name\u0026#39; in json_body and \u0026#39;query_type\u0026#39; in json_body: return True return False except Exception: return False def lambda_handler(event, context): try: compressed_payload = base64.b64decode(event[\u0026#39;awslogs\u0026#39;][\u0026#39;data\u0026#39;]) f = BytesIO(compressed_payload) decompressed_data = gzip.GzipFile(fileobj=f).read() log_data = json.loads(decompressed_data.decode(\u0026#39;utf-8\u0026#39;)) log_lines = [] for log_event in log_data.get(\u0026#39;logEvents\u0026#39;, []): log_lines.append(log_event.get(\u0026#39;message\u0026#39;, \u0026#39;\u0026#39;)) if not log_lines: print(f\u0026#34;Batch skipped: No log events found in payload. Log Group: {log_data.get(\u0026#39;logGroup\u0026#39;)}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: \u0026#39;Log batch ignored (No events).\u0026#39;} is_dns_log = is_vpc_dns_log(log_lines[0]) if is_dns_log: key_prefix = \u0026#39;vpc-dns-logs\u0026#39; filename_prefix = \u0026#39;vpc-\u0026#39; # Add vpc- to the filename else: key_prefix = \u0026#39;vpc-flow-logs\u0026#39; filename_prefix = \u0026#39;eni-\u0026#39; # Keep filename blank for other logs output_content = \u0026#39;\\n\u0026#39;.join(log_lines) full_log_group_name = log_data.get(\u0026#39;logGroup\u0026#39;, \u0026#39;unknown-group\u0026#39;) log_group_name_safe = full_log_group_name.strip(\u0026#39;/\u0026#39;).replace(\u0026#39;/\u0026#39;, \u0026#39;_\u0026#39;) final_filename = f\u0026#34;{filename_prefix}{context.aws_request_id}.gz\u0026#34; s3_key = f\u0026#39;exportedlogs/{key_prefix}/{log_group_name_safe}/{final_filename}\u0026#39; buffer = BytesIO() with gzip.GzipFile(fileobj=buffer, mode=\u0026#39;w\u0026#39;) as gz: gz.write(output_content.encode(\u0026#39;utf-8\u0026#39;)) gzipped_data = buffer.getvalue() s3.put_object( Bucket=RAW_S3_BUCKET, Key=s3_key, Body=gzipped_data, ContentType=\u0026#39;application/x-gzip\u0026#39; ) num_logs = len(log_lines) print(f\u0026#34;Exported {num_logs} raw log lines to s3://{RAW_S3_BUCKET}/{s3_key}\u0026#34;) return {\u0026#39;statusCode\u0026#39;: 200, \u0026#39;body\u0026#39;: f\u0026#39;Logs exported. {num_logs} events processed. Key Prefix: {key_prefix}\u0026#39;} except Exception as e: print(f\u0026#34;Error in CW Export Lambda: {e}\u0026#34;) raise e "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.5-processing-setup/","title":"Thiết lập xử lý","tags":[],"description":"","content":"Giai đoạn Thiết lập xử lý này xây dựng đường ống dữ liệu (data pipeline) cốt lõi để cấu trúc log thô và chuẩn bị chúng cho việc phân tích truy vấn. Giai đoạn này bắt buộc triển khai ba luồng Kinesis Data Firehose để đệm và phân phối CloudTrail và VPC logs đến các S3 buckets đích. Đồng thời, bạn sẽ cấu hình AWS Glue Database và bốn bảng Athena thông qua DDL để làm cho dữ liệu có cấu trúc có thể truy vấn được. Pipeline này dựa vào năm Lambda functions ETL được kích hoạt bởi S3 Event Notifications để thực hiện chuyển đổi dữ liệu cần thiết khi log đến.\nNội dung Tạo Kinesis Data Firehose Delivery Streams Tạo AWS Glue Database và Tables Tạo Lambda Functions - Xử lý ETL "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Thiết lập hệ thống phản hồi sự cố tự động AWS Tổng quan Hướng dẫn này cung cấp quy trình từng bước hoàn chỉnh để triển khai hệ thống phản hồi sự cố và điều tra số (forensics) tự động của chúng tôi trên AWS. Hệ thống này tận dụng CloudTrail, GuardDuty, VPC Flow Logs, Kinesis Firehose, Glue, Athena, và Lambda functions được điều phối bởi AWS Step Functions để tự động phát hiện, phân tích và cách ly các tài nguyên bị xâm phạm như EC2 instances và IAM users. Khả năng điều tra log sâu hơn được bổ sung bằng cách thiết lập Security Dashboard lưu trữ trên S3 và truy cập qua CloudFront và Cognito, truy vấn log sử dụng API Gateway và Lambda.\nNội dung Tổng quan Điều kiện tiên quyết Giai đoạn 1: Thiết lập nền tảng Giai đoạn 2: Thiết lập giám sát Giai đoạn 3: Thiết lập xử lý Giai đoạn 4: Thiết lập tự động hóa Giai đoạn 5: Thiết lập Dashboard Kiểm tra Sử dụng CDK Dọn dẹp Phụ lục "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.6-week6/","title":"Nhật ký Tuần 6","tags":[],"description":"","content":"Mục tiêu Tuần 6: Xác định phạm vi và trách nhiệm cho dự án nhóm. Ước tính chi phí vận hành cho kiến trúc đề xuất sử dụng AWS Pricing Calculator. Nghiên cứu các phương pháp thực hành tốt nhất về DevSecOps và ứng dụng của chúng trong môi trường AWS. Thiết lập hệ thống quản lý kiến thức (Notion) để tài liệu hóa quá trình học AWS. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành khóa học MOOC Pháp luật và đạo đức trong công nghệ số trên Coursera (Chương trình KS57) 13/10/2025 13/10/2025 3 - Tham gia một cuộc họp nhóm để thảo luận về phạm vi dự án, làm rõ trách nhiệm của từng thành viên, và lên kế hoạch cho các nhiệm vụ tiếp theo 14/10/2025 14/10/2025 4 - Tham gia một cuộc họp nhóm - Xem xét chi phí ước tính của việc chạy EC2 instance và các hàm Lambda sử dụng AWS Pricing Calculator, sau đó điều chỉnh kiến trúc để tối ưu hóa chi phí. 15/10/2025 15/10/2025 AWS Pricing Calculator\nGenerating Amazon EC2 estimates\nAWS Lambda pricing 5 - Hoàn thành khóa học MOOC Quản trị dự án và duy trì đổi mới trong chuyển đổi số trên Coursera (Chương trình KS57) - Tham gia hội thảo trực tuyến 𝗗𝗫\u0026lt;𝗶𝗻𝗔𝗰𝘁𝗶𝗼𝗻\u0026gt; 𝗧𝗮𝗹𝗸#𝟳: Reinventing DevSecOps with AWS Generative AI 16/10/2025 16/10/2025 6 - Tôi đã tạo một không gian làm việc Notion chuyên dụng để tài liệu hóa những gì tôi học về AWS, cùng với các mẹo và thủ thuật thực tế, để tôi có thể dễ dàng xem lại và hoàn thiện hiểu biết của mình theo thời gian. 17/10/2025 17/10/2025 Kết quả đạt được Tuần 6: Đã xác định thành công phạm vi dự án và phân công vai trò cho tất cả các thành viên trong nhóm dựa trên thế mạnh của họ. Tạo bảng ước tính chi phí chi tiết cho cơ sở hạ tầng EC2 và Lambda, xác định các lĩnh vực chính để tiết kiệm tiềm năng. Làm sâu sắc thêm hiểu biết về các nguyên tắc DevSecOps và cách Generative AI chuyển đổi quy trình phát triển. Xây dựng không gian làm việc Notion tập trung để ghi lại tiến trình học tập AWS và các mẹo khắc phục sự cố. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/6-self-evaluation/","title":"Tự đánh giá","tags":[],"description":"","content":"Trong suốt thời gian thực tập tại Amazon Web Services (AWS) từ 08/09/2025 đến 12/12/2025, tôi đã có cơ hội học hỏi, rèn luyện và áp dụng kiến thức đã được trang bị tại trường vào môi trường làm việc thực tế.\nTôi đã tham gia Chương trình Thực tập AWS First Cloud Journey, qua đó cải thiện kỹ năng Điện toán đám mây, Cơ sở hạ tầng dưới dạng Mã (IaC), DevOps, Tuân thủ bảo mật và Kiến trúc Giải pháp.\nVề tác phong, tôi luôn cố gắng hoàn thành tốt nhiệm vụ, tuân thủ nội quy, và tích cực trao đổi với đồng nghiệp để nâng cao hiệu quả công việc.\nĐể phản ánh một cách khách quan quá trình thực tập, tôi xin tự đánh giá bản thân dựa trên các tiêu chí dưới đây:\nSTT Tiêu chí Mô tả Tốt Khá Trung bình 1 Kiến thức và kỹ năng chuyên môn Hiểu biết về ngành, áp dụng kiến thức vào thực tế, kỹ năng sử dụng công cụ, chất lượng công việc ☐ ✅ ☐ 2 Khả năng học hỏi Tiếp thu kiến thức mới, học hỏi nhanh ✅ ☐ ☐ 3 Chủ động Tự tìm hiểu, nhận nhiệm vụ mà không chờ chỉ dẫn ☐ ✅ ☐ 4 Tinh thần trách nhiệm Hoàn thành công việc đúng hạn, đảm bảo chất lượng ☐ ✅ ☐ 5 Kỷ luật Tuân thủ giờ giấc, nội quy, quy trình làm việc ☐ ✅ ☐ 6 Tính cầu tiến Sẵn sàng nhận feedback và cải thiện bản thân ✅ ☐ ☐ 7 Giao tiếp Trình bày ý tưởng, báo cáo công việc rõ ràng ✅ ☐ ☐ 8 Hợp tác nhóm Làm việc hiệu quả với đồng nghiệp, tham gia nhóm ✅ ☐ ☐ 9 Ứng xử chuyên nghiệp Tôn trọng đồng nghiệp, đối tác, môi trường làm việc ✅ ☐ ☐ 10 Tư duy giải quyết vấn đề Nhận diện vấn đề, đề xuất giải pháp, sáng tạo ✅ ☐ ☐ 11 Đóng góp vào dự án/tổ chức Hiệu quả công việc, sáng kiến cải tiến, ghi nhận từ team ☐ ✅ ☐ 12 Tổng thể Đánh giá chung về toàn bộ quá trình thực tập ✅ ☐ ☐ Chia sẻ và Phản hồi Kỳ thực tập tại Amazon là một trải nghiệm mang tính bước ngoặt, đánh dấu sự chuyển mình của tôi từ một sinh viên thành một chuyên gia công nghệ điện toán đám mây. Hành trình bắt đầu với những kiến thức nền tảng về các dịch vụ cốt lõi như EC2, VPC và IAM, nhưng nhanh chóng tiến tới các kịch bản phức tạp, thực tế liên quan đến kiến trúc Serverless, thiết kế hướng sự kiện (Event-Driven) và Cơ sở hạ tầng dưới dạng Mã (IaC).\nMột trong những điều giá trị nhất là sự thay đổi trong tư duy, từ việc chỉ \u0026ldquo;làm cho chạy được\u0026rdquo; bằng ClickOps sang việc đảm bảo hệ thống có khả năng mở rộng, tái tạo và bảo mật bằng cách sử dụng các công cụ như CloudFormation và áp dụng AWS Well-Architected Framework. Việc tham gia các sự kiện như \u0026ldquo;AWS Cloud Mastery Series\u0026rdquo; đã mở rộng tầm nhìn của tôi vượt ra ngoài các kỹ năng kỹ thuật, giúp tôi hiểu rõ tầm quan trọng của các trụ cột bảo mật, tối ưu hóa chi phí và sức mạnh của AI tạo sinh.\nMặc dù có những thách thức, chẳng hạn như việc làm quen với các dịch vụ mới như Step Functions và kỷ luật cần thiết cho việc tự học liên tục, sự hỗ trợ từ cộng đồng và các cố vấn là vô giá. Kỳ thực tập này không chỉ trang bị cho tôi sự thành thạo về kỹ thuật mà còn thấm nhuần văn hóa ám ảnh khách hàng (customer obsession) và tinh thần làm chủ (ownership) mà tôi sẽ mang theo trong suốt sự nghiệp của mình.\nCần cải thiện Tăng cường Kỷ luật và Tuân thủ: Nghiêm túc tuân thủ giờ giấc, nội quy và quy trình làm việc để đảm bảo tính chuyên nghiệp và độ tin cậy. Nâng cao tính Chủ động và Trách nhiệm: Chủ động hơn trong việc tìm kiếm công việc và nhận nhiệm vụ thay vì chờ chỉ dẫn, cải thiện từ mức \u0026ldquo;Khá\u0026rdquo; lên \u0026ldquo;Tốt\u0026rdquo;. Cải thiện Đóng góp cho Nhóm: Đóng góp tích cực hơn vào các cuộc thảo luận của nhóm và đề xuất các ý tưởng sáng tạo để gia tăng tầm ảnh hưởng đối với dự án. Đào sâu Kiến thức chuyên môn: Đẩy nhanh tốc độ học hỏi các công nghệ mới để áp dụng chúng thành thạo và hiệu quả hơn trong thực tế. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.6-parse-findings/","title":"Mã Parse Findings","tags":[],"description":"","content":" import json import logging logger = logging.getLogger() logger.setLevel(logging.INFO) def lambda_handler(event, context): instance_ids = [] detail = event.get(\u0026#39;detail\u0026#39;, {}) region = event.get(\u0026#39;region\u0026#39;) or detail.get(\u0026#39;region\u0026#39;) or \u0026#39;ap-southeast-1\u0026#39; instance_id_primary = detail.get(\u0026#39;resource\u0026#39;, {}).get(\u0026#39;instanceDetails\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if instance_id_primary: instance_ids.append(instance_id_primary) # --- 2. Extract from the older/secondary \u0026#39;resources\u0026#39; array structure --- # --- 2. Trích xuất từ cấu trúc mảng \u0026#39;resources\u0026#39; cũ/phụ --- for r in detail.get(\u0026#34;resources\u0026#34;, []): if r.get(\u0026#34;type\u0026#34;) == \u0026#34;AwsEc2Instance\u0026#34;: id_from_details = r.get(\u0026#39;details\u0026#39;, {}).get(\u0026#39;instanceId\u0026#39;) if id_from_details: instance_ids.append(id_from_details) else: arn_id = r.get(\u0026#39;id\u0026#39;) if arn_id and arn_id.startswith(\u0026#39;arn:aws:ec2:\u0026#39;): instance_ids.append(arn_id.split(\u0026#39;/\u0026#39;)[-1]) unique_instance_ids = list(set([id for id in instance_ids if id])) return { \u0026#34;InstanceIds\u0026#34;: unique_instance_ids, \u0026#34;Region\u0026#34;: region } "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.6-automation-setup/","title":"Thiết lập tự động hóa","tags":[],"description":"","content":"Giai đoạn 4: Thiết lập tự động hóa Tạo Isolation Security Group EC2 Console → Security Groups → Create security group Name: IR-Isolation-SG Description: Denies all inbound and outbound traffic for compromised instances (Chặn tất cả lưu lượng đi và đến cho các instance bị xâm phạm) VPC: Chọn VPC của bạn Inbound rules: Không có (từ chối tất cả - deny all) Outbound rules: Xóa mặc định (từ chối tất cả - deny all) Tạo và ghi lại Security Group ID (ví dụ: sg-0078026b70389e7b3) Tạo SNS Topic SNS Console → Create topic Type: Standard, Name: IncidentResponseAlerts Access policy: { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sns:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;AWSEvents_IncidentResponseAlert_Target0\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;events.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;SNS:Publish\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:sns:ap-southeast-1:831981618496:IncidentResponseAlerts\u0026#34; } ] } Tạo Lambda Functions - Phản hồi sự cố (Incident Response) ir-parse-findings-lambda Handler: parse_findings.lambda_handler Role: ParseFindingsLambdaServiceRole Code: parse-findings ir-isolate-ec2-lambda Handler: isolate_ec2.lambda_handler Role: IsolateEC2LambdaServiceRole Env: ISOLATION_SG_ID=sg-XXXXXXX (từ bước 12) Code: isolate-ec2 ir-quarantine-iam-lambda Handler: quarantine_iam.lambda_handler Role: QuarantineIAMLambdaServiceRole Env: QUARANTINE_POLICY_ARN=arn:aws:iam::ACCOUNT_ID:policy/IrQuarantineIAMPolicy Code: quarantine-iam ir-alert-dispatch Handler: alert_dispatch.lambda_handler Role: AlertDispatchLambdaServiceRole Env: SENDER_EMAIL, RECIPIENT_EMAIL, SLACK_WEBHOOK_URL Add SNS trigger: Topic IncidentResponseAlerts Code: alert-dispatch Cập nhật SNS Topic Subscription SNS Console → IncidentResponseAlerts → Subscriptions Xác minh: Protocol=AWS Lambda, Endpoint=ir-alert-dispatch, Status=Confirmed Tạo Step Functions State Machine Step Functions Console → Create state machine Type: Standard, Name: IncidentResponseStepFunctions Definition: Step Functions Definition Role: StepFunctionsRole Create Tạo EventBridge Rule EventBridge Console → Rules → Create rule Name: IncidentResponseAlert Event pattern: { \u0026#34;source\u0026#34;: [\u0026#34;aws.guardduty\u0026#34;], \u0026#34;detail-type\u0026#34;: [\u0026#34;GuardDuty Finding\u0026#34;] } Targets (2): SNS topic: IncidentResponseAlerts Step Functions: IncidentResponseStepFunctions với role IncidentResponseStepFunctionsEventRole Cấu hình Athena Workgroup Athena Console → Workgroups → primary → Edit Query result location: s3://athena-query-results-ACCOUNT_ID-REGION/ Lưu (Save) "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.7-week7/","title":"Nhật ký Tuần 7","tags":[],"description":"","content":"Mục tiêu Tuần 7: Triển khai và cấu hình Amazon FSx for Windows File Server tích hợp với AD. Thực hiện các tác vụ quản trị lưu trữ: chống trùng lặp (deduplication), hạn ngạch (quotas), và shadow copies. Đánh giá hiệu suất hệ thống tệp sử dụng DiskSpd và giám sát qua CloudWatch. Củng cố kiến thức kiến trúc đám mây thông qua học tập trò chơi hóa (AWS Card Clash). Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Bận việc bên ngoài - Họp nhóm trực tuyến để phân chia công việc. 20/10/2025 20/10/2025 3 Cung cấp và cấu hình môi trường lab Amazon FSx for Windows File Server với nhiều hệ thống tệp và chia sẻ SMB để thử nghiệm sau này.\n+ Thiết lập môi trường lab FSx qua AWS CloudFormation, tạo VPC, subnets, security groups, và Windows management instances cần thiết cho workshop.\n+ Tạo cả hệ thống tệp SSD và HDD Multi-AZ FSx for Windows, chọn kích thước lưu trữ phù hợp, dung lượng thông lượng, subnet riêng tư, và tích hợp AWS Managed Microsoft AD.\n+ Sử dụng Windows management instance để cấu hình các chia sẻ tệp SMB mới trên các volume FSx, gán thư mục ứng dụng/dữ liệu và quyền chia sẻ lab cho phép cho các kịch bản sau này.\n+ Xác minh kết nối cơ bản từ Windows instance đến tên DNS và các chia sẻ FSx, đảm bảo môi trường đã sẵn sàng cho các bài tập hiệu suất và quản lý dữ liệu. 21/10/2025 21/10/2025 Amazon FSx for Windows File Server - AWS Study Group\nGetting started with Amazon FSx for Windows File Server\nAccessing data using file shares - Amazon FSx for Windows File Server 4 Triển khai kiểm tra hiệu suất, giám sát, và các tính năng bảo vệ dữ liệu nâng cao trên Amazon FSx for Windows File Server.\n+ Chạy các bài kiểm tra hiệu suất dựa trên DiskSpd từ một Windows instance đối với ổ đĩa FSx được ánh xạ để đo thông lượng đọc/ghi dưới tải.\n+ Giám sát các chỉ số CloudWatch FSx (thông lượng, IOPS, độ trễ, kết nối) từ FSx console để tương quan hiệu suất quan sát được với dung lượng đã cấu hình.\n+ Bật chống trùng lặp dữ liệu (data deduplication) trên hệ thống tệp FSx qua giao diện PowerShell FSx từ xa, tạo lịch trình tối ưu hóa hàng ngày, và xác thực trạng thái dedup và thống kê tiết kiệm.\n+ Bật shadow copies cho volume FSx, tăng giới hạn lưu trữ, tạo một snapshot theo yêu cầu, và xác nhận rằng tệp “Previous Versions” có thể được khôi phục từ Windows Explorer.\n+ Thực hành kiểm soát của quản trị viên đối với phiên người dùng và tệp đang mở sử dụng Shared Folders và FSx PowerShell cmdlets, bao gồm buộc đóng một tệp thử nghiệm đang hoạt động để ngắt I/O của máy khách. 22/10/2025 22/10/2025 FSx for Windows File Server performance\nProtecting your data with shadow copies\nAdministering FSx for Windows file systems 5 - Chơi các trận đấu AWS Card Clash với đồng đội để đặt đúng thẻ dịch vụ AWS vào các sơ đồ kiến trúc đám mây mẫu và xem cách các dịch vụ kết nối.\n- Thảo luận qua từng vòng để giải thích bằng ngôn ngữ đơn giản những gì các dịch vụ chính làm (ví dụ, cái nào xử lý tính toán, lưu trữ, hoặc mạng) để mọi người có thể nhớ chúng dễ dàng hơn.\n- Tải ghi chú bài giảng và liên kết học tập AWS vào NotebookLM và sử dụng nó để làm nổi bật các ý chính và tạo giải thích ngắn cho các chủ đề vẫn cảm thấy khó hiểu.\n- Nhờ NotebookLM tạo các câu hỏi ôn tập và tóm tắt ngắn từ những ghi chú đó để việc ôn tập giữa kỳ giống như một buổi hỏi đáp có hướng dẫn thay vì chỉ đọc lại mọi thứ.\n- Sử dụng Gemini để biến các chủ đề giữa kỳ thành các câu đố thực hành nhỏ và flashcards, sau đó trả lời chúng để kiểm tra xem khu vực AWS nào vẫn cần ôn tập thêm.\n- Kiểm tra lại bất kỳ câu trả lời không rõ ràng nào bằng tài liệu học tập chính thức của AWS để đảm bảo các giải thích và câu trả lời trắc nghiệm khớp với cách các dịch vụ thực sự hoạt động. 23/10/2025 23/10/2025 AWS Card Clash: Learn Cloud Architecture\nIntroducing AWS Card Clash mobile 6 Cấu hình hạn ngạch, chia sẻ tính sẵn sàng cao, mở rộng dung lượng, dọn dẹp, và xem xét quy trình làm việc AWS CLI cho FSx for Windows.\n+ Bật hạn ngạch lưu trữ theo người dùng trên hệ thống tệp FSx sử dụng giao diện PowerShell FSx từ xa, đặt giới hạn mặc định và cảnh báo, và thực thi hạn ngạch tùy chỉnh cho một người dùng cụ thể.\n+ Tạo một chia sẻ SMB được mã hóa, khả dụng liên tục cho khối lượng công việc SQL trên FSx, sử dụng thông tin xác thực từ AWS Secrets Manager và FSx PowerShell CLI để kích hoạt Continuous Availability.\n+ Mở rộng thông lượng và dung lượng lưu trữ của hệ thống tệp FSx từ console, tăng MB/s và tổng GiB trong khi cho phép FSx thực hiện tối ưu hóa trực tuyến trong nền.\n+ Xóa toàn bộ môi trường lab FSx bằng cách xóa ngăn xếp CloudFormation ban đầu và xác nhận rằng tất cả các tài nguyên liên quan đã bị chấm dứt để tránh chi phí phát sinh.\n+ Đọc phần “Using the AWS CLI (reference)” để hiểu cách tự động hóa các tác vụ FSx, AD, và liên quan với AWS CLI thay vì console. 24/10/2025 24/10/2025 Managing storage quotas - Amazon FSx for Windows File Server\nManaging throughput and storage capacity\nOne-time file system setup tasks using the Amazon FSx CLI Kết quả đạt được Tuần 7: Đã cung cấp và quản lý thành công môi trường máy chủ tệp Windows hiệu suất cao trên AWS sử dụng FSx. Thực hiện các tác vụ lưu trữ thiết yếu bao gồm Chống trùng lặp dữ liệu (tiết kiệm không gian) và Shadow Copies (cho phép khôi phục bởi người dùng). Thực thi quản trị thông qua hạn ngạch lưu trữ người dùng và giám sát sức khỏe hệ thống tệp qua CloudWatch. Nâng cao kiến thức đội nhóm về các dịch vụ và kiến trúc AWS thông qua các buổi học tập tương tác. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/7-feedback/","title":"Chia sẻ, đóng góp ý kiến","tags":[],"description":"","content":"Đánh giá chung 1. Môi trường làm việc\nMôi trường làm việc rất thân thiện và cởi mở. Các thành viên trong FCJ luôn sẵn sàng hỗ trợ khi mình gặp khó khăn, kể cả ngoài giờ làm việc. Không gian làm việc gọn gàng, thoải mái, giúp mình tập trung tốt hơn. Chúng mình cũng thường xuyên có các buổi giao lưu và hoạt động gắn kết team, giúp thắt chặt mối quan hệ và làm cho không khí làm việc trở nên vui vẻ hơn.\n2. Sự hỗ trợ của mentor / team admin\nMentor hướng dẫn rất chi tiết, giải thích rõ ràng khi mình chưa hiểu và luôn khuyến khích mình đặt câu hỏi. Các anh chị cũng rất nhiệt tình chia sẻ link các khóa học Udemy miễn phí hoặc các nguồn tài liệu chất lượng để tụi mình học thêm. Team admin hỗ trợ các thủ tục, tài liệu và tạo điều kiện để mình làm việc thuận lợi. Mình đánh giá cao việc mentor cho phép mình thử và tự xử lý vấn đề thay vì chỉ đưa đáp án.\n3. Sự phù hợp giữa công việc và chuyên ngành học\nMặc dù các công việc cụ thể—tập trung vào kỹ thuật phần mềm, phát triển web và ứng dụng—không hoàn toàn trùng khớp với giáo trình hiện tại ở trường đại học, nhưng mình thấy đây là một lợi thế lớn. Nó thúc đẩy mình dấn thân vào những lĩnh vực mới mà mình chưa từng tiếp cận, giúp mình xây dựng những kỹ năng mới quý giá một cách hiệu quả.\n4. Cơ hội học hỏi \u0026amp; phát triển kỹ năng\nTrong quá trình thực tập, mình học được nhiều kỹ năng mới như sử dụng công cụ quản lý dự án, kỹ năng làm việc nhóm, và cả cách giao tiếp chuyên nghiệp trong môi trường công ty. Quan trọng nhất là mình đã tích lũy được nhiều kinh nghiệm thực tế chuyên sâu về các dịch vụ AWS và kiến trúc đám mây. Mentor cũng chia sẻ nhiều kinh nghiệm thực tế giúp mình định hướng tốt hơn cho sự nghiệp.\n5. Văn hóa \u0026amp; tinh thần đồng đội\nVăn hóa công ty rất tích cực, cởi mở và hỗ trợ lẫn nhau. Mọi người tôn trọng lẫn nhau, làm việc nghiêm túc nhưng vẫn vui vẻ. Đối với các dự án, mỗi team làm việc rất gắn kết, và khi có việc gấp, mọi người đều hỗ trợ nhau không phân biệt vị trí. Điều này giúp mình cảm thấy mình thực sự là một phần của tập thể, dù chỉ là thực tập sinh.\n6. Chính sách / phúc lợi cho thực tập sinh\nCông ty tạo điều kiện rất tốt về thời gian làm việc linh hoạt, rất thuận tiện. Giá trị thực sự nằm ở khối lượng kiến thức khổng lồ về công nghệ điện toán đám mây và những mối quan hệ chuyên nghiệp mà mình đã xây dựng được trong quá trình thực tập, những điều này là vô giá cho sự nghiệp sau này của mình.\nMột số câu hỏi khác Điều bạn hài lòng nhất trong thời gian thực tập?\nĐiều khiến mình hài lòng nhất là đã thiết lập thành công các tích hợp phức tạp như Telegram và Cognito. Việc chứng kiến luồng xác thực hoạt động trơn tru và có thể triển khai toàn bộ cơ sở hạ tầng bằng AWS CDK đã mang lại cho mình cảm giác thành tựu lớn trong việc làm chủ các thách thức kỹ thuật này.\nĐiều bạn nghĩ công ty cần cải thiện cho các thực tập sinh sau?\nMình tin rằng thời gian biểu của các buổi workshop có thể được cải thiện. Cụ thể, việc sắp xếp Mastery Series sớm hơn, trước khi giai đoạn dự án bắt đầu, sẽ cung cấp cho thực tập sinh kiến thức nền tảng cần thiết để giải quyết dự án hiệu quả hơn ngay từ đầu.\nNếu giới thiệu cho bạn bè, bạn có khuyên họ thực tập ở đây không? Vì sao?\nCó, mình chắc chắn sẽ giới thiệu. Cộng đồng ở đây cực kỳ cởi mở và các mentor thực sự hỗ trợ rất nhiệt tình. Mình đặc biệt trân trọng văn hóa hỗ trợ lẫn nhau và tư duy cùng nhau hoàn thiện bản thân và giúp đỡ nhau cùng phát triển.\nĐề xuất \u0026amp; mong muốn Bạn có đề xuất gì để cải thiện trải nghiệm trong kỳ thực tập?\nNhư đã đề cập, việc điều chỉnh lịch trình workshop để đảm bảo việc đào tạo kỹ thuật (như Mastery Series) diễn ra trước khi bắt đầu dự án sẽ là một cải tiến đáng kể cho các khóa tiếp theo.\nBạn có muốn tiếp tục chương trình này trong tương lai?\nCó, mình rất mong muốn được tiếp tục đồng hành cùng chương trình.\nGóp ý khác (tự do chia sẻ): Mình muốn gửi lời cảm ơn chân thành vì cơ hội thực tập này. Đây thực sự là một trải nghiệm học tập quý giá.\n"},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.7-isolate-ec2/","title":"Mã Isolate EC2","tags":[],"description":"","content":" import json import boto3 import os from botocore.exceptions import ClientError ISOLATION_SG_ID = os.getenv(\u0026#39;ISOLATION_SG_ID\u0026#39;) def lambda_handler(event, context): print(\u0026#34;=== ISOLATE EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) instance_id = event.get(\u0026#39;InstanceId\u0026#39;) region = event.get(\u0026#39;Region\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) if not instance_id or not ISOLATION_SG_ID: print(\u0026#34;[ERROR] Missing InstanceId or IsolationSGId in input. Cannot isolate.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: \u0026#34;Missing input data\u0026#34;} try: ec2 = boto3.client(\u0026#39;ec2\u0026#39;, region_name=region) response = ec2.describe_instances(InstanceIds=[instance_id]) instance = response[\u0026#39;Reservations\u0026#39;][0][\u0026#39;Instances\u0026#39;][0] current_sgs = [sg[\u0026#39;GroupId\u0026#39;] for sg in instance.get(\u0026#39;SecurityGroups\u0026#39;, [])] if ISOLATION_SG_ID in current_sgs: print(f\u0026#34;[INFO] {instance_id} already has isolation SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;already_isolated\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: None } print(f\u0026#34;[ACTION] Isolating {instance_id} in {region} with SG {ISOLATION_SG_ID}\u0026#34;) ec2.modify_instance_attribute( InstanceId=instance_id, Groups=[ISOLATION_SG_ID] ) print(f\u0026#34;[SUCCESS] {instance_id} isolated with SG {ISOLATION_SG_ID}\u0026#34;) return { **event, \u0026#34;status\u0026#34;: \u0026#34;isolation_complete\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;Region\u0026#34;: region, \u0026#34;IsolationSG\u0026#34;: ISOLATION_SG_ID } except ClientError as e: error_code = e.response.get(\u0026#39;Error\u0026#39;, {}).get(\u0026#39;Code\u0026#39;) print(f\u0026#34;[ERROR] Isolation FAILED for {instance_id} ({error_code}): {str(e)}\u0026#34;) return { \u0026#34;status\u0026#34;: \u0026#34;isolation_failed\u0026#34;, \u0026#34;InstanceId\u0026#34;: instance_id, \u0026#34;error\u0026#34;: str(e) } except Exception as e: print(f\u0026#34;[ERROR] Isolation FAILED (General) for {instance_id}: {str(e)}\u0026#34;) raise e "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.7-dashboard-setup/","title":"Thiết lập Dashboard","tags":[],"description":"","content":"Hướng dẫn này sẽ chỉ cho bạn cách thiết lập security dashboard. Security dashboard sẽ sử dụng S3 để chứa các file và thư mục web, Lambda để truy vấn dữ liệu bằng Athena, API Gateway để định tuyến api tới Lambda và Cloudfront để caching và truy cập web bằng URL của nó.\nNội dung Thiết lập S3 Thiết lập Lambda Thiết lập API Gateway Thiết lập Cloudfront Thiết lập Cognito "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.8-week8/","title":"Nhật ký Tuần 8","tags":[],"description":"","content":"Mục tiêu Tuần 8: Học các nguyên tắc cơ bản của phát triển web 3D sử dụng Three.js và WebGL. Chuẩn bị kỹ lưỡng cho kỳ thi giữa kỳ AWS (AWS Midterm Exam) bằng các bài kiểm tra thực hành và flashcards. Phối hợp với nhóm để xác định các lỗ hổng kiến thức và củng cố các điểm yếu. Khám phá các ngân hàng câu hỏi AWS Certified Solutions Architect để hiểu sâu hơn. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Bắt đầu học các nguyên tắc cơ bản của Three.js sử dụng khóa học Three.js Journey để chuẩn bị cho việc xây dựng trải nghiệm web 3D tương tác.\n+ Xem lại giới thiệu Three.js Journey để hiểu cách WebGL hoạt động ngầm và cách Three.js đơn giản hóa việc render 3D trong trình duyệt.\n+ Thiết lập một dự án Three.js tối thiểu với HTML canvas, import thư viện, và khởi tạo một scene, camera, và WebGL renderer cơ bản để hiển thị nội dung trên trang.\n+ Tạo một lưới khối 3D (cube mesh) đơn giản sử dụng BoxGeometry và vật liệu cơ bản, sau đó render nó trên màn hình để xác minh rằng môi trường đã được cấu hình chính xác.\n+ Thử nghiệm với vị trí camera và xoay đối tượng trong vòng lặp hoạt ảnh để xem các thay đổi ảnh hưởng như thế nào đến chế độ xem và cảm giác tương tác trong thời gian thực.\n+ Ghi chú về cách các khái niệm Three.js cốt lõi này có thể tích hợp sau này với kỹ năng JavaScript và frontend hiện có cho các dự án kiểu portfolio. 27/10/2025 27/10/2025 Three.js Journey — Learn WebGL with Three.js\nthree.js manual – Getting started 3 - Tạo 500 AWS Flashcards cùng với các thành viên trong nhóm để học trên Quizlet 28/10/2025 28/10/2025 4 - Tìm thấy 2 GitHub Repo có các câu hỏi và câu trả lời mà tôi nghĩ có phần liên quan đến bài kiểm tra giữa kỳ 29/10/2025 29/10/2025 AWS Certified Solutions Architect Exam\nAWS Certified Cloud Practitioner Notes 5 Thực hành các câu hỏi thi AWS sử dụng tài nguyên GitHub từ Ngày 4 và tóm tắt cơ bản từ NotebookLM.\n+ Sử dụng ghi chú AWS Certified Cloud Practitioner từ những người học khác trực tuyến để hoàn thành các bài kiểm tra thực hành và kiểm tra mức độ sẵn sàng tổng thể cho giữa kỳ.\n+ Thực hành khoảng 40 câu hỏi từ các bộ câu hỏi kiểu AWS Certified Solutions Architect Associate để làm quen với các mục dựa trên kịch bản khó hơn.\n+ Mở các repo GitHub tìm thấy vào Ngày 4 trong quá trình ôn tập để tra cứu nhanh các giải thích khi câu trả lời không rõ ràng.\n+ Sử dụng Gemini với các ghi chú đã chọn để đơn giản hóa định nghĩa của các dịch vụ và khái niệm AWS cốt lõi xuất hiện thường xuyên trong các câu hỏi thực hành.\n+ Sử dụng NotebookLM cũ để tạo các câu đố. 30/10/2025 30/10/2025 6 - Ngày thi FCJ Midterm Exam (300/650) 31/10/2025 31/10/2025 Kết quả đạt được Tuần 8: Đã thiết lập thành công môi trường phát triển cho Three.js và render các cảnh 3D ban đầu. Phối hợp xây dựng bộ học liệu Flashcards AWS gồm 500 thẻ. Hoàn thành Bài kiểm tra Giữa kỳ, xác định được điểm mạnh cá nhân và các lĩnh vực cần cải thiện. Tiếp cận với các kịch bản thực tế của kiến trúc sư giải pháp thông qua các câu hỏi thực hành. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.8-verify-setup/","title":"Kiểm tra thiết lập","tags":[],"description":"","content":"Sau tất cả các giai đoạn thiết lập, vui lòng tham khảo checklist để đảm bảo việc tạo tài nguyên đã hoàn tất.\nXác minh thiết lập Checklist xác minh hoàn thành:\nIncident Response and Forensics:\n✅ S3 Buckets: Tất cả 5 buckets đã được tạo với versioning/encryption ✅ IAM Roles: Tất cả 17 roles với đúng policies ✅ CloudTrail: Logging đã được bật ✅ GuardDuty: Đã bật với S3 export ✅ VPC Flow Logs: Đang hoạt động (Active) ✅ Lambda Functions: Tất cả 9 functions đã deploy ✅ Firehose Streams: Tất cả 3 streams đang hoạt động ✅ Glue Tables: Tất cả 4 tables đã được tạo ✅ S3 Events: Tất cả 4 triggers đã được cấu hình ✅ SNS Topic: Đã tạo với subscription ✅ Step Functions: Đang hoạt động (Active) ✅ EventBridge Rule: Đã bật với 2 targets Security Dashboard:\n✅ S3 Buckets: Bucket đã được tạo với file dashboard được lưu trữ và bật hosting ✅ Query Lambda: Lambda đã được tạo với các roles thích hợp ✅ API Gateway: API Gateway đã được tạo với đúng API và tài nguyên ✅ CloudFront: Distribution đã được tạo với API và S3 origins đã cấu hình ✅ Cognito: Đã liên kết với CloudFront distribution và tạo user trong user pool Kiểm tra đầu cuối (End-to-End Test)\nTạo mẫu các phát hiện GuardDuty: 1.1 GuardDuty Console → Settings → Generate sample findings (200+ findings) hoặc 1.2 Kích hoạt một finding đơn lẻ qua CloudShell (Detector Id nằm trong GuardDuty Console → Settings ) aws guardduty create-sample-findings --detector-id [$dectector-id] --finding-types \u0026#34;Recon:EC2/PortProbeUnprotectedPort\u0026#34; Giám sát workflow: Kiểm tra EventBridge, SNS, Step Functions, Lambda logs Xác minh cảnh báo: Kiểm tra email và Slack Truy vấn dữ liệu trong Athena: "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.8-quarantine-iam/","title":"Mã Quarantine IAM","tags":[],"description":"","content":" import json import boto3 import os QUARANTINE_POLICY_ARN = os.environ.get(\u0026#34;QUARANTINE_POLICY_ARN\u0026#34;) def lambda_handler(event, context): print(\u0026#34;=== EVENT RECEIVED ===\u0026#34;) print(json.dumps(event, indent=2)) try: finding = event.get(\u0026#39;detail\u0026#39;, {}) user_name = ( finding.get(\u0026#39;resource\u0026#39;, {}) .get(\u0026#39;accessKeyDetails\u0026#39;, {}) .get(\u0026#39;userName\u0026#39;) ) if not user_name: print(\u0026#34;[WARNING] No IAM user found in this finding. Skipping.\u0026#34;) return {\u0026#34;status\u0026#34;: \u0026#34;no_user\u0026#34;} print(f\u0026#34;[ACTION] Quarantining IAM User \u0026#39;{user_name}\u0026#39;...\u0026#34;) iam = boto3.client(\u0026#39;iam\u0026#39;) # Kiểm tra nếu policy đã được gán (Check if policy is already attached) attached_policies = iam.list_attached_user_policies(UserName=user_name)[\u0026#39;AttachedPolicies\u0026#39;] policy_arns = [p[\u0026#39;PolicyArn\u0026#39;] for p in attached_policies] if QUARANTINE_POLICY_ARN in policy_arns: print(f\u0026#34;[INFO] Policy {QUARANTINE_POLICY_ARN} is already attached to user {user_name}.\u0026#34;) else: iam.attach_user_policy( UserName=user_name, PolicyArn=QUARANTINE_POLICY_ARN ) print(f\u0026#34;[SUCCESS] Policy attached. User {user_name} is now quarantined.\u0026#34;) except Exception as e: print(f\u0026#34;[ERROR] Failed to quarantine user: {str(e)}\u0026#34;) raise e return {\u0026#34;status\u0026#34;: \u0026#34;processed\u0026#34;, \u0026#34;action\u0026#34;: \u0026#34;iam_quarantined\u0026#34;} "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.9-week9/","title":"Nhật ký Tuần 9","tags":[],"description":"","content":"Mục tiêu Tuần 9: Phân tích chi tiêu và mô hình sử dụng đám mây sử dụng AWS Glue và Amazon Athena. Giám sát các chỉ số EC2 trong thời gian thực bằng cách tạo bảng điều khiển Grafana tùy chỉnh qua CloudWatch. Tự động hóa quy trình nghiệp vụ sử dụng AWS Step Functions và AWS SAM. Triển khai cơ sở hạ tầng dưới dạng mã (IaC) sử dụng AWS CDK trong môi trường VS Code cục bộ. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 - Hoàn thành khóa học MOOC Quản trị dữ liệu và an toàn thông tin trên Coursera (Chương trình KS57) 03/11/2025 03/11/2025 3 Sử dụng AWS Glue và Amazon Athena để khám phá Báo cáo Chi phí \u0026amp; Sử dụng (Cost \u0026amp; Usage Reports - CUR) và hiểu nguồn gốc chi tiêu đám mây.\n+ Chạy các truy vấn Athena đơn giản trên các bảng CUR được tạo bởi Glue để xem các hàng ví dụ, kiểm tra chu kỳ thanh toán, và làm quen với cấu trúc dữ liệu chi phí.\n+ Tóm tắt chi phí theo tài khoản và dịch vụ trong Athena để xem tài khoản và dịch vụ AWS nào chịu trách nhiệm cho mức chi tiêu cao nhất, sau đó tập trung vào các dòng sử dụng Amazon EC2 theo yêu cầu (on-demand) chính để biết thêm chi tiết.\n+ Kiểm tra các thẻ phân bổ chi phí (như thẻ trung tâm chi phí) trong dữ liệu CUR để so sánh mức chi tiêu được gắn thẻ chính xác cho các nhóm so với mức vẫn chưa được gắn thẻ.\n+ So sánh mức sử dụng được giảm giá (Savings Plans/Instance dự trữ) với giá ước tính theo yêu cầu trong các truy vấn Athena để xem khoản tiết kiệm mà các khoản giảm giá cung cấp cho các loại sử dụng EC2 cụ thể.\n+ Sử dụng kết quả truy vấn để xây dựng bức tranh rõ ràng hơn về ai đang chi tiêu, cho dịch vụ nào, và hiệu quả ra sao, để chuẩn bị cho công việc tối ưu hóa chi phí trong tương lai. 04/11/2025 04/11/2025 Cost and performance analysis with AWS Glue and Amazon Athena\nQuerying Cost and Usage Reports using Amazon Athena\nAWS Cost and Usage Reports overview\nCreating tables for CUR data using AWS Glue and Athena\nOrganizing and tracking costs with AWS cost allocation tags\nAmazon Athena pricing 4 Thiết lập Grafana để giám sát EC2 instance của tôi sử dụng CloudWatch và xây dựng một bảng điều khiển trực tiếp đơn giản.\n+ Kết nối Grafana với Amazon CloudWatch như một nguồn dữ liệu để nó có thể đọc các chỉ số EC2 từ tài khoản AWS của tôi.\n+ Kiểm tra nguồn dữ liệu và xác nhận Grafana có thể truy vấn thành công các chỉ số CloudWatch cho instance của tôi.\n+ Tạo một bảng điều khiển Grafana với các bảng hiển thị các chỉ số EC2 chính như mức sử dụng CPU theo thời gian.\n+ Lưu bảng điều khiển và sử dụng các tùy chọn làm mới và chia sẻ để nó có thể được tái sử dụng để theo dõi sức khỏe instance trong thời gian thực. 05/11/2025 05/11/2025 Getting started with Grafana basic\nUsing Amazon CloudWatch metrics\nGrafana CloudWatch data source configuration\nBuild your first Grafana dashboard 5 Hoàn thành thiết lập đầu cuối dựa trên CDK cho môi trường máy chủ web EC2 được sử dụng trong bài lab AWS Storage Gateway, sử dụng VS Code cục bộ thay vì Cloud9.\n+ Hoàn thành các bước giới thiệu và chuẩn bị, bao gồm tạo IAM role cần thiết cho phép Storage Gateway truy cập S3 một cách an toàn. + Thiết lập môi trường phát triển AWS CDK cục bộ trong VS Code với AWS CLI được cấu hình cho đúng tài khoản và khu vực. + Khởi tạo một dự án AWS CDK mới, định nghĩa một VPC với các subnet công khai, và kiểm tra mẫu CloudFormation đã tổng hợp để tìm lỗi từ máy cục bộ. + Cập nhật CDK stack để thêm một EC2 instance, security group, và user data script cài đặt Apache, sau đó triển khai stack và xác thực máy chủ web từ IP công khai của instance. 06/11/2025 06/11/2025 CDK Basic 6 Hoàn thành workshop AWS Step Functions cốt lõi: mô hình hóa luồng nghiệp vụ, nối các dịch vụ mẫu, và triển khai state machine được quản lý bởi SAM với quyền IAM phù hợp.\n+ Xem lại chi tiết miền nghiệp vụ và quy trình làm việc cho quy trình đăng ký tài khoản, xác định từng bước nghiệp vụ để sau này ánh xạ vào các trạng thái Step Functions.\n+ Thiết lập môi trường VS Code cục bộ + AWS Toolkit và sử dụng nó (thay vì Cloud9 vì tôi không thể sử dụng) để làm việc với các dịch vụ backend mẫu và cơ sở hạ tầng của workshop trong khu vực AWS đích.\n+ Xây dựng AWS Step Functions state machine đầu tiên để điều phối việc tạo tài khoản và kiểm tra dữ liệu, sau đó sử dụng biểu đồ/lịch sử thực thi để xác minh đầu vào và đầu ra của từng trạng thái Task.\n+ Tinh chỉnh các trạng thái Task và xử lý đầu vào/đầu ra trạng thái với InputPath và ResultPath để dữ liệu ứng dụng và kết quả kiểm tra được bảo toàn sạch sẽ qua quy trình làm việc.\n+ Di chuyển state machine vào một SAM template với một execution role chuyên dụng, cho phép CloudFormation quản lý việc triển khai và IAM cho quy trình làm việc đầu cuối. 07/11/2025 07/11/2025 Get Started with AWS Step Functions\nUsing AWS SAM to build Step Functions workflows\nWorking with AWS CDK and Toolkit in VS Code\nProcessing input and output in Step Functions\nService-level permissions for Step Functions Kết quả đạt được Tuần 9: Phân tích hóa đơn chi tiết sử dụng Amazon Athena trên các bảng Data Glue Catalog. Thiết lập giải pháp quan sát thời gian thực cho EC2 sử dụng Grafana và CloudWatch. Điều phối thành công quy trình làm việc serverless sử dụng Step Functions và định nghĩa hạ tầng với SAM. Chuyển đổi việc cung cấp cơ sở hạ tầng từ các bước thủ công sang triển khai tự động bằng CDK trong VS Code. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.9-alert-dispatch/","title":"Mã Alert Dispatch","tags":[],"description":"","content":" import os import json import logging import urllib.request import boto3 from botocore.exceptions import ClientError import html # --- Telegram ENV --- # BOT_TOKEN = os.environ.get(\u0026#39;BOT_TOKEN\u0026#39;) # CHAT_ID = os.environ.get(\u0026#39;CHAT_ID\u0026#39;) # MESSAGE_THREAD_ID = os.environ.get(\u0026#39;MESSAGE_THREAD_ID\u0026#39;) # --- Slack ENV --- SLACK_WEBHOOK_URL = os.environ.get(\u0026#34;SLACK_WEBHOOK_URL\u0026#34;) # --- SES ENV --- SENDER_EMAIL = os.environ.get(\u0026#39;SENDER_EMAIL\u0026#39;) RECIPIENT_EMAIL = os.environ.get(\u0026#39;RECIPIENT_EMAIL\u0026#39;) # Can now be \u0026#34;a@b.com, c@d.com\u0026#34; AWS_REGION = os.environ.get(\u0026#39;AWS_REGION\u0026#39;, \u0026#39;ap-southeast-1\u0026#39;) # --- Setup --- # TELEGRAM_URL = f\u0026#34;https://api.telegram.org/bot{BOT_TOKEN}/sendMessage\u0026#34; if BOT_TOKEN else None logger = logging.getLogger() logger.setLevel(logging.INFO) # Initialize SES Client ses_client = boto3.client(\u0026#39;ses\u0026#39;, region_name=AWS_REGION) # ==================================================================== # SEND TO TELEGRAM # ==================================================================== # def send_to_telegram(finding, chat_id, thread_id): # logger.info(\u0026#34;Formatting message for Telegram...\u0026#34;) # ... (Code commented out, keeping as is or translating if needed, but it is commented out so skipping detailed translation for brevity unless enabled) # ==================================================================== # SEND TO SLACK # ==================================================================== def send_to_slack(finding): if not SLACK_WEBHOOK_URL: logger.warning(\u0026#34;Slack ENV missing. Skipping.\u0026#34;) return severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;🔴 CAO (HIGH)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;🟠 TRUNG BÌNH (MEDIUM)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;🔵 THẤP (LOW)\u0026#34; payload = { \u0026#34;text\u0026#34;: f\u0026#34;🚨 {sev} – {title}\u0026#34;, \u0026#34;attachments\u0026#34;: [{ \u0026#34;color\u0026#34;: color, \u0026#34;blocks\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;header\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;plain_text\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;🚨 GuardDuty Finding: {title}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;fields\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mức độ (Severity):*\\n{sev}\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Khu vực (Region):*\\n{region}\u0026#34;} ]}, {\u0026#34;type\u0026#34;: \u0026#34;section\u0026#34;, \u0026#34;text\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Mô tả (Description):*\\n{description}\u0026#34;}}, {\u0026#34;type\u0026#34;: \u0026#34;divider\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;context\u0026#34;, \u0026#34;elements\u0026#34;: [ {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Tài khoản (Account):* `{account_id}`\u0026#34;}, {\u0026#34;type\u0026#34;: \u0026#34;mrkdwn\u0026#34;, \u0026#34;text\u0026#34;: f\u0026#34;*Loại (Type):* `{finding_type}`\u0026#34;} ]} ] }] } try: req = urllib.request.Request( SLACK_WEBHOOK_URL, data=json.dumps(payload).encode(\u0026#34;utf-8\u0026#34;), headers={\u0026#34;Content-Type\u0026#34;: \u0026#34;application/json\u0026#34;} ) with urllib.request.urlopen(req) as response: logger.info(\u0026#34;Slack response: \u0026#34; + response.read().decode(\u0026#34;utf-8\u0026#34;)) except Exception as e: logger.error(f\u0026#34;SLACK FAILED: {e}\u0026#34;) # ==================================================================== # SEND TO SES EMAIL (UPDATED FOR MULTIPLE RECIPIENTS) # ==================================================================== def send_to_ses(finding): if not SENDER_EMAIL or not RECIPIENT_EMAIL: logger.warning(\u0026#34;SES Env vars missing. Skipping Email.\u0026#34;) return logger.info(\u0026#34;Formatting message for SES Email...\u0026#34;) recipient_list = [email.strip() for email in RECIPIENT_EMAIL.split(\u0026#39;,\u0026#39;)] severity_num = finding.get(\u0026#34;severity\u0026#34;, 0) title = finding.get(\u0026#34;title\u0026#34;, \u0026#34;No Title\u0026#34;) description = finding.get(\u0026#34;description\u0026#34;, \u0026#34;No Description\u0026#34;) region = finding.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;) account_id = finding.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;) finding_type = finding.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;) finding_id = finding.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) if severity_num \u0026gt;= 7: color = \u0026#34;#ff0000\u0026#34; sev = \u0026#34;HIGH (CAO)\u0026#34; elif severity_num \u0026gt;= 4: color = \u0026#34;#ffa500\u0026#34; sev = \u0026#34;MEDIUM (TRUNG BÌNH)\u0026#34; else: color = \u0026#34;#007bff\u0026#34; sev = \u0026#34;LOW (THẤP)\u0026#34; html_body = f\u0026#34;\u0026#34;\u0026#34; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;style\u0026gt; body {{ font-family: Arial, sans-serif; line-height: 1.6; color: #333; }} .container {{ width: 100%; max-width: 600px; margin: 0 auto; border: 1px solid #ddd; border-radius: 8px; overflow: hidden; }} .header {{ background-color: {color}; color: white; padding: 15px; text-align: center; }} .content {{ padding: 20px; }} .footer {{ background-color: #f4f4f4; padding: 10px; text-align: center; font-size: 12px; color: #666; }} .label {{ font-weight: bold; color: #555; }} \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;header\u0026#34;\u0026gt; \u0026lt;h2\u0026gt;🚨 Cảnh báo GuardDuty: {sev}\u0026lt;/h2\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;content\u0026#34;\u0026gt; \u0026lt;h3\u0026gt;{title}\u0026lt;/h3\u0026gt; \u0026lt;p\u0026gt;{description}\u0026lt;/p\u0026gt; \u0026lt;hr\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Tài khoản:\u0026lt;/span\u0026gt; {account_id}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Khu vực:\u0026lt;/span\u0026gt; {region}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;Loại:\u0026lt;/span\u0026gt; {finding_type}\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;span class=\u0026#34;label\u0026#34;\u0026gt;ID Phát hiện:\u0026lt;/span\u0026gt; {finding_id}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div class=\u0026#34;footer\u0026#34;\u0026gt; Được tạo bởi AWS Lambda Alert Dispatch \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; \u0026#34;\u0026#34;\u0026#34; try: response = ses_client.send_email( Source=SENDER_EMAIL, Destination={\u0026#39;ToAddresses\u0026#39;: recipient_list}, # Uses the list now Message={ \u0026#39;Subject\u0026#39;: {\u0026#39;Data\u0026#39;: f\u0026#34;GuardDuty Alert [{sev}]: {title}\u0026#34;, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}, \u0026#39;Body\u0026#39;: {\u0026#39;Html\u0026#39;: {\u0026#39;Data\u0026#39;: html_body, \u0026#39;Charset\u0026#39;: \u0026#39;UTF-8\u0026#39;}} } ) logger.info(f\u0026#34;SES Email sent to {len(recipient_list)} recipients! MessageId: {response[\u0026#39;MessageId\u0026#39;]}\u0026#34;) except ClientError as e: logger.error(f\u0026#34;SES FAILED: {e.response[\u0026#39;Error\u0026#39;][\u0026#39;Message\u0026#39;]}\u0026#34;) # ==================================================================== # MAIN HANDLER # ==================================================================== def lambda_handler(event, context): logger.info(f\u0026#34;Event received: {json.dumps(event)}\u0026#34;) try: sns_message_raw = event[\u0026#34;Records\u0026#34;][0][\u0026#34;Sns\u0026#34;][\u0026#34;Message\u0026#34;] message_data = json.loads(sns_message_raw) # Normalization Logic finding = {} if \u0026#34;detail-type\u0026#34; in message_data and message_data[\u0026#34;detail-type\u0026#34;] == \u0026#34;GuardDuty Finding\u0026#34;: detail = message_data[\u0026#34;detail\u0026#34;] finding = { \u0026#34;severity\u0026#34;: detail.get(\u0026#34;severity\u0026#34;, 0), \u0026#34;title\u0026#34;: detail.get(\u0026#34;title\u0026#34;, \u0026#34;GuardDuty Finding\u0026#34;), \u0026#34;description\u0026#34;: detail.get(\u0026#34;description\u0026#34;, \u0026#34;No description provided\u0026#34;), \u0026#34;accountId\u0026#34;: detail.get(\u0026#34;accountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: detail.get(\u0026#34;region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: detail.get(\u0026#34;type\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;id\u0026#34;: detail.get(\u0026#34;id\u0026#34;, \u0026#34;N/A\u0026#34;) } elif \u0026#34;AlarmName\u0026#34; in message_data: state = message_data.get(\u0026#34;NewStateValue\u0026#34;) severity = 8 if state == \u0026#34;ALARM\u0026#34; else 0 finding = { \u0026#34;severity\u0026#34;: severity, \u0026#34;title\u0026#34;: f\u0026#34;CloudWatch Alarm: {message_data.get(\u0026#39;AlarmName\u0026#39;)}\u0026#34;, \u0026#34;description\u0026#34;: message_data.get(\u0026#34;NewStateReason\u0026#34;, \u0026#34;State change detected\u0026#34;), \u0026#34;accountId\u0026#34;: message_data.get(\u0026#34;AWSAccountId\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;region\u0026#34;: message_data.get(\u0026#34;Region\u0026#34;, \u0026#34;N/A\u0026#34;), \u0026#34;type\u0026#34;: \u0026#34;CloudWatch Alarm\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } else: finding = { \u0026#34;severity\u0026#34;: 0, \u0026#34;title\u0026#34;: \u0026#34;Unknown Alert\u0026#34;, \u0026#34;description\u0026#34;: f\u0026#34;Raw Payload: {json.dumps(message_data)}\u0026#34;, \u0026#34;accountId\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;N/A\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Unknown\u0026#34;, \u0026#34;id\u0026#34;: \u0026#34;N/A\u0026#34; } except Exception as e: logger.error(f\u0026#34;FATAL: Could not parse incoming SNS event: {e}\u0026#34;) return {\u0026#34;statusCode\u0026#34;: 500} # --- Send Telegram --- # if BOT_TOKEN and CHAT_ID: # send_to_telegram(finding, CHAT_ID, MESSAGE_THREAD_ID) # --- Send Slack --- if SLACK_WEBHOOK_URL: send_to_slack(finding) # --- Send SES Email --- if SENDER_EMAIL and RECIPIENT_EMAIL: send_to_ses(finding) return {\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;Dispatch complete\u0026#34;} "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.9-use-cdk/","title":"Sử dụng CDK","tags":[],"description":"","content":"Tổng quan Chúng tôi đã cung cấp CDK stack để tạo toàn bộ cơ sở hạ tầng cần thiết cho workshop này.\nĐể lấy các file, vui lòng truy cập Github Link và clone hoặc tải xuống tất cả các file về một thư mục.\nHướng dẫn cài đặt Trước khi triển khai CDK stack, bạn phải cấu hình môi trường cục bộ của mình để xác thực với tài khoản AWS bằng AWS Command Line Interface (CLI).\nCài đặt AWS CLI.\nLấy Credentials: Bạn cần một Access Key ID và một Secret Access Key từ một IAM user có quyền deployment.\nChạy lệnh cấu hình: Mở terminal và chạy lệnh aws configure.\n$ aws configure Khi được nhắc, nhập credentials và các cài đặt mong muốn. Default region name nên khớp với region nơi bạn định triển khai stack (ví dụ: ap-southeast-1):\nPrompt Example Value AWS Access Key ID AKIA... AWS Secret Access Key wJalr... Default region name ap-southeast-1 Default output format json Xác minh cấu hình: Kiểm tra thiết lập bằng cách lấy user identity. Kết quả thành công xác nhận bạn đã xác thực.\n$ aws sts get-caller-identity Điều kiện tiên quyết Đảm bảo các công cụ và dịch vụ sau đã được cài đặt và cấu hình trên hệ thống của bạn:\nPython 3.8+ và pip: Cần thiết để thực thi ứng dụng CDK và build Lambda function assets. Node.js và npm: Cần thiết để chạy AWS CDK CLI và build React dashboard. AWS CDK Toolkit: Cài đặt CDK CLI global: $ npm install -g aws-cdk Thiết lập môi trường Python Định nghĩa cơ sở hạ tầng được viết bằng Python. Một virtual environment chuyên dụng được sử dụng để quản lý các dependencies của dự án.\nTạo Virtual Environment:\n$ python -m venv .venv Kích hoạt Virtual Environment:\nOperating System Command macOS / Linux source .venv/bin/activate Windows (Command Prompt) .venv\\Scripts\\activate.bat Windows (PowerShell) .venv\\Scripts\\Activate.ps1 Cài đặt Python Dependencies:\n$ pip install -r requirements.txt Bước build dashboard Tại vị trí thư mục dự án, kiểm tra bên trong thư mục react. Nếu thư mục dist đã tồn tại, bạn không cần phải build. Nếu chưa, vui lòng làm theo các bước dưới đây. Nếu bạn đang dùng cmd sử dụng lệnh này để di chuyển vào thư mục react:\n$ cd react Và sử dụng lệnh này để liệt kê tất cả nội dung trong react:\n$ ls Điều kiện tiên quyết Đảm bảo bạn đã cài đặt Node.js và npm. Bạn có thể kiểm tra phiên bản hiện tại bằng cách chạy:\n$ npm --version Nếu lệnh không được nhận diện, vui lòng tải và cài đặt Node.js từ nodejs.org\nCài đặt dependencies Chạy lệnh sau để cài đặt tất cả các thư viện cần thiết:\n$ npm install Build Project Sau khi cài đặt hoàn tất, chạy lệnh build:\n$ npm run build Sau khi hoàn tất, một thư mục dist sẽ được tạo ra chứa index.html và thư mục assets.\nCấu hình Deployment Context Stack sử dụng các biến context (context variables). Các biến này được đọc từ cdk.context.json hoặc cung cấp qua cờ (flags) dòng lệnh.\nVariable Name Description Required if functionality is desired Default Value (in cdk.context.json) vpc_ids Danh sách các VPC IDs cho Flow Logs và DNS Query Logging. Có [] alert_email Danh sách các địa chỉ email cho thông báo cảnh báo (yêu cầu SES). Có [] sender_email Địa chỉ email người gửi SES đã xác thực. Có (nếu alert_email được thiết lập) \u0026quot;\u0026quot; slack_webhook_url Slack webhook URL để gửi cảnh báo. Không \u0026quot;\u0026quot; Ví dụ\n{ \u0026#34;vpc_ids\u0026#34;: [ \u0026#34;vpc-a1b2c3d4e5f6g7h8i\u0026#34; ], \u0026#34;alert_email\u0026#34;: [ \u0026#34;admin@example.com\u0026#34; ], \u0026#34;sender_email\u0026#34;: \u0026#34;alerts@your-domain.com\u0026#34;, \u0026#34;slack_webhook_url\u0026#34;: \u0026#34;\u0026#34; } Triển khai Stacks (Deploy) Trước khi xử lý tiếp, nếu đang ở trong thư mục /react, nhập lệnh này để quay lại thư mục chính:\n$ cd.. CDK Bootstrapping: Nếu bạn chưa từng sử dụng AWS CDK trong tài khoản AWS và region mục tiêu trước đây, chạy lệnh bootstrap một lần để cung cấp các tài nguyên cần thiết (ví dụ: S3 deployment bucket).\n$ cdk bootstrap (Tùy chọn) Synthesize và Diff: Xem lại các thay đổi CloudFormation được đề xuất trước khi deployment:\n$ cdk synth --all $ cdk diff --all Execute Deployment: Chạy lệnh deployment và phê duyệt bất kỳ thay đổi bảo mật IAM nào được yêu cầu khi được nhắc.\n$ cdk deploy --all Việc deployment hoàn tất khi CDK CLI báo cáo thành công cho stack: AwsIncidentResponseAutomationCdkStack và DashboardCdkStack\nLƯU Ý QUAN TRỌNG: Sau khi deployment hoàn tất, bạn nên xác minh email trong SES. Tạo một user trong Cognito để có thể đăng nhập vào Dashboard. Truy cập Security Group và xóa quy tắc outbound mặc định khỏi QuarantineSecurityGroup "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.10-week10/","title":"Nhật ký Tuần 10","tags":[],"description":"","content":"Mục tiêu Tuần 10: Củng cố quy trình Step Functions với callbacks, xử lý lỗi và các trạng thái song song. Thiết lập hệ thống cảnh báo Ứng phó Sự cố đa kênh (Telegram, Email). Cấu trúc dự án Ứng phó Sự cố trong Jira với các Epic và quyền sở hữu rõ ràng. Tối ưu hóa chi phí cảnh báo bằng cách chuyển từ SNS Email JSON sang Lambda-SES. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Mở rộng và làm cứng quy trình làm việc Step Functions với kích hoạt, tạm dừng/tiếp tục qua callbacks, xử lý lỗi mạnh mẽ, và kiểm tra song song.\n+ Cập nhật SubmitApplication Lambda để bắt đầu thực thi state machine tự động với payload đúng, biến các bài kiểm tra thủ công thành điểm nhập quy trình làm việc hướng sự kiện.\n+ Triển khai bước Chờ Phê duyệt dựa trên callback sử dụng task tokens để các ứng dụng bị gắn cờ tạm dừng trong Step Functions cho đến khi một Lambda xem xét riêng biệt tiếp tục chúng với quyết định chấp nhận/từ chối.\n+ Thêm các khối Retry và Catch vào các trạng thái Task quan trọng để các lỗi Lambda/API tạm thời được thử lại với backoff trong khi các lỗi không thể phục hồi chảy vào các đường dẫn xử lý lỗi rõ ràng.\n+ Chuyển đổi các kiểm tra tuần tự thành một trạng thái Parallel để xác thực tên và địa chỉ chạy đồng thời, sau đó điều chỉnh logic Choice để diễn giải đầu ra song song kết hợp một cách chính xác.\n+ Kết thúc bằng cách khám phá các tài nguyên Step Functions nâng cao (quy trình làm việc chạy dài, trạng thái Map/Wait, và các mẫu chính thức) để lên kế hoạch cho các bước tiếp theo cho các mẫu điều phối sẵn sàng cho sản xuất. 10/11/2025 10/11/2025 StartExecution – AWS Step Functions\nCallback patterns with task tokens\nHandling errors in Step Functions workflows\nParallel workflow state\nTutorials and workshops for learning Step Functions 3 Xây dựng hệ thống gửi cảnh báo SNS nền tảng: Email/EmailJSON để gửi đến hộp thư đến, mã Lambda tùy chỉnh cho Telegram với thiết lập bot và trò chuyện nhóm dựa trên chủ đề, và tạo các phát hiện GuardDuty thử nghiệm.\n+ Tạo một SNS topic (SNSToTelegram) và đăng ký Email và EmailJSON trực tiếp để các cảnh báo bảo mật tự động định tuyến đến hộp thư email của bạn mà không cần xử lý Lambda.\n+ Thiết lập một Telegram bot qua BotFather, lấy token bot, tạo một nhóm trò chuyện, bật tính năng Topics, và trích xuất ID trò chuyện và ID luồng tin nhắn để định tuyến cảnh báo có mục tiêu.\n+ Triển khai một hàm Telegram Lambda với token bot, ID trò chuyện, và ID luồng tin nhắn được lưu trữ dưới dạng biến môi trường, sau đó mã hóa hàm để phân tích tin nhắn SNS và chuyển tiếp chúng đến chủ đề Telegram.\n+ Cấu hình SNS topic để kích hoạt Telegram Lambda để các sự kiện bảo mật đến tự động gửi thông báo đến cả email và chủ đề trò chuyện nhóm Telegram cùng một lúc.\n+ Tạo các phát hiện mẫu AWS GuardDuty (Hơn 1000 emails\u0026hellip; Đây là một sai lầm). 11/11/2025 11/11/2025 4 Cấu trúc dự án Hệ thống Ứng phó Sự cố AWS trong Jira bằng cách xác định các epic cốt lõi, gán quyền sở hữu trên nhiều nhóm, và thiết lập nền tảng cho các quy trình xử lý sự cố.\n+ Tạo 5 epic chính trong Jira để ánh xạ quy trình ứng phó sự cố: Phát hiện mối đe dọa, Cảnh báo, Quy trình Ứng phó, Đường ống dữ liệu, và Thành phần Bảng điều khiển.\n+ Gán quyền sở hữu epic cho các thành viên nhóm cá nhân để mỗi khu vực có một người dẫn đầu rõ ràng chịu trách nhiệm cho phạm vi và việc giao hàng của nó.\n+ Tổ chức cấu trúc và trách nhiệm nhóm bằng cách căn chỉnh từng epic với bộ kỹ năng phù hợp (phát hiện mối đe dọa, cơ sở hạ tầng cảnh báo, điều phối quy trình làm việc, nhập dữ liệu, lập bảng điều khiển).\n+ Cấu hình phân rã epic-thành-tác vụ trong Jira để các nhiệm vụ phụ và vấn đề được gắn với epic cha của chúng, cho phép khả năng hiển thị nhóm và theo dõi burndown trên toàn hệ thống ứng phó sự cố. 12/11/2025 12/11/2025 5 Tối ưu hóa hệ thống cảnh báo bằng cách thay thế đăng ký Email SNS bằng Lambda→SES để giảm chi phí, cho phép định dạng email tùy chỉnh, và tận dụng giới hạn gửi cao hơn của SES.\n+ Phân tích tác động giá cả SNS từ các phát hiện mẫu GuardDuty và xác định rằng các đăng ký Email trực tiếp đang tạo ra các khoản phí không mong muốn về chi phí gửi SNS.\n+ Nghiên cứu khả năng của AWS SES và phát hiện ra nó cung cấp giới hạn gửi cao hơn và kiểm soát hoàn toàn định dạng email so với đăng ký Email SNS.\n+ Tạo một hàm Lambda mới để thay thế đăng ký Email SNS nhận tin nhắn SNS, phân tích các phát hiện GuardDuty, và gửi email HTML được định dạng qua SES.\n+ Triển khai mẫu email tùy chỉnh trong SES Lambda với HTML được tạo kiểu, siêu dữ liệu cảnh báo nhúng, chỉ báo mức độ nghiêm trọng, và chi tiết phát hiện GuardDuty để dễ đọc và hành động hơn.\n+ Cập nhật cấu hình SNS topic để kích hoạt cả Telegram Lambda và SES Lambda mới, loại bỏ đăng ký Email và giảm phí SNS trong khi duy trì việc gửi cảnh báo kênh đôi (Email + Telegram). 13/11/2025 13/11/2025 6 - Làm việc Freelance 14/11/2025 14/11/2025 Kết quả đạt được Tuần 10: Đã cung cấp một state machine Step Functions mạnh mẽ với các mẫu callback, xử lý song song và khả năng phục hồi lỗi. Kiến trúc và triển khai hệ thống gửi cảnh báo nhạy cảm về chi phí, đa kênh (Telegram + SES Email). Thiết lập khung Quản lý Dự án có cấu trúc trong Jira, căn chỉnh vai trò nhóm với các Epic kỹ thuật. Giảm thiểu thành công các chi phí SNS không mong muốn bằng cách tái cấu trúc cơ chế gửi email sử dụng AWS SES. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.10-cleanup/","title":"Dọn dẹp","tags":[],"description":"","content":"Chúc mừng bạn đã hoàn thành workshop này! Trong workshop này, bạn đã tạo một Hệ thống Phản hồi Sự cố và Điều tra số Tự động và làm quen với Lambda, Step Functions, EventBridge, Glue, Athena, CloudFront, Cognito, S3 Buckets\nHướng dẫn dọn dẹp: Hướng dẫn dọn dẹp cho thiết lập thủ công Hướng dẫn dọn dẹp cho thiết lập CDK "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.10-cleanup/5.10.1-manual-cleanup/","title":"Dọn dẹp thủ công","tags":[],"description":"","content":"Clean up (Thiết lập cơ sở hạ tầng thủ công) Giai đoạn 1: Dọn dẹp Automation và Monitoring Mục tiêu ở đây là dừng tất cả các tiến trình đang hoạt động và xóa các tài nguyên monitoring và automation cốt lõi (EventBridge, Step Functions, SNS, GuardDuty, Flow Logs, CloudTrail).\n1. Xóa Incident Response Automation 1.1 Xóa EventBridge Rule\nVào EventBridge Console → Rules. Chọn rule: IncidentResponseAlert. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.2 Xóa Step Functions State Machine\nVào Step Functions Console → State Machines. Chọn State Machine: IncidentResponseStepFunctions. Nhấn \u0026ldquo;Delete\u0026rdquo;. 1.3 Xóa SNS Topic và Subscription\nVào SNS Console → Topics → IncidentResponseAlerts. Đầu tiên, xóa subscription liên kết với ir-alert-dispatch. Sau đó, xóa chính topic bằng cách nhấn \u0026ldquo;Delete topic\u0026rdquo;. 1.4 Xóa GuardDuty Detector\nVào GuardDuty Console → Settings → General. Nhấn \u0026ldquo;Suspend\u0026rdquo; để dừng xử lý, sau đó nhấn \u0026ldquo;Disable GuardDuty\u0026rdquo; (hoặc \u0026ldquo;Delete detector\u0026rdquo;). 1.5 Vô hiệu hóa VPC Flow Logs\nVào VPC Console → VPC Flow Logs. Chọn flow log đã tạo (liên kết với YOUR_VPC_ID). Nhấn \u0026ldquo;Delete flow log\u0026rdquo;. 1.6 Xóa CloudTrail Trail\nVào CloudTrail Console → Trails. Chọn trail: incident-responses-cloudtrail-ACCOUNT_ID-REGION. Nhấn \u0026ldquo;Delete\u0026rdquo;. Giai đoạn 2: Dọn dẹp Lambda và Compute 2. Xóa tất cả Lambda Functions (9 Functions) Vào Lambda Console và xóa các functions sau:\nincident-response-cloudtrail-etl incident-response-guardduty-etl cloudwatch-etl-lambda cloudwatch-eni-etl-lambda cloudwatch-export-lambda ir-parse-findings-lambda ir-isolate-ec2-lambda ir-quarantine-iam-lambda ir-alert-dispatch 3. Xóa Isolation Security Group Vào EC2 Console → Security Groups. Tìm và chọn Security Group: IR-Isolation-SG (sử dụng ID sg-XXXXXXX). Nhấn \u0026ldquo;Delete security group\u0026rdquo;. 4. Xóa CloudWatch Log Groups Vào CloudWatch Console → Log Groups và xóa:\nCentralized log group: /aws/incident-response/centralized-logs. Bất kỳ Lambda log groups nào liên quan đến 9 functions đã xóa (ví dụ: /aws/lambda/ir-parse-findings-lambda). Giai đoạn 3: Dọn dẹp Processing và Data Lake 5. Xóa Kinesis Data Firehose Streams Vào Kinesis Console → Delivery Streams và xóa:\ncloudtrail-firehose-stream vpc-dns-firehose-stream vpc-flow-firehose-stream 6. Xóa AWS Glue Tables và Database 6.1 Xóa Glue Tables\nVào Glue Console → Tables. Chọn và xóa: security_logs.processed_cloudtrail, security_logs.processed_guardduty, security_logs.vpc_logs, và security_logs.eni_flow_logs. 6.2 Xóa Glue Database\nVào Glue Console → Databases. Chọn database: security_logs và nhấn \u0026ldquo;Delete\u0026rdquo;. 7. Xóa IAM Roles và Policies 7.1 Xóa IAM Policies\nVào IAM Console → Policies. Xóa custom managed policy: IrQuarantineIAMPolicy. Lưu ý: Inline policies được tạo trong quá trình cài đặt sẽ tự động bị xóa khi role tương ứng bị xóa. 7.2 Xóa IAM Roles\nVào IAM Console → Roles. Xóa 17 roles sau: Lambda Execution Roles: CloudTrailETLLambdaServiceRole, GuardDutyETLLambdaServiceRole, CloudWatchETLLambdaServiceRole, CloudWatchENIETLLambdaServiceRole, CloudWatchExportLambdaServiceRole, ParseFindingsLambdaServiceRole, IsolateEC2LambdaServiceRole, QuarantineIAMLambdaServiceRole, AlertDispatchLambdaServiceRole. Service Roles: CloudTrailFirehoseRole, CloudWatchFirehoseRole, StepFunctionsRole, IncidentResponseStepFunctionsEventRole, FlowLogsIAMRole, GlueCloudWatchRole. Giai đoạn 4: Dọn dẹp S3 Bucket (Xóa dữ liệu) 8. Làm trống và Xóa S3 Buckets Đây là bước cuối cùng để đảm bảo tất cả các khoản phí lưu trữ được dừng lại.\nBucket Name Mục đích incident-response-log-list-bucket-ACCOUNT_ID-REGION Nguồn Log Chính (CloudTrail/GuardDuty/Exported CW) processed-cloudtrail-logs-ACCOUNT_ID-REGION Firehose Destination cho CloudTrail logs processed-cloudwatch-logs-ACCOUNT_ID-REGION Firehose Destination cho VPC DNS/Flow logs processed-guardduty-findings-ACCOUNT_ID-REGION ETL Destination cho GuardDuty logs athena-query-results-ACCOUNT_ID-REGION Lưu trữ kết quả truy vấn Athena Vào S3 Console. Đối với mỗi bucket trong 5 buckets: Nhấn vào tên bucket. Vào tab \u0026ldquo;Objects\u0026rdquo;. Nhấn \u0026ldquo;Empty\u0026rdquo; để xóa tất cả dữ liệu. Bạn phải xác nhận việc xóa vĩnh viễn bằng cách gõ permanently delete. Quay lại danh sách S3 bucket, chọn bucket, và nhấn \u0026ldquo;Delete\u0026rdquo;. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/5.11.10-step-functions-state-machine-definition/","title":"Mã Định nghĩa Step Functions ASL","tags":[],"description":"","content":" { \u0026#34;Comment\u0026#34;: \u0026#34;Guardduty Incident Response Automation\u0026#34;, \u0026#34;StartAt\u0026#34;: \u0026#34;CheckFindingType\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;CheckFindingType\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Comment\u0026#34;: \u0026#34;Check if EC2 (Kiểm tra nếu là EC2)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Instance\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;ParseFindings\u0026#34; }, { \u0026#34;Comment\u0026#34;: \u0026#34;Check if IAM (Kiểm tra nếu là IAM)\u0026#34;, \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.resourceType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;AccessKey\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;Quarantine_IAM_User\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;NoActionNeeded\u0026#34; }, \u0026#34;ParseFindings\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34;, \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-parse-findings-lambda\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34;, \u0026#34;Lambda.TooManyRequestsException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 1, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2, \u0026#34;JitterStrategy\u0026#34;: \u0026#34;FULL\u0026#34; } ], \u0026#34;Next\u0026#34;: \u0026#34;Isolate_EC2_Instance\u0026#34; }, \u0026#34;Isolate_EC2_Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-isolate-ec2-lambda\u0026#34;, \u0026#34;Payload\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceIds[0]\u0026#34;, \u0026#34;Region.$\u0026#34;: \u0026#34;$.Region\u0026#34; } }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;Next\u0026#34;: \u0026#34;CheckIsolationStatus\u0026#34;, \u0026#34;OutputPath\u0026#34;: \u0026#34;$.Payload\u0026#34; }, \u0026#34;CheckIsolationStatus\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.IsolationSG\u0026#34;, \u0026#34;IsNull\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;AlreadyIsolated\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;EnableTerminationProtection\u0026#34; }, \u0026#34;AlreadyIsolated\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; }, \u0026#34;EnableTerminationProtection\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:modifyInstanceAttribute\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceId.$\u0026#34;: \u0026#34;$.InstanceId\u0026#34;, \u0026#34;DisableApiTermination\u0026#34;: { \u0026#34;Value\u0026#34;: true } }, \u0026#34;Next\u0026#34;: \u0026#34;CreateQuarantineTag\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;CreateQuarantineTag\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createTags\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Resources.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; }, { \u0026#34;Key\u0026#34;: \u0026#34;Security Group\u0026#34;, \u0026#34;Value.$\u0026#34;: \u0026#34;$.IsolationSG\u0026#34; } ] }, \u0026#34;Next\u0026#34;: \u0026#34;DescribeInstanceASG\u0026#34;, \u0026#34;ResultPath\u0026#34;: null }, \u0026#34;DescribeInstanceASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:describeAutoScalingInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.ASGInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CheckIfASGExists\u0026#34; }, \u0026#34;CheckIfASGExists\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0]\u0026#34;, \u0026#34;IsPresent\u0026#34;: true, \u0026#34;Next\u0026#34;: \u0026#34;UpdateASGConfiguration\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;UpdateASGConfiguration\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:updateAutoScalingGroup\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;MinSize\u0026#34;: 0 }, \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;Wait for ASG\u0026#34; }, \u0026#34;Wait for ASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 10, \u0026#34;Next\u0026#34;: \u0026#34;DetachFromASG\u0026#34; }, \u0026#34;DetachFromASG\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:autoscaling:detachInstances\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;AutoScalingGroupName.$\u0026#34;: \u0026#34;$.ASGInfo.AutoScalingInstances[0].AutoScalingGroupName\u0026#34;, \u0026#34;InstanceIds.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34;, \u0026#34;ShouldDecrementDesiredCapacity\u0026#34;: false }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;AutoScaling.ValidationException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 15, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;ResultPath\u0026#34;: null, \u0026#34;Next\u0026#34;: \u0026#34;DescribeVolumes\u0026#34; }, \u0026#34;DescribeVolumes\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:describeVolumes\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;Filters\u0026#34;: [ { \u0026#34;Name\u0026#34;: \u0026#34;attachment.instance-id\u0026#34;, \u0026#34;Values.$\u0026#34;: \u0026#34;States.Array($.InstanceId)\u0026#34; } ] }, \u0026#34;ResultPath\u0026#34;: \u0026#34;$.VolumeInfo\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshots\u0026#34; }, \u0026#34;CreateSnapshots\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Map\u0026#34;, \u0026#34;ItemsPath\u0026#34;: \u0026#34;$.VolumeInfo.Volumes\u0026#34;, \u0026#34;MaxConcurrency\u0026#34;: 1, \u0026#34;Iterator\u0026#34;: { \u0026#34;StartAt\u0026#34;: \u0026#34;Wait before calling CreateSnapshot API\u0026#34;, \u0026#34;States\u0026#34;: { \u0026#34;Wait before calling CreateSnapshot API\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Wait\u0026#34;, \u0026#34;Seconds\u0026#34;: 15, \u0026#34;Next\u0026#34;: \u0026#34;CreateSnapshot\u0026#34; }, \u0026#34;CreateSnapshot\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::aws-sdk:ec2:createSnapshot\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;VolumeId.$\u0026#34;: \u0026#34;$.VolumeId\u0026#34;, \u0026#34;Description.$\u0026#34;: \u0026#34;States.Format(\u0026#39;IR Snapshot for {} - {}\u0026#39;, $.Attachments[0].InstanceId, $.VolumeId)\u0026#34;, \u0026#34;TagSpecifications\u0026#34;: [ { \u0026#34;ResourceType\u0026#34;: \u0026#34;snapshot\u0026#34;, \u0026#34;Tags\u0026#34;: [ { \u0026#34;Key\u0026#34;: \u0026#34;Quarantine\u0026#34;, \u0026#34;Value\u0026#34;: \u0026#34;True\u0026#34; } ] } ] }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Ec2.RequestLimitExceeded\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 60, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true } } }, \u0026#34;End\u0026#34;: true }, \u0026#34;Quarantine_IAM_User\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Choice\u0026#34;, \u0026#34;Choices\u0026#34;: [ { \u0026#34;Variable\u0026#34;: \u0026#34;$.detail.resource.accessKeyDetails.userType\u0026#34;, \u0026#34;StringEquals\u0026#34;: \u0026#34;Root\u0026#34;, \u0026#34;Next\u0026#34;: \u0026#34;RootUserDetected\u0026#34; } ], \u0026#34;Default\u0026#34;: \u0026#34;ExecuteIAMQuarantine\u0026#34; }, \u0026#34;RootUserDetected\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34;, \u0026#34;Comment\u0026#34;: \u0026#34;Cannot quarantine root user\u0026#34; }, \u0026#34;ExecuteIAMQuarantine\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Task\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:states:::lambda:invoke\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;FunctionName\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:831981618496:function:ir-quarantine-iam-lambda\u0026#34;, \u0026#34;Payload.$\u0026#34;: \u0026#34;$\u0026#34; }, \u0026#34;Retry\u0026#34;: [ { \u0026#34;ErrorEquals\u0026#34;: [ \u0026#34;Lambda.TooManyRequestsException\u0026#34;, \u0026#34;Lambda.ServiceException\u0026#34;, \u0026#34;Lambda.AWSLambdaException\u0026#34;, \u0026#34;Lambda.SdkClientException\u0026#34; ], \u0026#34;IntervalSeconds\u0026#34;: 2, \u0026#34;MaxAttempts\u0026#34;: 3, \u0026#34;BackoffRate\u0026#34;: 2 } ], \u0026#34;End\u0026#34;: true }, \u0026#34;NoActionNeeded\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;Succeed\u0026#34; } } } "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.11-week11/","title":"Nhật ký Tuần 11","tags":[],"description":"","content":"Mục tiêu Tuần 11: Tái cấu trúc các hàm Lambda Cảnh báo thành dịch vụ \u0026ldquo;Gửi Cảnh báo\u0026rdquo; (Alert Dispatch) thống nhất, mô-đun. Tích hợp khả năng webhook của Slack để mở rộng các kênh thông báo cảnh báo. Tập trung quản lý thông tin xác thực sử dụng Biến Môi trường Lambda. Tiếp tục hoàn thiện kế hoạch dự án Hệ thống Ứng phó Sự cố trong Jira. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Tham dự sự kiện AWS Cloud Mastery Series #2 – DevOps on AWS 17/11/2025 17/11/2025 3 Hợp nhất Telegram và SES Lambdas thành một hàm Gửi Cảnh báo (Alert Dispatch) thống nhất với mã có cấu trúc, tích hợp triển khai Slack của bạn bè, và xác thực mọi thứ với GuardDuty.\n+ Hợp nhất các hàm Telegram và SES Lambda riêng biệt thành một Alert Dispatch Lambda duy nhất với cấu trúc mã sạch, mô-đun và các hàm trợ giúp chuyên dụng cho từng kênh.\n+ Tích hợp gửi Slack webhook từ mã của bạn tôi—bây giờ cả ba kênh (Telegram, SES, Slack) đều được xử lý bởi một hàm với logic phân tích được chia sẻ.\n+ Cấu trúc mã Lambda đúng cách với sự phân tách rõ ràng: phân tích SNS → làm giàu cảnh báo → bộ định dạng cụ thể cho kênh (Slack blocks, tin nhắn Telegram, SES HTML) → xử lý lỗi.\n+ Thiết lập biến môi trường để quản lý tập trung tất cả thông tin xác thực (URL webhook Slack, token bot/ID trò chuyện/ID luồng Telegram, địa chỉ người gửi SES)—sạch sẽ hơn nhiều so với mã hóa cứng.\n+ Kiểm tra đường ống đa kênh hoàn chỉnh với các phát hiện mẫu GuardDuty—xác minh cảnh báo đến được định dạng chính xác trong Slack, Telegram, và email cùng lúc, và mọi thứ hoạt động đáng tin cậy. 18/11/2025 18/11/2025 4 Cấu trúc dự án Hệ thống Ứng phó Sự cố AWS trong Jira bằng cách xác định các epic cốt lõi, gán quyền sở hữu trên nhiều nhóm, và thiết lập nền tảng cho các quy trình xử lý sự cố.\n+ Tạo 5 epic chính trong Jira để ánh xạ quy trình ứng phó sự cố: Phát hiện mối đe dọa, Cảnh báo, Quy trình Ứng phó, Đường ống dữ liệu, và Thành phần Bảng điều khiển.\n+ Gán quyền sở hữu epic cho các thành viên nhóm cá nhân để mỗi khu vực có một người dẫn đầu rõ ràng chịu trách nhiệm cho phạm vi và việc giao hàng của nó.\n+ Tổ chức cấu trúc và trách nhiệm nhóm bằng cách căn chỉnh từng epic với bộ kỹ năng phù hợp (phát hiện mối đe dọa, cơ sở hạ tầng cảnh báo, điều phối quy trình làm việc, nhập dữ liệu, lập bảng điều khiển).\n+ Cấu hình phân rã epic-thành-tác vụ trong Jira để các nhiệm vụ phụ và vấn đề được gắn với epic cha của chúng, cho phép khả năng hiển thị nhóm và theo dõi burndown trên toàn hệ thống ứng phó sự cố. 19/11/2025 19/11/2025 5 Về thăm trường cấp 3 Bùi Thị Xuân nhân ngày Nhà giáo Việt Nam. 20/11/2025 20/11/2025 6 Tôi được mời dự lễ tốt nghiệp của một người bạn ở Đại học FPT. 21/11/2025 21/11/2025 Kết quả đạt được Tuần 11: Cải thiện đáng kể khả năng bảo trì mã bằng cách hợp nhất các hàm Lambda rời rạc thành một \u0026ldquo;Alert Dispatcher\u0026rdquo; duy nhất. Mở rộng hệ thống cảnh báo sự cố để hỗ trợ Telegram, Slack, và SES Email cùng một lúc. Triển khai các phương pháp cấu hình bảo mật bằng cách chuyển thông tin xác thực được mã hóa cứng sang Biến Môi trường. Thực thi tính rõ ràng của dự án bằng cách xác định các Epics và phân công trách nhiệm chi tiết trong Jira. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/5-workshop/5.11-appendices/","title":"Phụ lục","tags":[],"description":"","content":"Phụ lục Lambda Codes: CloudTrail ETL GuardDuty ETL CloudWatch ETL CloudWatch ENI ETL CloudWatch Auto Export Parse Findings Isolate EC2 Instance Quarantine IAM Alert Dispatch Step Functions ASL Code: Step Functions ASL Code "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.12-week12/","title":"Nhật ký Tuần 12","tags":[],"description":"","content":"Mục tiêu Tuần 12: Thiết kế và tối ưu hóa UX cho Bảng điều khiển Ứng phó Sự cố S3. Bảo mật bảng điều khiển công khai bằng cách triển khai Xác thực Cognito với React. Ngăn chặn chi phí truy vấn Athena trái phép bằng cách thực thi kiểm soát truy cập dựa trên phiên. Khám phá thiết lập Linux thay thế (Arch) và mạng WireGuard VPN. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Thiết kế bảng điều khiển S3 với Kiệt để xác định các chỉ số chính và cải tiến UX, sau đó sửa lỗi và tối ưu hóa hiệu suất bảng điều khiển.\n+ Brainstorm bố cục bảng điều khiển S3 với Kiệt, thẻ tóm tắt cảnh báo, dòng thời gian, phân phối mức độ nghiêm trọng, và các chỉ số thời gian thực cho khối lượng cảnh báo và thành công khi gửi.\n+ Xác định các vấn đề UX: thiếu bộ lọc, nhóm cảnh báo không rõ ràng, và thiếu chi tiết.\n+ Sửa lỗi: Lỗi truy vấn và lỗi giao diện người dùng\n+ Tối ưu hóa truy vấn bảng điều khiển để tổng hợp nhanh hơn, thêm làm mới thời gian thực, và cải thiện phân cấp trực quan để các phát hiện quan trọng nổi bật, đã kiểm tra với các sự kiện GuardDuty. 24/11/2025 24/11/2025 3 Xác định một vấn đề bảo mật và chi phí nghiêm trọng: quyền truy cập bảng điều khiển không xác thực gây ra các truy vấn Athena không giới hạn khi làm mới trang, sau đó khám phá các giải pháp xác thực.\n+ Phát hiện ra bảng điều khiển S3 không có trang đăng nhập, vì vậy bất kỳ ai cũng có thể làm mới và kích hoạt các truy vấn Athena đắt tiền mà không cần ủy quyền.\n+ Đã thử tích hợp Cognito + Lambda@Edge để thêm xác thực tại biên, nhưng gặp trở ngại: CloudFront distribution của tôi sử dụng giá phẳng (flat pricing) (không phải trả tiền theo mức sử dụng) và không thể chuyển đổi, khiến Lambda@Edge không thể sử dụng được.\n+ Đã thử CloudFront Functions như một sự thay thế, kết hợp nó với Lambda để triển khai lọc yêu cầu và xác thực cơ bản mà không cần Lambda@Edge. 25/11/2025 25/11/2025 4 Gỡ lỗi các vấn đề phiên CloudFront/Lambda, đánh giá AWS Amplify nhưng chuyển sang xác thực dựa trên React để đáp ứng thời hạn.\n+ Dành hàng giờ để khắc phục sự cố thiết lập CloudFront Functions + Lambda, sau đây có thể là lý do: phiên không tồn tại và quyền truy cập chéo tên miền từ S3 bị chặn, không tìm thấy giải pháp khả thi nào.\n+ Khám phá AWS Amplify như một sự thay thế cho xác thực được quản lý, nhưng nhận ra cấu trúc bảng điều khiển hiện tại không tương thích nếu không tái cấu trúc đáng kể và lãng phí thời gian.\n+ Quyết định triển khai xác thực trực tiếp trong bảng điều khiển React do thời hạn gấp rút.\n+ Tích hợp đăng nhập Cognito trực tiếp vào các thành phần React với quản lý phiên dựa trên token, bảo vệ quyền truy cập bảng điều khiển và thực thi truy vấn Athena.\n+ Kiểm tra luồng xác thực React đầu cuối, người dùng bây giờ phải xác thực trước khi xem bảng điều khiển, và chỉ các phiên được ủy quyền mới có thể kích hoạt các truy vấn Athena, giải quyết cả vấn đề bảo mật và chi phí. 26/11/2025 26/11/2025 5 Đây là một dự án phụ: Cài đặt Arch Linux trên PC dựng sẵn của một người bạn và bắt đầu thiết lập WireGuard VPN, học quản lý gói pacman trong quá trình này.\n+ Cài đặt Arch Linux trên một hệ thống dựng sẵn thay thế cho hệ điều hành mặc định, bây giờ tôi có thể nói một cách chính đáng \u0026ldquo;I use Arch btw\u0026rdquo;.\n+ Nghiên cứu bảo mật mạng cho PC và xác định WireGuard là một giải pháp VPN hiện đại, nhẹ để bảo mật lưu lượng truy cập nhóm.\n+ Khám phá pacman (trình quản lý gói của Arch) hoạt động khác với apt, dành thời gian tìm kiếm các gói WireGuard và hiểu cấu trúc kho lưu trữ của Arch (core, extra, community).\n+ Bắt đầu cấu hình WireGuard trên hệ thống Arch nhưng nhận ra sự phức tạp của thiết lập cần nhiều thời gian hơn mức có sẵn trong một ngày.\n+ Ghi lại tất cả tên gói và các bước cấu hình để tiếp tục vào ngày hôm sau. 27/11/2025 27/11/2025 6 Hoàn thành cài đặt và cấu hình WireGuard VPN trên Arch Linux, giải quyết các vấn đề phụ thuộc pacman và kiểm tra kết nối ngang hàng.\n+ Hoàn thành cài đặt WireGuard sử dụng pacman, giải quyết xung đột phụ thuộc và tìm đúng phiên bản gói cho Arch.\n+ Tạo khóa WireGuard (công khai/riêng tư) và cấu hình kết nối ngang hàng cho mạng dự án trường trung học của nhóm.\n+ Thiết lập giao diện mạng và định tuyến IP trên Arch với các quy tắc tường lửa phù hợp để cho phép truy cập VPN an toàn giữa các thành viên nhóm.\n+ Kiểm tra kết nối WireGuard đầu cuối, xác minh các đồng đẳng có thể kết nối và giao tiếp qua đường hầm được mã hóa một cách đáng tin cậy.\n+ Ghi lại toàn bộ quy trình thiết lập cho nhóm để những người khác có thể sao chép cấu hình WireGuard trên hệ thống của họ. 28/11/2025 28/11/2025 Kết quả đạt được Tuần 12: Cải tiến UX Bảng điều khiển S3, giải quyết lỗi và cải thiện hiệu suất trực quan hóa dữ liệu. Triển khai thành công Xác thực Client-Side sử dụng Cognito và React để bảo vệ các chỉ số nhạy cảm. Loại bỏ rủi ro tăng đột biến hóa đơn Athena không giới hạn bằng cách thực thi thực thi truy vấn dựa trên phiên. Cấu hình WireGuard VPN an toàn trên Arch Linux, thể hiện sự linh hoạt trong quản trị hệ thống. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/1-worklog/1.13-week13/","title":"Nhật ký Tuần 13","tags":[],"description":"","content":"Mục tiêu Tuần 13: Hoàn thiện việc theo dõi và quản lý dự án trên Jira. Định dạng và cấu trúc lại toàn bộ tài liệu dự án trên Hugo. Dịch tài liệu hội thảo và bản đề xuất sang tiếng Việt. Triển khai trang tài liệu tĩnh lên GitHub Pages. Hỗ trợ các thành viên trong nhóm triển khai GitHub Pages và sửa lỗi. Các nhiệm vụ thực hiện trong tuần: Ngày Nhiệm vụ Ngày bắt đầu Ngày hoàn thành Tài liệu tham khảo 2 Hoàn tất thiết lập bảng Jira. Dịch Bản đề xuất từ Google Doc sang tiếng Việt và đưa vào phần đề xuất. 01/12/2025 01/12/2025 3 Bắt đầu định dạng tài liệu và tổ chức cấu trúc thư mục Hugo. 02/12/2025 02/12/2025 4 Tiếp tục định dạng tài liệu, sửa các lỗi markdown và đảm bảo kiểu dáng nhất quán. 03/12/2025 03/12/2025 5 Hoàn thành việc định dạng tài liệu. Dịch toàn bộ nội dung hội thảo Hugo sang tiếng Việt. 04/12/2025 04/12/2025 6 Triển khai trang Hugo lên GitHub Pages. Giúp bạn bè và thành viên nhóm triển khai trang web của họ lên GitHub và sửa các lỗi build. 05/12/2025 05/12/2025 Kết quả đạt được Tuần 13: Triển khai thành công trang tài liệu được định dạng đầy đủ và song ngữ (Anh/Việt). Hoàn thành việc cập nhật theo dõi dự án trên Jira. Hỗ trợ nhiều thành viên trong nhóm triển khai thành công nhật ký làm việc và giải quyết lỗi. Tích hợp bản dịch tiếng Việt của tài liệu đề xuất. "},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://beforelights.github.io/AWS-Worklog/vi/tags/","title":"Tags","tags":[],"description":"","content":""}]